{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Decision tree, Logistic regression, KNN neighbour, SVM,Gradient Boosting and Neural nets on event dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing common packages for the techniques\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "import scikitplot as sckplt\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, average_precision_score, roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Technique specific packages\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import ensemble\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Data \n",
    "event=pd.read_excel(\"C:\\\\Users\\\\agraw\\\\Desktop\\\\Predictive\\\\Assignment 3\\\\HW3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       count         mean          std  min      25%  \\\n",
      "sequence_number       2000.0  1000.500000   577.494589  1.0   500.75   \n",
      "US                    2000.0     0.824500     0.380489  0.0     1.00   \n",
      "source_a              2000.0     0.126500     0.332495  0.0     0.00   \n",
      "source_c              2000.0     0.056000     0.229979  0.0     0.00   \n",
      "source_b              2000.0     0.060000     0.237546  0.0     0.00   \n",
      "source_d              2000.0     0.041500     0.199493  0.0     0.00   \n",
      "source_e              2000.0     0.151000     0.358138  0.0     0.00   \n",
      "source_m              2000.0     0.016500     0.127420  0.0     0.00   \n",
      "source_o              2000.0     0.033500     0.179983  0.0     0.00   \n",
      "source_h              2000.0     0.052500     0.223089  0.0     0.00   \n",
      "source_r              2000.0     0.068500     0.252665  0.0     0.00   \n",
      "source_s              2000.0     0.047000     0.211692  0.0     0.00   \n",
      "source_t              2000.0     0.021500     0.145080  0.0     0.00   \n",
      "source_u              2000.0     0.119000     0.323869  0.0     0.00   \n",
      "source_p              2000.0     0.006000     0.077246  0.0     0.00   \n",
      "source_x              2000.0     0.018000     0.132984  0.0     0.00   \n",
      "source_w              2000.0     0.137500     0.344461  0.0     0.00   \n",
      "Freq                  2000.0     1.417000     1.405738  0.0     1.00   \n",
      "last_update_days_ago  2000.0  2155.101000  1141.302846  1.0  1133.00   \n",
      "1st_update_days_ago   2000.0  2435.601500  1077.872233  1.0  1671.25   \n",
      "Web order             2000.0     0.426000     0.494617  0.0     0.00   \n",
      "Gender=male           2000.0     0.524500     0.499524  0.0     0.00   \n",
      "Address_is_res        2000.0     0.221000     0.415024  0.0     0.00   \n",
      "Purchase              2000.0     0.500000     0.500125  0.0     0.00   \n",
      "Spending              2000.0   102.560745   186.749816  0.0     0.00   \n",
      "\n",
      "                           50%        75%      max  \n",
      "sequence_number       1000.500  1500.2500  2000.00  \n",
      "US                       1.000     1.0000     1.00  \n",
      "source_a                 0.000     0.0000     1.00  \n",
      "source_c                 0.000     0.0000     1.00  \n",
      "source_b                 0.000     0.0000     1.00  \n",
      "source_d                 0.000     0.0000     1.00  \n",
      "source_e                 0.000     0.0000     1.00  \n",
      "source_m                 0.000     0.0000     1.00  \n",
      "source_o                 0.000     0.0000     1.00  \n",
      "source_h                 0.000     0.0000     1.00  \n",
      "source_r                 0.000     0.0000     1.00  \n",
      "source_s                 0.000     0.0000     1.00  \n",
      "source_t                 0.000     0.0000     1.00  \n",
      "source_u                 0.000     0.0000     1.00  \n",
      "source_p                 0.000     0.0000     1.00  \n",
      "source_x                 0.000     0.0000     1.00  \n",
      "source_w                 0.000     0.0000     1.00  \n",
      "Freq                     1.000     2.0000    15.00  \n",
      "last_update_days_ago  2280.000  3139.2500  4188.00  \n",
      "1st_update_days_ago   2721.000  3353.0000  4188.00  \n",
      "Web order                0.000     1.0000     1.00  \n",
      "Gender=male              1.000     1.0000     1.00  \n",
      "Address_is_res           0.000     0.0000     1.00  \n",
      "Purchase                 0.500     1.0000     1.00  \n",
      "Spending                 1.855   152.5325  1500.06  \n"
     ]
    }
   ],
   "source": [
    "#Exploring data\n",
    "print(event.describe().transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the data set are 2000 by 25\n"
     ]
    }
   ],
   "source": [
    "#Dimension of the data set\n",
    "n_samples, n_features = event.shape\n",
    "print ('The dimensions of the data set are', n_samples, 'by', n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "X=event.copy(deep=True)\n",
    "columns = ['sequence_number', 'Purchase', 'Spending']\n",
    "X.drop(columns, inplace=True, axis=1)\n",
    "y = event.loc[:,'Spending'] # Target variable\n",
    "\n",
    "#Test_train_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processing - scaling of data \n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(X_train)\n",
    "x_train = pd.DataFrame(x_train_scaled)\n",
    "\n",
    "x_test_scaled = scaler.fit_transform(X_test)\n",
    "x_test = pd.DataFrame(x_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeRegressor(criterion='mse', max_depth=None,\n",
       "                                             max_features=None,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             presort=False, random_state=None,\n",
       "                                             splitter='best'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'criterion': ['mse', 'mae'],\n",
       "                         'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                       13, 14, 15, 16, 17, 18, 19],\n",
       "                         'max_leaf_nodes': [10],\n",
       "                         'min_samples_split': [0.05, 0.1, 0.15000000000000002,\n",
       "                                               0.2, 0.25, 0.3,\n",
       "                                               0.35000000000000003, 0.4,\n",
       "                                               0.45]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimize the Decision tree  by hyperparameter tuning using cross validation\n",
    "# Defining different parameters for tuning the model\n",
    "d_range = list(range(1,20))\n",
    "c_options = [\"mse\", \"mae\"]\n",
    "samples_split=list(np.arange(0.05, 0.5, 0.05))\n",
    "leaf_nodes=[10]\n",
    "\n",
    "param_grid = dict(max_depth = d_range, criterion = c_options,min_samples_split=samples_split,max_leaf_nodes=leaf_nodes)\n",
    "#print (param_grid)\n",
    "model = tree.DecisionTreeRegressor()\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, cv = 10,scoring='neg_mean_squared_error')\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final reports for the Decision tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-19588.52574255357\n",
      "{'criterion': 'mae', 'max_depth': 6, 'max_leaf_nodes': 10, 'min_samples_split': 0.05}\n",
      "DecisionTreeRegressor(criterion='mae', max_depth=6, max_features=None,\n",
      "                      max_leaf_nodes=10, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=0.05, min_weight_fraction_leaf=0.0,\n",
      "                      presort=False, random_state=None, splitter='best')\n",
      "mean square error 19819.01122275\n",
      "root mean square error 140.78001002539386\n",
      "mean absolute error 70.26956666666665\n"
     ]
    }
   ],
   "source": [
    "#print(grid.grid_scores_)\n",
    "#print(grid.grid_scores_[0].parameters)\n",
    "#print(grid.grid_scores_[0].cv_validation_scores)\n",
    "#print(grid.grid_scores_[0].mean_validation_score)\n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)\n",
    "\n",
    "#final fitted model\n",
    "bclf1 = grid.best_estimator_\n",
    "bclf1.fit(x_train,y_train)\n",
    "pred = bclf1.predict(x_test)\n",
    "\n",
    "mse=mean_squared_error(y_test, pred)\n",
    "print(\"mean square error\",mse)\n",
    "rms = sqrt(mean_squared_error(y_test, pred))\n",
    "print(\"root mean square error\",rms)\n",
    "mae=mean_absolute_error(y_test, pred)\n",
    "print(\"mean absolute error\",mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=LinearRegression(copy_X=True, fit_intercept=True,\n",
       "                                        n_jobs=None, normalize=False),\n",
       "             iid='warn', n_jobs=None, param_grid={}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different parameters for tuning the model\n",
    "param_grid = {}\n",
    "#print (param_grid)\n",
    "model = LinearRegression()\n",
    "\n",
    "#mean_squared_error\n",
    "grid = GridSearchCV(model, param_grid, cv = 10,scoring='neg_mean_squared_error')\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final reports for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-16281.288936134777\n",
      "{}\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
      "mean square error 17597.142998353287\n",
      "root mean square error 132.65422344710058\n",
      "mean absolute error 84.60580802030539\n"
     ]
    }
   ],
   "source": [
    "#print(grid.grid_scores_)\n",
    "#print(grid.grid_scores_[0].parameters)\n",
    "#print(grid.grid_scores_[0].cv_validation_scores)\n",
    "#print(grid.grid_scores_[0].mean_validation_score)\n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)\n",
    "\n",
    "#final fitted model\n",
    "bclf1 = grid.best_estimator_\n",
    "bclf1.fit(x_train,y_train)\n",
    "pred = bclf1.predict(x_test)\n",
    "\n",
    "mse=mean_squared_error(y_test, pred)\n",
    "print(\"mean square error\",mse)\n",
    "rms = sqrt(mean_squared_error(y_test, pred))\n",
    "print(\"root mean square error\",rms)\n",
    "mae=mean_absolute_error(y_test, pred)\n",
    "print(\"mean absolute error\",mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=1000, normalize=False, positive=False,\n",
       "                             precompute=False, random_state=None,\n",
       "                             selection='cyclic', tol=0.0001, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'alpha': [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6,\n",
       "                                   0.7000000000000001, 0.8, 0.9, 1.0, 1.1,\n",
       "                                   1.2000000000000002, 1.3000000000000003,\n",
       "                                   1.4000000000000001, 1.5000000000000002, 1.6,\n",
       "                                   1.7000000000000002, 1.8000000000000003,\n",
       "                                   1.9000000000000001]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different parameters for tuning the model\n",
    "#Linear model\n",
    "param_grid = {'alpha':list(np.arange(0.1,2,0.1))}\n",
    "model=linear_model.Lasso()\n",
    "\n",
    "#mean_squared_error\n",
    "grid = GridSearchCV(model, param_grid, cv = 10,scoring='neg_mean_squared_error')\n",
    "grid.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final reports for lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-16193.861459323778\n",
      "{'alpha': 0.4}\n",
      "Lasso(alpha=0.4, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=None,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False)\n",
      "mean square error 17352.65854388237\n",
      "root mean square error 131.7294900312089\n",
      "mean absolute error 84.33790135336872\n"
     ]
    }
   ],
   "source": [
    "#print(grid.grid_scores_)\n",
    "#print(grid.grid_scores_[0].parameters)\n",
    "#print(grid.grid_scores_[0].cv_validation_scores)\n",
    "#print(grid.grid_scores_[0].mean_validation_score)\n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)\n",
    "\n",
    "#final fitted model\n",
    "bclf1 = grid.best_estimator_\n",
    "bclf1.fit(x_train,y_train)\n",
    "pred = bclf1.predict(x_test)\n",
    "\n",
    "mse=mean_squared_error(y_test, pred)\n",
    "print(\"mean square error\",mse)\n",
    "rms = sqrt(mean_squared_error(y_test, pred))\n",
    "print(\"root mean square error\",rms)\n",
    "mae=mean_absolute_error(y_test, pred)\n",
    "print(\"mean absolute error\",mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=None, normalize=False, random_state=None,\n",
       "                             solver='auto', tol=0.001),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'alpha': [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6,\n",
       "                                   0.7000000000000001, 0.8, 0.9, 1.0, 1.1,\n",
       "                                   1.2000000000000002, 1.3000000000000003,\n",
       "                                   1.4000000000000001, 1.5000000000000002, 1.6,\n",
       "                                   1.7000000000000002, 1.8000000000000003,\n",
       "                                   1.9000000000000001]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different parameters for tuning the model\n",
    "param_grid = {'alpha':list(np.arange(0.1,2,0.1))}\n",
    "model=linear_model.Ridge()\n",
    "grid = GridSearchCV(model, param_grid, cv = 10,scoring='neg_mean_squared_error')\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final reports for Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-16281.88861859038\n",
      "{'alpha': 0.1}\n",
      "Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "mean square error 17535.842010883007\n",
      "root mean square error 132.42296632715568\n",
      "mean absolute error 84.279112555381\n"
     ]
    }
   ],
   "source": [
    "#print(grid.grid_scores_)\n",
    "#print(grid.grid_scores_[0].parameters)\n",
    "#print(grid.grid_scores_[0].cv_validation_scores)\n",
    "#print(grid.grid_scores_[0].mean_validation_score)\n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)\n",
    "\n",
    "#final fitted model\n",
    "bclf1 = grid.best_estimator_\n",
    "bclf1.fit(x_train,y_train)\n",
    "pred = bclf1.predict(x_test)\n",
    "\n",
    "mse=mean_squared_error(y_test, pred)\n",
    "print(\"mean square error\",mse)\n",
    "rms = sqrt(mean_squared_error(y_test, pred))\n",
    "print(\"root mean square error\",rms)\n",
    "mae=mean_absolute_error(y_test, pred)\n",
    "print(\"mean absolute error\",mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30,\n",
       "                                           metric='minkowski',\n",
       "                                           metric_params=None, n_jobs=None,\n",
       "                                           n_neighbors=5, p=2,\n",
       "                                           weights='uniform'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                         13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "                                         23, 24, 25, 26, 27, 28, 29],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimize the KNN model by hypertuning using cross validation\n",
    "# Different parameters for tuning the model\n",
    "n_range = list(range(1,30))\n",
    "w_options = [\"uniform\", \"distance\"]\n",
    "\n",
    "param_grid = dict(n_neighbors=n_range, weights=w_options)\n",
    "#print (param_grid)\n",
    "model = neighbors.KNeighborsRegressor()\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, cv = 10,scoring='neg_mean_squared_error')\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final reports for KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-28130.858517892786\n",
      "{'n_neighbors': 5, 'weights': 'distance'}\n",
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                    weights='distance')\n",
      "mean square error 30012.6684618907\n",
      "root mean square error 173.24164759632916\n",
      "mean absolute error 94.75166362077671\n"
     ]
    }
   ],
   "source": [
    "#print(grid.grid_scores_)\n",
    "#print(grid.grid_scores_[0].parameters)\n",
    "#print(grid.grid_scores_[0].cv_validation_scores)\n",
    "#print(grid.grid_scores_[0].mean_validation_score)\n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)\n",
    "\n",
    "#final fitted model\n",
    "bclf1 = grid.best_estimator_\n",
    "bclf1.fit(x_train,y_train)\n",
    "pred = bclf1.predict(x_test)\n",
    "\n",
    "mse=mean_squared_error(y_test, pred)\n",
    "print(\"mean square error\",mse)\n",
    "rms = sqrt(mean_squared_error(y_test, pred))\n",
    "print(\"root mean square error\",rms)\n",
    "mae=mean_absolute_error(y_test, pred)\n",
    "print(\"mean absolute error\",mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='auto_deprecated', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'C': [1, 10, 100], 'epsilon': [0.1, 0.2, 0.3],\n",
       "                          'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
       "                         {'C': [1, 10, 100, 1000], 'epsilon': [0.1, 0.2, 0.3],\n",
       "                          'kernel': ['linear']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimize the SVM model by hypertuning using cross validation\n",
    "# Different parameters for tuning the model\n",
    "\n",
    "param_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100],'epsilon':[0.1,0.2,0.3]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000],'epsilon':[0.1,0.2,0.3]}]\n",
    "\n",
    "#print (param_grid)\n",
    "model = SVR()\n",
    "\n",
    "#mean_squared_error\n",
    "grid = GridSearchCV(model, param_grid, cv = 10,scoring='neg_mean_squared_error')\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-18527.505585533283\n",
      "{'C': 1000, 'epsilon': 0.3, 'kernel': 'linear'}\n",
      "SVR(C=1000, cache_size=200, coef0=0.0, degree=3, epsilon=0.3,\n",
      "    gamma='auto_deprecated', kernel='linear', max_iter=-1, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "mean square error 17736.974098941395\n",
      "root mean square error 133.18023163721182\n",
      "mean absolute error 71.81484107663087\n"
     ]
    }
   ],
   "source": [
    "#print(grid.grid_scores_)\n",
    "#print(grid.grid_scores_[0].parameters)\n",
    "#print(grid.grid_scores_[0].cv_validation_scores)\n",
    "#print(grid.grid_scores_[0].mean_validation_score)\n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)\n",
    "\n",
    "#final fitted model\n",
    "bclf1 = grid.best_estimator_\n",
    "bclf1.fit(x_train,y_train)\n",
    "pred = bclf1.predict(x_test)\n",
    "\n",
    "mse=mean_squared_error(y_test, pred)\n",
    "print(\"mean square error\",mse)\n",
    "rms = sqrt(mean_squared_error(y_test, pred))\n",
    "print(\"root mean square error\",rms)\n",
    "mae=mean_absolute_error(y_test, pred)\n",
    "print(\"mean absolute error\",mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=RandomForestRegressor(bootstrap=True, criterion='mse',\n",
       "                                             max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators='warn', n_jobs=None,\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [10], 'max_features': ['sqrt'],\n",
       "                         'min_samples_leaf': [20, 40],\n",
       "                         'n_estimators': [10, 100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the best parameters\n",
    "tuned_parameters = {\"n_estimators\" : [10, 100, 200], \"max_depth\" : [10],\n",
    "                     \"min_samples_leaf\" : [20, 40],\"max_features\" :['sqrt']}\n",
    "#print (param_grid)\n",
    "model = RandomForestRegressor() \n",
    "\n",
    "grid = GridSearchCV(model, tuned_parameters, cv = 10, scoring = \"neg_mean_squared_error\")\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-22177.62615154665\n",
      "{'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 20, 'n_estimators': 200}\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=20, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=0, warm_start=False)\n",
      "mean square error 20471.435726542393\n",
      "root mean square error 143.0784250910751\n",
      "mean absolute error 83.69684854800131\n"
     ]
    }
   ],
   "source": [
    "#print(grid.grid_scores_)\n",
    "#print(grid.grid_scores_[0].parameters)\n",
    "#print(grid.grid_scores_[0].cv_validation_scores)\n",
    "#print(grid.grid_scores_[0].mean_validation_score)\n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)\n",
    "\n",
    "#final fitted model\n",
    "bclf1 = grid.best_estimator_\n",
    "bclf1.fit(x_train,y_train)\n",
    "pred = bclf1.predict(x_test)\n",
    "\n",
    "mse=mean_squared_error(y_test, pred)\n",
    "print(\"mean square error\",mse)\n",
    "rms = sqrt(mean_squared_error(y_test, pred))\n",
    "print(\"root mean square error\",rms)\n",
    "mae=mean_absolute_error(y_test, pred)\n",
    "print(\"mean absolute error\",mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'learning_rate': [0.05,0.1,0.15], 'n_estimators': [100,200],\n",
    "                     'max_depth':[8],'max_features':['sqrt']\n",
    "                     ,'subsample':[0.8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=GradientBoostingRegressor(alpha=0.9,\n",
       "                                                 criterion='friedman_mse',\n",
       "                                                 init=None, learning_rate=0.1,\n",
       "                                                 loss='ls', max_depth=3,\n",
       "                                                 max_features=None,\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=100,\n",
       "                                                 n_ite...\n",
       "                                                 presort='auto',\n",
       "                                                 random_state=None,\n",
       "                                                 subsample=1.0, tol=0.0001,\n",
       "                                                 validation_fraction=0.1,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.05, 0.1, 0.15], 'max_depth': [8],\n",
       "                         'max_features': ['sqrt'], 'n_estimators': [100, 200],\n",
       "                         'subsample': [0.8]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the best hyperparameters\n",
    "model = ensemble.GradientBoostingRegressor()\n",
    "\n",
    "#mean_squared_error\n",
    "grid = GridSearchCV(model, param_grid, cv = 10,scoring='neg_mean_squared_error')\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-16981.635112278287\n",
      "{'learning_rate': 0.05, 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100, 'subsample': 0.8}\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.05, loss='ls', max_depth=8,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=0.8, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "mean square error 18898.868634090304\n",
      "root mean square error 137.47315604906402\n",
      "mean absolute error 77.16649537458545\n"
     ]
    }
   ],
   "source": [
    "#print(grid.grid_scores_)\n",
    "#print(grid.grid_scores_[0].parameters)\n",
    "#print(grid.grid_scores_[0].cv_validation_scores)\n",
    "#print(grid.grid_scores_[0].mean_validation_score)\n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)\n",
    "\n",
    "#final fitted model\n",
    "bclf1 = grid.best_estimator_\n",
    "bclf1.fit(x_train,y_train)\n",
    "pred = bclf1.predict(x_test)\n",
    "\n",
    "mse=mean_squared_error(y_test, pred)\n",
    "print(\"mean square error\",mse)\n",
    "rms = sqrt(mean_squared_error(y_test, pred))\n",
    "print(\"root mean square error\",rms)\n",
    "mae=mean_absolute_error(y_test, pred)\n",
    "print(\"mean absolute error\",mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: -30033.62 (10619.65) MSE\n"
     ]
    }
   ],
   "source": [
    "# define base model\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(22, input_dim=22, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "#Data to train the model\n",
    "\n",
    "X = x_train\n",
    "Y = y_train\n",
    "\n",
    "# evaluate model\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=50, verbose=0)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Baseline: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -16305.27 (6310.66) MSE\n"
     ]
    }
   ],
   "source": [
    "#Increasing one layer\n",
    "\n",
    "# define the model\n",
    "def larger_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(22, input_dim=22, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# evaluate model\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=larger_model, epochs=50, batch_size=50, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -15664.11 (6195.87) MSE\n"
     ]
    }
   ],
   "source": [
    "#Increasing one more layer of the model\n",
    "        \n",
    "# define the model\n",
    "def larger_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(22, input_dim=22, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(5, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# evaluate model\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=larger_model, epochs=50, batch_size=25, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question 1 part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the different regressors on the dataset where purchase is equal to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "event.loc[:,\"Purchase\"]==1\n",
    "event1=event[event.loc[:,\"Purchase\"]==1]\n",
    "X=event1.copy(deep=True)\n",
    "columns = ['sequence_number', 'Purchase', 'Spending']\n",
    "X.drop(columns, inplace=True, axis=1)\n",
    "y = event1.loc[:,'Spending'] # Target variable\n",
    "\n",
    "#Test_train_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processing - scaling of data \n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(X_train)\n",
    "x_train = pd.DataFrame(x_train_scaled)\n",
    "\n",
    "x_test_scaled = scaler.fit_transform(X_test)\n",
    "x_test = pd.DataFrame(x_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeRegressor(criterion='mse', max_depth=None,\n",
       "                                             max_features=None,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             presort=False, random_state=None,\n",
       "                                             splitter='best'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'criterion': ['mse', 'mae'],\n",
       "                         'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                       13, 14, 15, 16, 17, 18, 19],\n",
       "                         'max_leaf_nodes': [10],\n",
       "                         'min_samples_split': [0.05, 0.1, 0.15000000000000002,\n",
       "                                               0.2, 0.25, 0.3,\n",
       "                                               0.35000000000000003, 0.4,\n",
       "                                               0.45]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimize the Decision tree  by hyperparameter tuning using cross validation\n",
    "# Defining different parameters for tuning the model\n",
    "d_range = list(range(1,20))\n",
    "c_options = [\"mse\", \"mae\"]\n",
    "samples_split=list(np.arange(0.05, 0.5, 0.05))\n",
    "leaf_nodes=[10]\n",
    "\n",
    "param_grid = dict(max_depth = d_range, criterion = c_options,min_samples_split=samples_split,max_leaf_nodes=leaf_nodes)\n",
    "#print (param_grid)\n",
    "model = tree.DecisionTreeRegressor()\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, cv = 10,scoring='neg_mean_squared_error')\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final reports for the Decision tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-29695.78672669974\n",
      "{'criterion': 'mse', 'max_depth': 4, 'max_leaf_nodes': 10, 'min_samples_split': 0.1}\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
      "                      max_leaf_nodes=10, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=0.1, min_weight_fraction_leaf=0.0,\n",
      "                      presort=False, random_state=None, splitter='best')\n",
      "mean square error 40279.47518028626\n",
      "root mean square error 200.6974717834937\n",
      "mean absolute error 117.18188559926098\n"
     ]
    }
   ],
   "source": [
    "#print(grid.grid_scores_)\n",
    "#print(grid.grid_scores_[0].parameters)\n",
    "#print(grid.grid_scores_[0].cv_validation_scores)\n",
    "#print(grid.grid_scores_[0].mean_validation_score)\n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)\n",
    "\n",
    "#final fitted model\n",
    "bclf1 = grid.best_estimator_\n",
    "bclf1.fit(x_train,y_train)\n",
    "pred = bclf1.predict(x_test)\n",
    "\n",
    "mse=mean_squared_error(y_test, pred)\n",
    "print(\"mean square error\",mse)\n",
    "rms = sqrt(mean_squared_error(y_test, pred))\n",
    "print(\"root mean square error\",rms)\n",
    "mae=mean_absolute_error(y_test, pred)\n",
    "print(\"mean absolute error\",mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=1000, normalize=False, positive=False,\n",
       "                             precompute=False, random_state=None,\n",
       "                             selection='cyclic', tol=0.0001, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'alpha': [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6,\n",
       "                                   0.7000000000000001, 0.8, 0.9, 1.0, 1.1,\n",
       "                                   1.2000000000000002, 1.3000000000000003,\n",
       "                                   1.4000000000000001, 1.5000000000000002, 1.6,\n",
       "                                   1.7000000000000002, 1.8000000000000003,\n",
       "                                   1.9000000000000001]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different parameters for tuning the model\n",
    "#Linear model\n",
    "param_grid = {'alpha':list(np.arange(0.1,2,0.1))}\n",
    "#print (param_grid)\n",
    "model=linear_model.Lasso()\n",
    "\n",
    "#mean_squared_error\n",
    "grid = GridSearchCV(model, param_grid, cv = 10,scoring='neg_mean_squared_error')\n",
    "grid.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final reports for lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-25818.26161734962\n",
      "{'alpha': 1.3000000000000003}\n",
      "Lasso(alpha=1.3000000000000003, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=None,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False)\n",
      "mean square error 30543.970722000166\n",
      "root mean square error 174.76833443733497\n",
      "mean absolute error 105.68420142712681\n"
     ]
    }
   ],
   "source": [
    "#print(grid.grid_scores_)\n",
    "#print(grid.grid_scores_[0].parameters)\n",
    "#print(grid.grid_scores_[0].cv_validation_scores)\n",
    "#print(grid.grid_scores_[0].mean_validation_score)\n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)\n",
    "\n",
    "#final fitted model\n",
    "bclf1 = grid.best_estimator_\n",
    "bclf1.fit(x_train,y_train)\n",
    "pred = bclf1.predict(x_test)\n",
    "\n",
    "mse=mean_squared_error(y_test, pred)\n",
    "print(\"mean square error\",mse)\n",
    "rms = sqrt(mean_squared_error(y_test, pred))\n",
    "print(\"root mean square error\",rms)\n",
    "mae=mean_absolute_error(y_test, pred)\n",
    "print(\"mean absolute error\",mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=None, normalize=False, random_state=None,\n",
       "                             solver='auto', tol=0.001),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'alpha': [0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6,\n",
       "                                   0.7000000000000001, 0.8, 0.9, 1.0, 1.1,\n",
       "                                   1.2000000000000002, 1.3000000000000003,\n",
       "                                   1.4000000000000001, 1.5000000000000002, 1.6,\n",
       "                                   1.7000000000000002, 1.8000000000000003,\n",
       "                                   1.9000000000000001]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different parameters for tuning the model\n",
    "param_grid = {'alpha':list(np.arange(0.1,2,0.1))}\n",
    "model=linear_model.Ridge()\n",
    "grid = GridSearchCV(model, param_grid, cv = 10,scoring='neg_mean_squared_error')\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final reports for Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-26414.037310966454\n",
      "{'alpha': 0.30000000000000004}\n",
      "Ridge(alpha=0.30000000000000004, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "mean square error 30136.20631105547\n",
      "root mean square error 173.5978292233387\n",
      "mean absolute error 106.52013725234761\n"
     ]
    }
   ],
   "source": [
    "#print(grid.grid_scores_)\n",
    "#print(grid.grid_scores_[0].parameters)\n",
    "#print(grid.grid_scores_[0].cv_validation_scores)\n",
    "#print(grid.grid_scores_[0].mean_validation_score)\n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)\n",
    "\n",
    "#final fitted model\n",
    "bclf1 = grid.best_estimator_\n",
    "bclf1.fit(x_train,y_train)\n",
    "pred = bclf1.predict(x_test)\n",
    "\n",
    "mse=mean_squared_error(y_test, pred)\n",
    "print(\"mean square error\",mse)\n",
    "rms = sqrt(mean_squared_error(y_test, pred))\n",
    "print(\"root mean square error\",rms)\n",
    "mae=mean_absolute_error(y_test, pred)\n",
    "print(\"mean absolute error\",mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression without regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=LinearRegression(copy_X=True, fit_intercept=True,\n",
       "                                        n_jobs=None, normalize=False),\n",
       "             iid='warn', n_jobs=None, param_grid={}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different parameters for tuning the model\n",
    "param_grid = {}\n",
    "#print (param_grid)\n",
    "model = LinearRegression()\n",
    "\n",
    "#mean_squared_error\n",
    "grid = GridSearchCV(model, param_grid, cv = 10,scoring='neg_mean_squared_error')\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final reports for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-26454.665773513087\n",
      "{}\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
      "mean square error 30009.67073896936\n",
      "root mean square error 173.23299552616805\n",
      "mean absolute error 106.67706446199857\n"
     ]
    }
   ],
   "source": [
    "#print(grid.grid_scores_)\n",
    "#print(grid.grid_scores_[0].parameters)\n",
    "#print(grid.grid_scores_[0].cv_validation_scores)\n",
    "#print(grid.grid_scores_[0].mean_validation_score)\n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)\n",
    "\n",
    "#final fitted model\n",
    "bclf1 = grid.best_estimator_\n",
    "bclf1.fit(x_train,y_train)\n",
    "pred = bclf1.predict(x_test)\n",
    "\n",
    "mse=mean_squared_error(y_test, pred)\n",
    "print(\"mean square error\",mse)\n",
    "rms = sqrt(mean_squared_error(y_test, pred))\n",
    "print(\"root mean square error\",rms)\n",
    "mae=mean_absolute_error(y_test, pred)\n",
    "print(\"mean absolute error\",mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30,\n",
       "                                           metric='minkowski',\n",
       "                                           metric_params=None, n_jobs=None,\n",
       "                                           n_neighbors=5, p=2,\n",
       "                                           weights='uniform'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                         13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "                                         23, 24, 25, 26, 27, 28, 29],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimize the KNN model by hypertuning using cross validation\n",
    "# Different parameters for tuning the model\n",
    "n_range = list(range(1,30))\n",
    "w_options = [\"uniform\", \"distance\"]\n",
    "\n",
    "param_grid = dict(n_neighbors=n_range, weights=w_options)\n",
    "#print (param_grid)\n",
    "model = neighbors.KNeighborsRegressor()\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, cv = 10,scoring='neg_mean_squared_error')\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final reports for KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-38301.50348802166\n",
      "{'n_neighbors': 29, 'weights': 'distance'}\n",
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=29, p=2,\n",
      "                    weights='distance')\n",
      "mean square error 54857.05130528657\n",
      "root mean square error 234.2158220643656\n",
      "mean absolute error 129.739443143942\n"
     ]
    }
   ],
   "source": [
    "#print(grid.grid_scores_)\n",
    "#print(grid.grid_scores_[0].parameters)\n",
    "#print(grid.grid_scores_[0].cv_validation_scores)\n",
    "#print(grid.grid_scores_[0].mean_validation_score)\n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)\n",
    "\n",
    "#final fitted model\n",
    "bclf1 = grid.best_estimator_\n",
    "bclf1.fit(x_train,y_train)\n",
    "pred = bclf1.predict(x_test)\n",
    "\n",
    "mse=mean_squared_error(y_test, pred)\n",
    "print(\"mean square error\",mse)\n",
    "rms = sqrt(mean_squared_error(y_test, pred))\n",
    "print(\"root mean square error\",rms)\n",
    "mae=mean_absolute_error(y_test, pred)\n",
    "print(\"mean absolute error\",mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='auto_deprecated', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'C': [1, 10, 100], 'epsilon': [0.1, 0.2, 0.3],\n",
       "                          'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
       "                         {'C': [1, 10, 100, 1000], 'epsilon': [0.1, 0.2, 0.3],\n",
       "                          'kernel': ['linear']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimize the SVM model by hypertuning using cross validation\n",
    "# Different parameters for tuning the model\n",
    "\n",
    "param_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100],'epsilon':[0.1,0.2,0.3]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000],'epsilon':[0.1,0.2,0.3]}]\n",
    "\n",
    "model = SVR()\n",
    "\n",
    "#mean_squared_error\n",
    "grid = GridSearchCV(model, param_grid, cv = 10,scoring='neg_mean_squared_error')\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-28457.568299695242\n",
      "{'C': 1000, 'epsilon': 0.2, 'kernel': 'linear'}\n",
      "SVR(C=1000, cache_size=200, coef0=0.0, degree=3, epsilon=0.2,\n",
      "    gamma='auto_deprecated', kernel='linear', max_iter=-1, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "mean square error 34704.58646183507\n",
      "root mean square error 186.29167040379198\n",
      "mean absolute error 104.38973704543547\n"
     ]
    }
   ],
   "source": [
    "#print(grid.grid_scores_)\n",
    "#print(grid.grid_scores_[0].parameters)\n",
    "#print(grid.grid_scores_[0].cv_validation_scores)\n",
    "#print(grid.grid_scores_[0].mean_validation_score)\n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)\n",
    "\n",
    "#final fitted model\n",
    "bclf1 = grid.best_estimator_\n",
    "bclf1.fit(x_train,y_train)\n",
    "pred = bclf1.predict(x_test)\n",
    "\n",
    "mse=mean_squared_error(y_test, pred)\n",
    "print(\"mean square error\",mse)\n",
    "rms = sqrt(mean_squared_error(y_test, pred))\n",
    "print(\"root mean square error\",rms)\n",
    "mae=mean_absolute_error(y_test, pred)\n",
    "print(\"mean absolute error\",mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'learning_rate': [0.05,0.1,0.15], 'n_estimators': [100,200],\n",
    "                     'max_depth':[8],'max_features':['sqrt']\n",
    "                     ,'subsample':[0.8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=GradientBoostingRegressor(alpha=0.9,\n",
       "                                                 criterion='friedman_mse',\n",
       "                                                 init=None, learning_rate=0.1,\n",
       "                                                 loss='ls', max_depth=3,\n",
       "                                                 max_features=None,\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=100,\n",
       "                                                 n_ite...\n",
       "                                                 presort='auto',\n",
       "                                                 random_state=None,\n",
       "                                                 subsample=1.0, tol=0.0001,\n",
       "                                                 validation_fraction=0.1,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.05, 0.1, 0.15], 'max_depth': [8],\n",
       "                         'max_features': ['sqrt'], 'n_estimators': [100, 200],\n",
       "                         'subsample': [0.8]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the best hyperparameters\n",
    "model = ensemble.GradientBoostingRegressor()\n",
    "\n",
    "#mean_squared_error\n",
    "grid = GridSearchCV(model, param_grid, cv = 10,scoring='neg_mean_squared_error')\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-25743.97584754156\n",
      "{'learning_rate': 0.05, 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100, 'subsample': 0.8}\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.05, loss='ls', max_depth=8,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=0.8, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "mean square error 35716.28403099431\n",
      "root mean square error 188.987523479711\n",
      "mean absolute error 110.2712582806939\n"
     ]
    }
   ],
   "source": [
    "#print(grid.grid_scores_)\n",
    "#print(grid.grid_scores_[0].parameters)\n",
    "#print(grid.grid_scores_[0].cv_validation_scores)\n",
    "#print(grid.grid_scores_[0].mean_validation_score)\n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)\n",
    "\n",
    "#final fitted model\n",
    "bclf1 = grid.best_estimator_\n",
    "bclf1.fit(x_train,y_train)\n",
    "pred = bclf1.predict(x_test)\n",
    "\n",
    "mse=mean_squared_error(y_test, pred)\n",
    "print(\"mean square error\",mse)\n",
    "rms = sqrt(mean_squared_error(y_test, pred))\n",
    "print(\"root mean square error\",rms)\n",
    "mae=mean_absolute_error(y_test, pred)\n",
    "print(\"mean absolute error\",mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=RandomForestRegressor(bootstrap=True, criterion='mse',\n",
       "                                             max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators='warn', n_jobs=None,\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [10], 'max_features': ['sqrt'],\n",
       "                         'min_samples_leaf': [20, 40],\n",
       "                         'n_estimators': [10, 100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the best parameters\n",
    "tuned_parameters = {\"n_estimators\" : [10, 100, 200], \"max_depth\" : [10],\n",
    "                     \"min_samples_leaf\" : [20, 40],\"max_features\" :['sqrt']}\n",
    "#print (param_grid)\n",
    "model = RandomForestRegressor() \n",
    "\n",
    "grid = GridSearchCV(model, tuned_parameters, cv = 10, scoring = \"neg_mean_squared_error\")\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-32695.80681231426\n",
      "{'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 20, 'n_estimators': 100}\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
      "                      max_features='sqrt', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=20, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=0, warm_start=False)\n",
      "mean square error 46115.042246286524\n",
      "root mean square error 214.74413204156832\n",
      "mean absolute error 120.83272881083086\n"
     ]
    }
   ],
   "source": [
    "#print(grid.grid_scores_)\n",
    "#print(grid.grid_scores_[0].parameters)\n",
    "#print(grid.grid_scores_[0].cv_validation_scores)\n",
    "#print(grid.grid_scores_[0].mean_validation_score)\n",
    "print (grid.best_score_)\n",
    "print (grid.best_params_)\n",
    "print (grid.best_estimator_)\n",
    "\n",
    "#final fitted model\n",
    "bclf1 = grid.best_estimator_\n",
    "bclf1.fit(x_train,y_train)\n",
    "pred = bclf1.predict(x_test)\n",
    "\n",
    "mse=mean_squared_error(y_test, pred)\n",
    "print(\"mean square error\",mse)\n",
    "rms = sqrt(mean_squared_error(y_test, pred))\n",
    "print(\"root mean square error\",rms)\n",
    "mae=mean_absolute_error(y_test, pred)\n",
    "print(\"mean absolute error\",mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: -45299.82 (13134.41) MSE\n"
     ]
    }
   ],
   "source": [
    "# define base model\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(22, input_dim=22, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "#data to train the model\n",
    "\n",
    "X = x_train\n",
    "Y = y_train\n",
    "\n",
    "# evaluate model\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=50, verbose=0)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Baseline: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -27978.68 (13048.21) MSE\n"
     ]
    }
   ],
   "source": [
    "#Increasing one layer\n",
    "\n",
    "# define the model\n",
    "def larger_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(22, input_dim=22, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# evaluate model \n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=larger_model, epochs=50, batch_size=50, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -25469.20 (10967.99) MSE\n"
     ]
    }
   ],
   "source": [
    "#Increasing one more layer of the model\n",
    "        \n",
    "# define the model\n",
    "def larger_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(22, input_dim=22, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(5, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# evaluate model\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=larger_model, epochs=50, batch_size=25, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
