{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as sckplt\n",
    "import time\n",
    "import re\n",
    "import scipy.stats as stat\n",
    "from math import sqrt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
    "from sklearn import linear_model, tree, neighbors, svm, ensemble\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting OS directory\n",
    "os.chdir('C:\\\\Users\\\\rckar\\\\OneDrive\\\\Documents\\\\MSBA\\\\Fall Semester\\\\6420 Predictive Analytics\\\\HW3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_number</th>\n",
       "      <th>US</th>\n",
       "      <th>source_a</th>\n",
       "      <th>source_c</th>\n",
       "      <th>source_b</th>\n",
       "      <th>source_d</th>\n",
       "      <th>source_e</th>\n",
       "      <th>source_m</th>\n",
       "      <th>source_o</th>\n",
       "      <th>source_h</th>\n",
       "      <th>...</th>\n",
       "      <th>source_x</th>\n",
       "      <th>source_w</th>\n",
       "      <th>Freq</th>\n",
       "      <th>last_update_days_ago</th>\n",
       "      <th>1st_update_days_ago</th>\n",
       "      <th>Web order</th>\n",
       "      <th>Gender=male</th>\n",
       "      <th>Address_is_res</th>\n",
       "      <th>Purchase</th>\n",
       "      <th>Spending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3662</td>\n",
       "      <td>3662</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>127.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2900</td>\n",
       "      <td>2900</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_number  US  source_a  source_c  source_b  source_d  source_e  \\\n",
       "0                1   1         0         0         1         0         0   \n",
       "1                2   1         0         0         0         0         1   \n",
       "\n",
       "   source_m  source_o  source_h  ...  source_x  source_w  Freq  \\\n",
       "0         0         0         0  ...         0         0     2   \n",
       "1         0         0         0  ...         0         0     0   \n",
       "\n",
       "   last_update_days_ago  1st_update_days_ago  Web order  Gender=male  \\\n",
       "0                  3662                 3662          1            0   \n",
       "1                  2900                 2900          1            1   \n",
       "\n",
       "   Address_is_res  Purchase  Spending  \n",
       "0               1         1    127.87  \n",
       "1               0         0      0.00  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading Data\n",
    "df = pd.read_excel(\"HW3.xlsx\")\n",
    "df.head(2)\n",
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data pre-processing\n",
    "\n",
    "# checking for null values\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purchase = df[df['Purchase'] == 1]\n",
    "\n",
    "# Selecting required columns\n",
    "X_df = df_purchase.iloc[:,1:23]\n",
    "y_df = df_purchase.iloc[:,24:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating the Train and Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test_holdout, y_train, y_test_holdout = train_test_split(X_df, y_df, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train_scaled)\n",
    "\n",
    "x_test_scaled = scaler.fit_transform(X_test_holdout)\n",
    "X_test_holdout = pd.DataFrame(x_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the mean absolute errors for each model run\n",
      "[ -96.53684897  -82.46407438 -111.29601696 -104.23354129 -114.72630347]\n",
      " \n",
      "Mean score: 101.85 \n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 107.59440489615713\n",
      "Root Mean Squared Error: 179.3309695816787\n",
      "r2: 0.5135462735363512\n",
      " \n",
      "Time Taken =  0.328125\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "# create linear regression object \n",
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "# cross validation \n",
    "scores = cross_val_score(lr, X_train, y_train, cv=5, scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "print(\"Below are the mean absolute errors for each model run\")\n",
    "print(scores)\n",
    "print(\" \")\n",
    "print(\"Mean score: %0.2f \" % (abs(scores.mean())))\n",
    "\n",
    "# Model fit on training data and predicting on testing data\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test_holdout)\n",
    "\n",
    "# Model performance on testing data\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "# print('Explained Variance:',metrics.explained_variance_score(y_test_holdout, y_pred))\n",
    "print('r2:',metrics.r2_score(y_test_holdout, y_pred))\n",
    "\n",
    "print(\" \")\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score achieved across all parameters:  98.27231057485693\n",
      " \n",
      "Best parameters\n",
      "{'alpha': 1.9000000000000004}\n",
      " \n",
      "Best estimator\n",
      "Lasso(alpha=1.9000000000000004, copy_X=True, fit_intercept=True,\n",
      "   max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "   random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 106.75669504641262\n",
      "Root Mean Squared Error: 183.88506395287703\n",
      "r2: 0.4885256586200427\n",
      "Time Taken =  1.0625\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "lasso = linear_model.Lasso()\n",
    "\n",
    "#Hyper Parameter tuning\n",
    "param_set ={'alpha': list(np.arange(0.1,2,0.2))}\n",
    "grid_lasso = GridSearchCV(lasso, param_grid = param_set, cv=5, scoring='neg_mean_absolute_error', verbose = 0)\n",
    "grid_lasso.fit(X_train,y_train)\n",
    "\n",
    "# examine the best model\n",
    "print(\"Best score achieved across all parameters: \", abs(grid_lasso.best_score_))\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(\" \")\n",
    "print(\"Best parameters\")\n",
    "print (grid_lasso.best_params_)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Best estimator\")\n",
    "print (grid_lasso.best_estimator_)\n",
    "\n",
    "# predicting on test data\n",
    "lasso = grid_lasso.best_estimator_\n",
    "lasso.fit(X_train,y_train)\n",
    "y_pred = lasso.predict(X_test_holdout)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "print('r2:',metrics.r2_score(y_test_holdout, y_pred))\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score achieved across all parameters:  100.50414928984068\n",
      " \n",
      "Best parameters\n",
      "{'alpha': 1.3000000000000003}\n",
      " \n",
      "Best estimator\n",
      "Ridge(alpha=1.3000000000000003, copy_X=True, fit_intercept=True,\n",
      "   max_iter=None, normalize=False, random_state=None, solver='auto',\n",
      "   tol=0.001)\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 107.74492892655539\n",
      "Root Mean Squared Error: 182.0902445429324\n",
      "r2: 0.49846147334580204\n",
      "Time Taken =  2.3125\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "ridge = linear_model.Ridge()\n",
    "\n",
    "#Hyper Parameter tuning\n",
    "param_set ={'alpha': list(np.arange(0.1,2,0.2))}\n",
    "grid_ridge = GridSearchCV(ridge, param_grid = param_set, cv=5, scoring='neg_mean_absolute_error', verbose = 0)\n",
    "grid_ridge.fit(X_train,y_train)\n",
    "\n",
    "# examine the best model\n",
    "print(\"Best score achieved across all parameters: \", abs(grid_ridge.best_score_))\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(\" \")\n",
    "print(\"Best parameters\")\n",
    "print (grid_ridge.best_params_)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Best estimator\")\n",
    "print (grid_ridge.best_estimator_)\n",
    "\n",
    "# predicting on test data\n",
    "ridge = grid_ridge.best_estimator_\n",
    "ridge.fit(X_train,y_train)\n",
    "y_pred = ridge.predict(X_test_holdout)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "print('r2:',metrics.r2_score(y_test_holdout, y_pred))\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score achieved across all parameters:  111.09508560440752\n",
      " \n",
      "Best parameters\n",
      "{'n_neighbors': 26, 'weights': 'distance'}\n",
      " \n",
      "Best estimator\n",
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=None, n_neighbors=26, p=2,\n",
      "          weights='distance')\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 128.92246215381246\n",
      "Root Mean Squared Error: 239.6096409308345\n",
      "r2: 0.13156060090654254\n",
      "Time Taken =  12.953125\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "knn = neighbors.KNeighborsRegressor()\n",
    "\n",
    "#Hyper Parameter tuning\n",
    "param_set ={'n_neighbors': list(range(1,30)), 'weights': [\"uniform\", \"distance\"]}\n",
    "grid_knn = GridSearchCV(knn, param_grid = param_set, cv=5, scoring='neg_mean_absolute_error', verbose = 0)\n",
    "grid_knn.fit(X_train,y_train)\n",
    "\n",
    "# examine the best model\n",
    "print(\"Best score achieved across all parameters: \", abs(grid_knn.best_score_))\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(\" \")\n",
    "print(\"Best parameters\")\n",
    "print (grid_knn.best_params_)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Best estimator\")\n",
    "print (grid_knn.best_estimator_)\n",
    "\n",
    "# predicting on test data\n",
    "knn = grid_knn.best_estimator_\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test_holdout)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "print('r2:',metrics.r2_score(y_test_holdout, y_pred))\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score achieved across all parameters:  98.67343434617351\n",
      " \n",
      "Best parameters\n",
      "{'max_depth': 4, 'min_samples_split': 11}\n",
      " \n",
      "Best estimator\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=11, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best')\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 108.29010017865403\n",
      "Root Mean Squared Error: 198.91353890225153\n",
      "r2: 0.40150623602769187\n",
      "Time Taken =  32.0625\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "DTree = tree.DecisionTreeRegressor()\n",
    "\n",
    "#Hyper parameter tuning\n",
    "param_set ={'max_depth': range(1,20), 'min_samples_split' : range(2,30)}\n",
    "grid_DTree = GridSearchCV(DTree, param_grid = param_set, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_DTree.fit(X_train,y_train)\n",
    "\n",
    "# examine the best model\n",
    "print(\"Best score achieved across all parameters: \", abs(grid_DTree.best_score_))\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(\" \")\n",
    "print(\"Best parameters\")\n",
    "print (grid_DTree.best_params_)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Best estimator\")\n",
    "print (grid_DTree.best_estimator_)\n",
    "\n",
    "# predicting on test data\n",
    "DTree = grid_DTree.best_estimator_\n",
    "DTree.fit(X_train,y_train)\n",
    "y_pred = DTree.predict(X_test_holdout)\n",
    "\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "print('r2:',metrics.r2_score(y_test_holdout, y_pred))\n",
    "\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score achieved across all parameters:  96.65206568430278\n",
      " \n",
      "Best parameters\n",
      "{'C': 100, 'epsilon': 0.5, 'kernel': 'linear'}\n",
      " \n",
      "Best estimator\n",
      "SVR(C=100, cache_size=200, coef0=0.0, degree=3, epsilon=0.5,\n",
      "  gamma='auto_deprecated', kernel='linear', max_iter=-1, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 108.4197259572856\n",
      "Root Mean Squared Error: 203.30354331313333\n",
      "r2: 0.3939695377170195\n",
      "Time Taken =  25.765625\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "SVR = svm.SVR()\n",
    "# Hyper parameter tuning using GridSearch\n",
    "param_set = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1,2,10,100,1000], 'epsilon':[0.05,0.1,0.2,0.3,0.5]},\n",
    "                    {'kernel': ['linear'], 'C': [1,2,5,10,100], 'epsilon':[0.05,0.1,0.2,0.3,0.5]}]\n",
    "grid_SVR = GridSearchCV(SVR, param_grid = param_set, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_SVR.fit(X_train,y_train)\n",
    "\n",
    "# examine the best model\n",
    "print(\"Best score achieved across all parameters: \", abs(grid_SVR.best_score_))\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(\" \")\n",
    "print(\"Best parameters\")\n",
    "print (grid_SVR.best_params_)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Best estimator\")\n",
    "print (grid_SVR.best_estimator_)\n",
    "\n",
    "# predicting on test data\n",
    "SVR = grid_SVR.best_estimator_\n",
    "SVR.fit(X_train,y_train)\n",
    "y_pred = SVR.predict(X_test_holdout)\n",
    "\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "print('r2:',metrics.explained_variance_score(y_test_holdout, y_pred))\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble model : Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score achieved across all parameters:  94.91881209672553\n",
      " \n",
      "Best parameters\n",
      "{'bootstrap': True, 'max_depth': 3, 'max_features': 'auto', 'min_samples_split': 5, 'n_estimators': 500, 'n_jobs': -1}\n",
      " \n",
      "Best estimator\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=5,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 101.76641456829184\n",
      "Root Mean Squared Error: 181.0008807774893\n",
      "r2: 0.5048482374926706\n",
      " \n",
      "Time Taken =  362.21875\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "RF = ensemble.RandomForestRegressor()\n",
    "\n",
    "# Hyper parameter tuning using GridSearch\n",
    "param_set ={'max_depth': [3,10,20],\n",
    "            'min_samples_split' :[4,5,10],\n",
    "            'n_estimators': [100,250,500],\n",
    "            'bootstrap':[True, False] ,\n",
    "            'max_features':['auto','sqrt'],\n",
    "            'n_jobs':[-1]\n",
    "           }\n",
    "grid_RF = GridSearchCV(RF, param_grid = param_set, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_RF.fit(X_train,y_train)\n",
    "\n",
    "# examine the best model\n",
    "print(\"Best score achieved across all parameters: \", abs(grid_RF.best_score_))\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(\" \")\n",
    "print(\"Best parameters\")\n",
    "print (grid_RF.best_params_)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Best estimator\")\n",
    "print (grid_RF.best_estimator_)\n",
    "\n",
    "# predicting on test data\n",
    "RF = grid_RF.best_estimator_\n",
    "RF.fit(X_train,y_train)\n",
    "y_pred = RF.predict(X_test_holdout)\n",
    "\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "print('r2:',metrics.explained_variance_score(y_test_holdout, y_pred))\n",
    "print(\" \")\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble model : XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:37:32] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:34] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:34] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:34] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:34] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:34] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:34] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:34] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:34] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:34] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:34] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:34] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:34] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:34] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:35] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:35] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:35] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:35] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:35] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:35] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:35] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:36] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:36] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:36] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:36] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:36] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:36] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:36] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:36] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:36] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:37] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:37] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:37] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:37] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:37] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:37] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:39] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:39] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:39] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:39] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:39] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:39] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:39] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:39] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[00:37:39] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:37:39] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Best score achieved across all parameters:  96.13404741170245\n",
      " \n",
      "Best parameters\n",
      "{'colsample_bytree': 0.8594916060785803, 'gamma': 9.465277258470813, 'learning_rate': 0.2134110737570123, 'max_depth': 4, 'n_estimators': 34, 'n_jobs': -1, 'subsample': 0.9595729552178727}\n",
      " \n",
      "Best estimator\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bynode=1, colsample_bytree=0.8594916060785803,\n",
      "       gamma=9.465277258470813, importance_type='gain',\n",
      "       learning_rate=0.2134110737570123, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=1, missing=None, n_estimators=34, n_jobs=-1,\n",
      "       nthread=None, nthreads=-1, objective='reg:linear', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=None, subsample=0.9595729552178727, verbosity=1)\n",
      "[00:37:39] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Time Taken =  46.09375\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "XGB = xgboost.XGBRegressor(nthreads=-1)\n",
    "\n",
    "a = st.beta(10, 1)\n",
    "\n",
    "# Hyper parameter tuning using GridSearch\n",
    "param_set ={\"n_estimators\": st.randint(3, 40),\n",
    "            \"max_depth\": st.randint(3, 40),\n",
    "            \"learning_rate\": st.uniform(0.05, 0.4),\n",
    "            \"colsample_bytree\": a,\n",
    "            \"subsample\": a,\n",
    "            \"gamma\": st.uniform(0, 10),\n",
    "            'n_jobs':[-1]\n",
    "           }\n",
    "\n",
    "grid_XGB = RandomizedSearchCV(XGB, param_set, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_XGB.fit(X_train,y_train)\n",
    "\n",
    "# examine the best model\n",
    "print(\"Best score achieved across all parameters: \", abs(grid_XGB.best_score_))\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(\" \")\n",
    "print(\"Best parameters\")\n",
    "print (grid_XGB.best_params_)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Best estimator\")\n",
    "print (grid_XGB.best_estimator_)\n",
    "\n",
    "# predicting on test data\n",
    "XGB = grid_XGB.best_estimator_\n",
    "XGB.fit(X_train,y_train)\n",
    "y_pred = XGB.predict(X_test_holdout)\n",
    "\n",
    "# print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "# print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "# print('r2:',metrics.explained_variance_score(y_test_holdout, y_pred))\n",
    "# print(\" \")\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:37:40] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 106.70936235107423\n",
      "Root Mean Squared Error: 191.04454003178867\n",
      "r2: 0.4479237811179464\n"
     ]
    }
   ],
   "source": [
    "# predicting on test data\n",
    "XGB = grid_XGB.best_estimator_\n",
    "XGB.fit(X_train,y_train)\n",
    "y_pred = XGB.predict(X_test_holdout)\n",
    "\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "print('r2:',metrics.explained_variance_score(y_test_holdout, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shallow Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rckar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\rckar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 387us/step - loss: 201.5887 - mae: 201.5887 - mse: 83867.1172\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 201.0253 - mae: 201.0253 - mse: 83639.7188\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 200.3855 - mae: 200.3855 - mse: 83386.5234\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 199.5787 - mae: 199.5787 - mse: 83072.1875\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 198.5416 - mae: 198.5417 - mse: 82667.2734\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 197.2402 - mae: 197.2402 - mse: 82139.5156\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 195.6639 - mae: 195.6638 - mse: 81504.1797\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 193.8223 - mae: 193.8223 - mse: 80782.5938\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 191.7255 - mae: 191.7255 - mse: 79936.2969\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 189.3620 - mae: 189.3620 - mse: 79022.4531\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 186.7155 - mae: 186.7155 - mse: 77997.8047\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 183.7767 - mae: 183.7767 - mse: 76838.4219\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 180.5096 - mae: 180.5096 - mse: 75623.4297\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 176.9792 - mae: 176.9792 - mse: 74289.8594\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 173.2931 - mae: 173.2931 - mse: 72870.6016\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 169.5602 - mae: 169.5602 - mse: 71446.1094\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 165.9130 - mae: 165.9130 - mse: 69981.1562\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 162.2789 - mae: 162.2788 - mse: 68569.7969\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 44us/step - loss: 158.6467 - mae: 158.6467 - mse: 67146.6016\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - ETA: 0s - loss: 176.5082 - mae: 176.5082 - mse: 103154.46 - 0s 50us/step - loss: 155.0678 - mae: 155.0678 - mse: 65633.2031\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 151.5395 - mae: 151.5395 - mse: 64207.4805\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 148.0999 - mae: 148.0999 - mse: 62739.5742\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 144.6096 - mae: 144.6096 - mse: 61324.9727\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 141.2483 - mae: 141.2483 - mse: 59877.3320\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 138.1511 - mae: 138.1511 - mse: 58605.5391\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 135.1923 - mae: 135.1923 - mse: 57292.5352\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 132.5015 - mae: 132.5015 - mse: 56099.1523\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 129.9476 - mae: 129.9476 - mse: 54913.0117\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 127.5169 - mae: 127.5169 - mse: 53831.5117\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 125.4342 - mae: 125.4342 - mse: 52885.1016\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 123.8612 - mae: 123.8612 - mse: 52028.7031\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 122.5039 - mae: 122.5039 - mse: 51307.4023\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 121.4134 - mae: 121.4134 - mse: 50619.4414\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 120.6124 - mae: 120.6124 - mse: 50092.5430\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 119.9862 - mae: 119.9862 - mse: 49667.9258\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 119.5165 - mae: 119.5165 - mse: 49253.6523\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 119.1412 - mae: 119.1412 - mse: 48900.3984\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 118.9080 - mae: 118.9080 - mse: 48655.0664\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 118.7313 - mae: 118.7313 - mse: 48400.3438\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 118.5498 - mae: 118.5499 - mse: 48205.1836\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 118.3913 - mae: 118.3913 - mse: 48010.5664\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 118.2401 - mae: 118.2401 - mse: 47859.3789\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 118.1231 - mae: 118.1231 - mse: 47737.9453\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 118.0107 - mae: 118.0107 - mse: 47597.9453\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 117.9109 - mae: 117.9109 - mse: 47473.9570\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 117.8243 - mae: 117.8243 - mse: 47390.9414\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 117.7337 - mae: 117.7337 - mse: 47309.1094\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 117.6321 - mae: 117.6321 - mse: 47192.6055\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 117.5418 - mae: 117.5418 - mse: 47101.9922\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 117.4513 - mae: 117.4513 - mse: 47017.8711\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 117.3618 - mae: 117.3618 - mse: 46951.4648\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 49us/step - loss: 117.2736 - mae: 117.2736 - mse: 46887.3164\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 117.1904 - mae: 117.1904 - mse: 46840.3516\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 117.1027 - mae: 117.1027 - mse: 46785.3750\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 117.0304 - mae: 117.0304 - mse: 46693.3555\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 116.9370 - mae: 116.9370 - mse: 46616.2383\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 116.8612 - mae: 116.8612 - mse: 46604.8086\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 116.7790 - mae: 116.7790 - mse: 46543.9961\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 116.6886 - mae: 116.6886 - mse: 46472.9727\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 116.6105 - mae: 116.6105 - mse: 46422.1719\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 116.5155 - mae: 116.5155 - mse: 46391.3125\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 116.4367 - mae: 116.4367 - mse: 46358.4453\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 116.3664 - mae: 116.3664 - mse: 46360.2070\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 116.2692 - mae: 116.2692 - mse: 46302.0156\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 116.1944 - mae: 116.1944 - mse: 46224.6211\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 116.1020 - mae: 116.1020 - mse: 46183.7578\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 49us/step - loss: 116.0253 - mae: 116.0253 - mse: 46167.8086\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 115.9467 - mae: 115.9467 - mse: 46096.3203\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 115.8843 - mae: 115.8843 - mse: 46118.1641\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 115.7599 - mae: 115.7599 - mse: 46068.3672\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 115.6769 - mae: 115.6769 - mse: 46032.0039\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 115.5835 - mae: 115.5835 - mse: 45987.9141\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 115.4939 - mae: 115.4939 - mse: 45932.7891\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 115.4133 - mae: 115.4133 - mse: 45860.1641\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 115.3381 - mae: 115.3381 - mse: 45821.5391\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 115.2254 - mae: 115.2253 - mse: 45773.1211\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 115.1391 - mae: 115.1391 - mse: 45739.7148\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 115.0440 - mae: 115.0440 - mse: 45690.1992\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 114.9664 - mae: 114.9664 - mse: 45668.7656\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 114.8646 - mae: 114.8646 - mse: 45584.3125\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 114.7685 - mae: 114.7685 - mse: 45515.3281\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 114.6680 - mae: 114.6680 - mse: 45462.6484\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 114.5765 - mae: 114.5765 - mse: 45415.3516\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 114.4808 - mae: 114.4808 - mse: 45371.0625\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 114.3711 - mae: 114.3711 - mse: 45308.7617\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 114.2730 - mae: 114.2730 - mse: 45232.8750\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 114.1739 - mae: 114.1739 - mse: 45164.1836\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 114.0669 - mae: 114.0669 - mse: 45088.2539\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 113.9699 - mae: 113.9699 - mse: 45042.2617\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 113.8657 - mae: 113.8657 - mse: 44987.3555\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 113.7687 - mae: 113.7687 - mse: 44898.5586\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 113.6652 - mae: 113.6652 - mse: 44790.6055\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 113.5564 - mae: 113.5564 - mse: 44733.3984\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 113.4721 - mae: 113.4721 - mse: 44723.9727\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 113.3540 - mae: 113.3540 - mse: 44655.5352\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 113.2655 - mae: 113.2655 - mse: 44609.0430\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 113.1555 - mae: 113.1555 - mse: 44534.7617\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 113.0766 - mae: 113.0766 - mse: 44519.0117\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 112.9566 - mae: 112.9566 - mse: 44443.6641\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 112.8547 - mae: 112.8547 - mse: 44361.5977\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 388us/step - loss: 199.9895 - mae: 199.9895 - mse: 82695.0234\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 199.4135 - mae: 199.4135 - mse: 82468.1797\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 198.7713 - mae: 198.7713 - mse: 82214.8984\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 44us/step - loss: 197.9771 - mae: 197.9771 - mse: 81904.7969\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 196.9545 - mae: 196.9545 - mse: 81502.1016\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 195.6472 - mae: 195.6472 - mse: 80993.2891\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 194.0273 - mae: 194.0273 - mse: 80363.0156\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 192.0431 - mae: 192.0430 - mse: 79581.4609\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 189.6912 - mae: 189.6912 - mse: 78666.5312\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 186.9514 - mae: 186.9514 - mse: 77606.5391\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 183.8802 - mae: 183.8802 - mse: 76411.1406\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 180.4182 - mae: 180.4182 - mse: 75074.3750\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 176.5924 - mae: 176.5924 - mse: 73663.5234\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 172.5533 - mae: 172.5533 - mse: 72137.9609\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 168.4087 - mae: 168.4087 - mse: 70535.0000\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 164.1860 - mae: 164.1860 - mse: 68931.3125\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 160.1133 - mae: 160.1133 - mse: 67331.5234\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 155.9345 - mae: 155.9345 - mse: 65709.4531\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 152.0361 - mae: 152.0361 - mse: 64037.5938\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 148.3021 - mae: 148.3021 - mse: 62547.8203\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 144.6104 - mae: 144.6104 - mse: 60982.8477\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 140.8860 - mae: 140.8860 - mse: 59453.7344\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 137.2612 - mae: 137.2612 - mse: 58008.6797\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 133.9722 - mae: 133.9722 - mse: 56654.3320\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 130.8885 - mae: 130.8885 - mse: 55326.5781\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 128.0226 - mae: 128.0226 - mse: 54100.9844\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 125.5662 - mae: 125.5662 - mse: 53058.4609\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 123.2576 - mae: 123.2576 - mse: 52007.1445\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 121.6955 - mae: 121.6955 - mse: 51139.2148\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 120.3275 - mae: 120.3275 - mse: 50418.4219\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 119.3924 - mae: 119.3924 - mse: 49783.2656\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 48us/step - loss: 118.5970 - mae: 118.5970 - mse: 49274.3320\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 117.9960 - mae: 117.9960 - mse: 48790.7227\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 117.5783 - mae: 117.5783 - mse: 48434.7266\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 117.2921 - mae: 117.2921 - mse: 48138.2500\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 117.0759 - mae: 117.0759 - mse: 47897.6875\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 116.9036 - mae: 116.9036 - mse: 47697.1250\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 116.7456 - mae: 116.7456 - mse: 47503.7070\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 116.6104 - mae: 116.6104 - mse: 47339.3398\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 116.4768 - mae: 116.4769 - mse: 47220.5352\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 116.3683 - mae: 116.3682 - mse: 47097.9922\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 116.2577 - mae: 116.2577 - mse: 46992.9883\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 116.1517 - mae: 116.1517 - mse: 46913.5273\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 116.0501 - mae: 116.0501 - mse: 46797.6797\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 115.9507 - mae: 115.9507 - mse: 46679.5039\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 115.8589 - mae: 115.8589 - mse: 46639.9727\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 115.7750 - mae: 115.7750 - mse: 46572.6680\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 115.6891 - mae: 115.6891 - mse: 46538.0781\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 115.6011 - mae: 115.6011 - mse: 46490.6406\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 115.5131 - mae: 115.5131 - mse: 46423.9297\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 115.4236 - mae: 115.4236 - mse: 46380.2734\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 115.3380 - mae: 115.3380 - mse: 46337.9336\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 115.2561 - mae: 115.2561 - mse: 46299.6484\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 115.1756 - mae: 115.1756 - mse: 46258.4258\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 115.1021 - mae: 115.1021 - mse: 46239.3516\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 115.0204 - mae: 115.0204 - mse: 46202.1094\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 114.9267 - mae: 114.9267 - mse: 46106.6133\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 114.8502 - mae: 114.8502 - mse: 46035.2812\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 114.7738 - mae: 114.7738 - mse: 45990.4414\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 114.6894 - mae: 114.6894 - mse: 45953.8203\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 114.6070 - mae: 114.6070 - mse: 45924.2148\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 114.5223 - mae: 114.5223 - mse: 45892.7383\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 114.4369 - mae: 114.4369 - mse: 45865.7734\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 114.3551 - mae: 114.3551 - mse: 45838.4258\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 114.2762 - mae: 114.2761 - mse: 45809.9844\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 114.1928 - mae: 114.1928 - mse: 45777.7773\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 114.1052 - mae: 114.1052 - mse: 45733.7852\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 114.0317 - mae: 114.0317 - mse: 45681.5469\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 113.9491 - mae: 113.9491 - mse: 45620.9727\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 113.8835 - mae: 113.8835 - mse: 45584.2695\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 113.7899 - mae: 113.7899 - mse: 45521.8320\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 113.7079 - mae: 113.7079 - mse: 45483.3398\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 113.6219 - mae: 113.6219 - mse: 45432.3477\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 113.5393 - mae: 113.5393 - mse: 45417.8242\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 113.4536 - mae: 113.4536 - mse: 45381.2578\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 113.3686 - mae: 113.3686 - mse: 45330.2617\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 44us/step - loss: 113.2835 - mae: 113.2835 - mse: 45293.3438\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 49us/step - loss: 113.1902 - mae: 113.1902 - mse: 45265.1055\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 113.1119 - mae: 113.1119 - mse: 45210.4336\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - ETA: 0s - loss: 70.5948 - mae: 70.5948 - mse: 8192.62 - 0s 48us/step - loss: 113.0247 - mae: 113.0247 - mse: 45168.2500\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 112.9387 - mae: 112.9387 - mse: 45079.4648\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 112.8332 - mae: 112.8332 - mse: 45018.3633\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 112.7399 - mae: 112.7399 - mse: 45005.0391\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 112.6442 - mae: 112.6442 - mse: 44952.1133\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 112.5554 - mae: 112.5554 - mse: 44925.1875\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 112.4433 - mae: 112.4433 - mse: 44852.6250\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 112.3537 - mae: 112.3537 - mse: 44789.6914\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 112.2583 - mae: 112.2583 - mse: 44750.0977\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 112.1533 - mae: 112.1533 - mse: 44666.4570\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 112.0357 - mae: 112.0357 - mse: 44606.1914\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 111.9416 - mae: 111.9416 - mse: 44579.8516\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 111.8350 - mae: 111.8350 - mse: 44508.6797\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 111.7451 - mae: 111.7450 - mse: 44475.1719\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 111.6383 - mae: 111.6383 - mse: 44402.5547\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 111.5415 - mae: 111.5415 - mse: 44342.8438\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 111.4582 - mae: 111.4582 - mse: 44221.1797\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 111.3538 - mae: 111.3538 - mse: 44234.9531\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 111.2615 - mae: 111.2615 - mse: 44180.3242\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 111.1303 - mae: 111.1303 - mse: 44083.4766\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 111.0386 - mae: 111.0386 - mse: 44091.5938\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 419us/step - loss: 199.5950 - mae: 199.5950 - mse: 83722.0234\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 198.9807 - mae: 198.9807 - mse: 83476.6250\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 198.2327 - mae: 198.2327 - mse: 83190.3906\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 197.2469 - mae: 197.2469 - mse: 82801.7656\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 195.9600 - mae: 195.9599 - mse: 82313.1719\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 194.3273 - mae: 194.3273 - mse: 81670.9453\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 192.3513 - mae: 192.3513 - mse: 80897.3438\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 190.0627 - mae: 190.0626 - mse: 80025.1875\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 187.4928 - mae: 187.4927 - mse: 79025.5703\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 184.6285 - mae: 184.6285 - mse: 77927.5078\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 181.4191 - mae: 181.4191 - mse: 76680.7344\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 177.9213 - mae: 177.9212 - mse: 75423.0938\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 174.0254 - mae: 174.0254 - mse: 73926.2422\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 170.1231 - mae: 170.1231 - mse: 72436.6172\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 166.1832 - mae: 166.1832 - mse: 70952.3438\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 162.2902 - mae: 162.2902 - mse: 69415.6406\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 158.5339 - mae: 158.5339 - mse: 67904.7422\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 154.8647 - mae: 154.8647 - mse: 66363.3516\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 151.3128 - mae: 151.3128 - mse: 64877.7070\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 147.8690 - mae: 147.8690 - mse: 63436.8125\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 44us/step - loss: 144.4066 - mae: 144.4066 - mse: 61972.4648\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 141.0878 - mae: 141.0878 - mse: 60586.7812\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 137.9298 - mae: 137.9298 - mse: 59258.3672\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 135.0888 - mae: 135.0888 - mse: 57952.6133\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 132.2325 - mae: 132.2325 - mse: 56747.5195\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 129.9547 - mae: 129.9548 - mse: 55596.4570\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 127.7865 - mae: 127.7865 - mse: 54630.6680\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 125.8650 - mae: 125.8650 - mse: 53672.9258\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 124.5618 - mae: 124.5618 - mse: 52865.6055\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 123.2746 - mae: 123.2746 - mse: 52138.8516\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 122.3112 - mae: 122.3112 - mse: 51548.5117\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 121.5785 - mae: 121.5785 - mse: 50982.1914\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 121.0074 - mae: 121.0074 - mse: 50483.7031\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 120.5402 - mae: 120.5402 - mse: 50066.3516\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 120.2335 - mae: 120.2335 - mse: 49742.3867\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 120.0200 - mae: 120.0200 - mse: 49497.9414\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 44us/step - loss: 119.8492 - mae: 119.8492 - mse: 49300.5703\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 119.7307 - mae: 119.7307 - mse: 49131.1719\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 119.5901 - mae: 119.5900 - mse: 48982.0664\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 119.4786 - mae: 119.4786 - mse: 48851.1016\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 49us/step - loss: 119.3443 - mae: 119.3443 - mse: 48704.1172\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 119.2587 - mae: 119.2586 - mse: 48544.6602\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 119.0986 - mae: 119.0986 - mse: 48394.3672\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 118.9883 - mae: 118.9883 - mse: 48299.1914\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 118.8836 - mae: 118.8836 - mse: 48176.7383\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 118.7902 - mae: 118.7902 - mse: 48089.2227\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 118.6941 - mae: 118.6941 - mse: 48010.0117\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 118.5948 - mae: 118.5948 - mse: 47932.0898\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 118.5096 - mae: 118.5096 - mse: 47828.4062\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 118.4015 - mae: 118.4016 - mse: 47735.9336\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 118.3045 - mae: 118.3045 - mse: 47703.7852\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 118.2272 - mae: 118.2272 - mse: 47598.6055\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 118.1134 - mae: 118.1134 - mse: 47543.5195\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 118.0250 - mae: 118.0250 - mse: 47482.5977\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 117.9307 - mae: 117.9307 - mse: 47414.0898\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 117.8394 - mae: 117.8394 - mse: 47372.6211\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 117.7466 - mae: 117.7466 - mse: 47295.2031\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 117.6722 - mae: 117.6722 - mse: 47271.2148\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 117.5650 - mae: 117.5650 - mse: 47197.1055\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 117.4739 - mae: 117.4740 - mse: 47126.3398\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 117.3804 - mae: 117.3804 - mse: 47080.6836\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 117.2981 - mae: 117.2981 - mse: 47009.6328\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 117.1885 - mae: 117.1885 - mse: 46960.3125\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 117.1015 - mae: 117.1015 - mse: 46934.7656\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 117.0266 - mae: 117.0266 - mse: 46849.7461\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 116.9117 - mae: 116.9117 - mse: 46808.7656\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 49us/step - loss: 116.8396 - mae: 116.8396 - mse: 46752.2852\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 116.7360 - mae: 116.7360 - mse: 46739.8711\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 116.6309 - mae: 116.6309 - mse: 46714.6797\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 116.5366 - mae: 116.5366 - mse: 46648.1719\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 116.4413 - mae: 116.4413 - mse: 46588.9102\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 116.3606 - mae: 116.3606 - mse: 46501.1641\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 116.2654 - mae: 116.2654 - mse: 46462.9297\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 116.1694 - mae: 116.1694 - mse: 46410.3086\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 116.0694 - mae: 116.0694 - mse: 46305.8516\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 115.9716 - mae: 115.9716 - mse: 46262.3555\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 115.8797 - mae: 115.8797 - mse: 46217.6133\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 115.7839 - mae: 115.7839 - mse: 46135.6484\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 115.6845 - mae: 115.6845 - mse: 46034.2422\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 115.5974 - mae: 115.5974 - mse: 46018.0234\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 115.4816 - mae: 115.4816 - mse: 45985.7188\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 115.3800 - mae: 115.3800 - mse: 45880.5781\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 115.2754 - mae: 115.2754 - mse: 45821.3086\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 115.1712 - mae: 115.1712 - mse: 45767.4961\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 115.0682 - mae: 115.0682 - mse: 45727.1406\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 114.9627 - mae: 114.9627 - mse: 45671.3867\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 114.8564 - mae: 114.8564 - mse: 45621.2305\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 114.7455 - mae: 114.7455 - mse: 45549.2812\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 114.6344 - mae: 114.6344 - mse: 45481.0430\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 49us/step - loss: 114.5324 - mae: 114.5324 - mse: 45441.5000\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 114.4156 - mae: 114.4156 - mse: 45347.4570\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 114.3035 - mae: 114.3035 - mse: 45279.1875\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 114.2051 - mae: 114.2051 - mse: 45196.2188\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 114.0799 - mae: 114.0799 - mse: 45110.0234\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 113.9797 - mae: 113.9797 - mse: 45086.9375\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 113.8534 - mae: 113.8534 - mse: 45030.5938\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 113.7342 - mae: 113.7342 - mse: 44932.8984\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 113.6231 - mae: 113.6231 - mse: 44869.9883\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 113.4881 - mae: 113.4881 - mse: 44764.3789\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 113.3754 - mae: 113.3754 - mse: 44683.1797\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 430us/step - loss: 203.8012 - mae: 203.8012 - mse: 85033.9922\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 203.2100 - mae: 203.2100 - mse: 84796.9922\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 202.5245 - mae: 202.5245 - mse: 84517.9609\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 201.6664 - mae: 201.6664 - mse: 84178.0859\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 200.5483 - mae: 200.5483 - mse: 83731.0625\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 199.1639 - mae: 199.1639 - mse: 83162.7734\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 197.5011 - mae: 197.5011 - mse: 82515.8359\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 195.5412 - mae: 195.5412 - mse: 81712.5391\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 193.3221 - mae: 193.3221 - mse: 80825.5859\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 190.8246 - mae: 190.8245 - mse: 79825.2578\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 188.0191 - mae: 188.0191 - mse: 78757.1016\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 184.9583 - mae: 184.9583 - mse: 77565.1016\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 181.5249 - mae: 181.5249 - mse: 76205.5703\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 177.8368 - mae: 177.8368 - mse: 74826.5312\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 174.0277 - mae: 174.0277 - mse: 73373.6562\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 170.1489 - mae: 170.1489 - mse: 71887.5469\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 166.3563 - mae: 166.3563 - mse: 70349.5547\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 162.6216 - mae: 162.6216 - mse: 68839.8672\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 158.8813 - mae: 158.8813 - mse: 67340.5391\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 155.2279 - mae: 155.2279 - mse: 65827.3594\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 151.6499 - mae: 151.6499 - mse: 64372.0586\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 147.9995 - mae: 147.9995 - mse: 62920.9609\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 144.5268 - mae: 144.5268 - mse: 61453.8672\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 141.0930 - mae: 141.0930 - mse: 60042.9727\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 137.8957 - mae: 137.8957 - mse: 58727.0859\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 134.9443 - mae: 134.9443 - mse: 57395.3398\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 132.1901 - mae: 132.1900 - mse: 56190.1055\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 129.7320 - mae: 129.7320 - mse: 55104.4531\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 127.4548 - mae: 127.4548 - mse: 54019.4023\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 125.5400 - mae: 125.5400 - mse: 53098.6914\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 124.0147 - mae: 124.0147 - mse: 52286.4023\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 122.6645 - mae: 122.6646 - mse: 51534.9727\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 121.7139 - mae: 121.7139 - mse: 50920.5742\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 120.8310 - mae: 120.8310 - mse: 50392.7188\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 120.2209 - mae: 120.2209 - mse: 49912.1719\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 119.7794 - mae: 119.7794 - mse: 49499.9805\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 49us/step - loss: 119.3861 - mae: 119.3861 - mse: 49180.1562\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 119.0994 - mae: 119.0994 - mse: 48880.4336\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 118.8345 - mae: 118.8345 - mse: 48654.1680\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 118.6269 - mae: 118.6269 - mse: 48416.0898\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 118.4334 - mae: 118.4334 - mse: 48200.1680\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 118.2647 - mae: 118.2647 - mse: 47996.4453\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 118.0944 - mae: 118.0944 - mse: 47839.5586\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 117.9649 - mae: 117.9650 - mse: 47722.2695\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 117.8314 - mae: 117.8314 - mse: 47594.5586\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 117.7338 - mae: 117.7338 - mse: 47467.3477\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 117.6198 - mae: 117.6198 - mse: 47370.3828\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 117.5084 - mae: 117.5084 - mse: 47319.8477\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 117.4134 - mae: 117.4135 - mse: 47285.9766\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 117.3082 - mae: 117.3082 - mse: 47233.1641\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 117.2223 - mae: 117.2223 - mse: 47135.6211\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 117.1082 - mae: 117.1082 - mse: 47051.4023\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 117.0152 - mae: 117.0152 - mse: 47026.4414\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 116.9174 - mae: 116.9174 - mse: 46967.8242\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 116.8290 - mae: 116.8290 - mse: 46924.1914\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 116.7368 - mae: 116.7368 - mse: 46863.6953\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - ETA: 0s - loss: 75.2461 - mae: 75.2461 - mse: 8896.11 - 0s 57us/step - loss: 116.6598 - mae: 116.6598 - mse: 46787.9961\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 116.5525 - mae: 116.5525 - mse: 46734.7188\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 116.4622 - mae: 116.4622 - mse: 46710.5977\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 116.3637 - mae: 116.3637 - mse: 46659.2500\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 116.2738 - mae: 116.2738 - mse: 46561.8789\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 116.1760 - mae: 116.1760 - mse: 46508.9609\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 116.0751 - mae: 116.0751 - mse: 46453.9648\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 115.9789 - mae: 115.9789 - mse: 46389.1719\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 115.8637 - mae: 115.8637 - mse: 46322.8281\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 115.7630 - mae: 115.7630 - mse: 46262.5312\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 115.6610 - mae: 115.6610 - mse: 46196.1797\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 115.5462 - mae: 115.5462 - mse: 46133.7969\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 115.4450 - mae: 115.4450 - mse: 46065.8516\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 115.3396 - mae: 115.3396 - mse: 46022.6172\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 115.2336 - mae: 115.2336 - mse: 45950.0586\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 115.1203 - mae: 115.1203 - mse: 45871.9297\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 115.0106 - mae: 115.0106 - mse: 45807.5859\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 114.9060 - mae: 114.9060 - mse: 45729.8281\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 114.7764 - mae: 114.7764 - mse: 45664.9727\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 114.6832 - mae: 114.6832 - mse: 45592.3516\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 114.5583 - mae: 114.5583 - mse: 45538.8906\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 114.4632 - mae: 114.4632 - mse: 45521.2578\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 114.3303 - mae: 114.3303 - mse: 45394.8086\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 114.2069 - mae: 114.2069 - mse: 45299.6484\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 114.0955 - mae: 114.0955 - mse: 45270.8477\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 113.9732 - mae: 113.9732 - mse: 45215.7500\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 113.8664 - mae: 113.8664 - mse: 45174.9453\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 113.7423 - mae: 113.7423 - mse: 45087.6016\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 113.6601 - mae: 113.6601 - mse: 45068.4219\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 113.5044 - mae: 113.5044 - mse: 44993.2148\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 54us/step - loss: 113.4019 - mae: 113.4019 - mse: 44889.4805\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 113.2975 - mae: 113.2975 - mse: 44841.8906\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 113.1762 - mae: 113.1762 - mse: 44785.1797\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 113.0492 - mae: 113.0492 - mse: 44722.3945\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 112.9392 - mae: 112.9392 - mse: 44663.6875\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 112.8277 - mae: 112.8277 - mse: 44611.7734\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 112.7147 - mae: 112.7147 - mse: 44538.2695\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 49us/step - loss: 112.6192 - mae: 112.6192 - mse: 44521.3359\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 112.4755 - mae: 112.4755 - mse: 44463.4648\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 112.3593 - mae: 112.3593 - mse: 44377.7461\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 112.2438 - mae: 112.2438 - mse: 44300.1641\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 112.1422 - mae: 112.1422 - mse: 44254.3164\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 112.0219 - mae: 112.0219 - mse: 44188.9414\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 111.9058 - mae: 111.9058 - mse: 44100.8906\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 434us/step - loss: 194.3074 - mae: 194.3074 - mse: 78338.5234\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 52us/step - loss: 193.6333 - mae: 193.6333 - mse: 78081.7656\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 192.8992 - mae: 192.8992 - mse: 77799.1719\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 192.0066 - mae: 192.0066 - mse: 77457.8516\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 190.8761 - mae: 190.8761 - mse: 77039.8203\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 189.4893 - mae: 189.4894 - mse: 76506.8672\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 187.7790 - mae: 187.7790 - mse: 75864.9844\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 185.7518 - mae: 185.7517 - mse: 75096.5781\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 183.4865 - mae: 183.4865 - mse: 74230.0078\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 180.9768 - mae: 180.9768 - mse: 73258.7266\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 178.1923 - mae: 178.1924 - mse: 72212.1250\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 175.1519 - mae: 175.1519 - mse: 71099.1641\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 171.8371 - mae: 171.8371 - mse: 69891.0547\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 168.2671 - mae: 168.2671 - mse: 68634.3750\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 164.6903 - mae: 164.6903 - mse: 67290.8281\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 49us/step - loss: 161.0589 - mae: 161.0589 - mse: 65929.5469\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 157.5641 - mae: 157.5641 - mse: 64604.2070\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 154.1292 - mae: 154.1292 - mse: 63343.9336\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 150.7769 - mae: 150.7769 - mse: 61947.4922\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 147.5421 - mae: 147.5421 - mse: 60620.6328\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 144.2731 - mae: 144.2731 - mse: 59359.2070\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 141.0008 - mae: 141.0008 - mse: 58058.1875\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 137.8933 - mae: 137.8933 - mse: 56777.2266\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 134.7363 - mae: 134.7363 - mse: 55577.4414\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 131.8335 - mae: 131.8335 - mse: 54325.4062\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 128.9887 - mae: 128.9887 - mse: 53177.4688\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 126.3463 - mae: 126.3463 - mse: 52094.9961\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 124.0231 - mae: 124.0230 - mse: 51098.2188\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 121.8775 - mae: 121.8775 - mse: 50140.1719\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 120.1737 - mae: 120.1737 - mse: 49316.9531\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 118.7446 - mae: 118.7446 - mse: 48574.1211\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 117.5273 - mae: 117.5273 - mse: 47924.7266\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 116.5761 - mae: 116.5761 - mse: 47358.1836\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 115.8599 - mae: 115.8599 - mse: 46908.2461\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 115.1960 - mae: 115.1960 - mse: 46446.4531\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 114.6382 - mae: 114.6382 - mse: 46073.9375\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 114.2712 - mae: 114.2712 - mse: 45734.4844\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 113.9679 - mae: 113.9679 - mse: 45489.0898\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 113.7654 - mae: 113.7653 - mse: 45254.5781\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 113.6003 - mae: 113.6003 - mse: 45045.8984\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 49us/step - loss: 113.4049 - mae: 113.4049 - mse: 44892.1484\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 113.2643 - mae: 113.2643 - mse: 44719.0312\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 113.1246 - mae: 113.1246 - mse: 44560.2383\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 113.0156 - mae: 113.0156 - mse: 44447.7617\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 112.9245 - mae: 112.9245 - mse: 44347.9258\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 112.8359 - mae: 112.8359 - mse: 44248.3516\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 112.7545 - mae: 112.7545 - mse: 44180.8125\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 112.6795 - mae: 112.6795 - mse: 44097.7383\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 112.5960 - mae: 112.5960 - mse: 44046.7344\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 112.5140 - mae: 112.5140 - mse: 43995.8750\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 112.4374 - mae: 112.4374 - mse: 43919.3633\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 112.3576 - mae: 112.3575 - mse: 43849.9023\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 112.2868 - mae: 112.2868 - mse: 43779.3203\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 112.2052 - mae: 112.2052 - mse: 43732.1914\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 112.1404 - mae: 112.1404 - mse: 43657.8398\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 112.0563 - mae: 112.0563 - mse: 43595.7852\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 111.9861 - mae: 111.9861 - mse: 43545.9258\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 111.9277 - mae: 111.9277 - mse: 43528.2148\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 111.8394 - mae: 111.8394 - mse: 43496.2539\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 111.7623 - mae: 111.7623 - mse: 43450.8438\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 111.6961 - mae: 111.6961 - mse: 43395.2539\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 111.6173 - mae: 111.6173 - mse: 43340.9688\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 111.5494 - mae: 111.5494 - mse: 43321.5234\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 111.4797 - mae: 111.4797 - mse: 43270.9531\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 111.4141 - mae: 111.4141 - mse: 43269.0195\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 111.3278 - mae: 111.3278 - mse: 43239.2969\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 111.2642 - mae: 111.2642 - mse: 43175.9375\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 49us/step - loss: 111.1869 - mae: 111.1869 - mse: 43149.9453\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 111.1207 - mae: 111.1207 - mse: 43148.0156\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 111.0494 - mae: 111.0494 - mse: 43118.1523\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 110.9751 - mae: 110.9751 - mse: 43063.2305\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 110.9042 - mae: 110.9042 - mse: 43018.1406\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 110.8692 - mae: 110.8692 - mse: 42947.6875\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 110.7662 - mae: 110.7662 - mse: 42930.5000\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 110.6940 - mae: 110.6940 - mse: 42908.0938\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 110.6382 - mae: 110.6382 - mse: 42908.9023\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 110.5602 - mae: 110.5602 - mse: 42849.2148\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 110.4846 - mae: 110.4846 - mse: 42796.7656\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 110.4142 - mae: 110.4142 - mse: 42770.0742\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 49us/step - loss: 110.3414 - mae: 110.3414 - mse: 42762.8281\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 110.2789 - mae: 110.2789 - mse: 42698.0898\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 110.2102 - mae: 110.2102 - mse: 42662.6016\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 110.1386 - mae: 110.1386 - mse: 42625.6914\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 110.0704 - mae: 110.0704 - mse: 42572.6211\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 109.9948 - mae: 109.9948 - mse: 42534.6172\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 109.9342 - mae: 109.9342 - mse: 42534.4375\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 109.8682 - mae: 109.8682 - mse: 42496.0781\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 109.7944 - mae: 109.7945 - mse: 42448.5469\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 109.7380 - mae: 109.7380 - mse: 42375.5000\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 109.6631 - mae: 109.6631 - mse: 42357.7852\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 109.5861 - mae: 109.5861 - mse: 42307.4805\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 109.5238 - mae: 109.5238 - mse: 42235.4648\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 109.4455 - mae: 109.4455 - mse: 42173.6562\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 109.3769 - mae: 109.3769 - mse: 42140.9258\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 49us/step - loss: 109.3045 - mae: 109.3045 - mse: 42102.4883\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 109.2440 - mae: 109.2440 - mse: 42066.2383\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 109.1593 - mae: 109.1593 - mse: 42031.6797\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 109.0843 - mae: 109.0843 - mse: 41970.9258\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 109.0057 - mae: 109.0057 - mse: 41903.6250\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 108.9599 - mae: 108.9599 - mse: 41816.4414\n",
      "Epoch 1/100\n",
      "750/750 [==============================] - 0s 349us/step - loss: 199.7550 - mae: 199.7550 - mse: 82693.1797\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 198.9683 - mae: 198.9683 - mse: 82385.2109\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 197.9907 - mae: 197.9907 - mse: 81997.8672\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 196.6638 - mae: 196.6638 - mse: 81474.3125\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 194.9076 - mae: 194.9076 - mse: 80772.5312\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 192.6855 - mae: 192.6855 - mse: 79930.0391\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 190.0563 - mae: 190.0563 - mse: 78889.0000\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 187.0193 - mae: 187.0193 - mse: 77699.6484\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 183.5569 - mae: 183.5569 - mse: 76367.1719\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 179.5610 - mae: 179.5610 - mse: 74848.4609\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 175.0531 - mae: 175.0531 - mse: 73125.5000\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 170.2580 - mae: 170.2580 - mse: 71336.0312\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 165.4337 - mae: 165.4337 - mse: 69485.4922\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 160.7602 - mae: 160.7602 - mse: 67611.7734\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 156.0343 - mae: 156.0343 - mse: 65739.5938\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 151.5462 - mae: 151.5462 - mse: 63909.6055\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 147.2236 - mae: 147.2236 - mse: 62134.4648\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 0s 50us/step - loss: 142.8902 - mae: 142.8902 - mse: 60348.8320\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 0s 50us/step - loss: 138.7455 - mae: 138.7455 - mse: 58641.6680\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 134.8403 - mae: 134.8403 - mse: 56964.1992\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 131.3307 - mae: 131.3307 - mse: 55445.5898\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 128.1337 - mae: 128.1337 - mse: 54063.0039\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 125.3354 - mae: 125.3354 - mse: 52811.6172\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 123.1611 - mae: 123.1611 - mse: 51693.6836\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 121.5410 - mae: 121.5410 - mse: 50732.2031\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 120.1556 - mae: 120.1556 - mse: 49926.6680\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 119.2815 - mae: 119.2815 - mse: 49320.2148\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 118.6022 - mae: 118.6022 - mse: 48754.4805\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 118.1077 - mae: 118.1077 - mse: 48378.3320\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 117.8378 - mae: 117.8378 - mse: 48007.8555\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 117.5901 - mae: 117.5901 - mse: 47730.9219\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 117.3865 - mae: 117.3865 - mse: 47538.5977\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 117.2217 - mae: 117.2217 - mse: 47321.2656\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 117.0677 - mae: 117.0677 - mse: 47157.1523\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 116.9431 - mae: 116.9431 - mse: 47013.0781\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 116.8258 - mae: 116.8258 - mse: 46918.6172\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 116.7112 - mae: 116.7112 - mse: 46801.7109\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 48us/step - loss: 116.6073 - mae: 116.6073 - mse: 46676.5156\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 116.4824 - mae: 116.4824 - mse: 46552.0898\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 116.3619 - mae: 116.3619 - mse: 46483.5234\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 116.2503 - mae: 116.2503 - mse: 46388.6406\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 116.1407 - mae: 116.1407 - mse: 46321.7812\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 116.0448 - mae: 116.0447 - mse: 46219.2305\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 115.9298 - mae: 115.9298 - mse: 46161.5586\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 115.8360 - mae: 115.8360 - mse: 46111.4258\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 115.7441 - mae: 115.7441 - mse: 46107.0703\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 115.6262 - mae: 115.6262 - mse: 46038.1328\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 115.5268 - mae: 115.5268 - mse: 45963.5469\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 115.4305 - mae: 115.4305 - mse: 45906.0742\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 0s 46us/step - loss: 115.3329 - mae: 115.3329 - mse: 45859.8516\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 115.2285 - mae: 115.2286 - mse: 45805.1562\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 115.1339 - mae: 115.1339 - mse: 45753.0781\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 115.0435 - mae: 115.0435 - mse: 45689.8555\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 114.9321 - mae: 114.9321 - mse: 45670.0586\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 114.8378 - mae: 114.8378 - mse: 45594.6094\n",
      "Epoch 56/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 114.7512 - mae: 114.7512 - mse: 45569.9844\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 114.6387 - mae: 114.6387 - mse: 45528.5977\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 114.5448 - mae: 114.5448 - mse: 45450.3555\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 114.4460 - mae: 114.4460 - mse: 45419.7070\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 114.3566 - mae: 114.3566 - mse: 45314.2305\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 114.2678 - mae: 114.2678 - mse: 45293.1133\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 114.1615 - mae: 114.1614 - mse: 45203.7031\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 114.0631 - mae: 114.0631 - mse: 45141.7500\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 113.9612 - mae: 113.9612 - mse: 45076.6562\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 113.8581 - mae: 113.8581 - mse: 45026.7930\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 113.7629 - mae: 113.7629 - mse: 44995.5508\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 113.6566 - mae: 113.6566 - mse: 44923.3984\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 113.5589 - mae: 113.5589 - mse: 44849.0391\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 113.4408 - mae: 113.4408 - mse: 44769.5156\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 113.3300 - mae: 113.3300 - mse: 44765.8125\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 113.2303 - mae: 113.2302 - mse: 44683.6250\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 113.1058 - mae: 113.1058 - mse: 44639.2891\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 0s 50us/step - loss: 113.0061 - mae: 113.0061 - mse: 44516.8203\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 112.8650 - mae: 112.8649 - mse: 44475.3281\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 112.7246 - mae: 112.7246 - mse: 44384.9180\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 112.5938 - mae: 112.5938 - mse: 44282.2383\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 112.4701 - mae: 112.4702 - mse: 44193.4570\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 112.3426 - mae: 112.3426 - mse: 44096.6250\n",
      "Epoch 79/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 112.2008 - mae: 112.2008 - mse: 44043.8789\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 112.0800 - mae: 112.0800 - mse: 44017.7188\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 111.9474 - mae: 111.9474 - mse: 43948.9453\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 111.8053 - mae: 111.8053 - mse: 43847.2891\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 111.6690 - mae: 111.6691 - mse: 43722.2734\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 111.5492 - mae: 111.5492 - mse: 43585.5938\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 111.4047 - mae: 111.4047 - mse: 43496.7852\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 111.2686 - mae: 111.2686 - mse: 43477.1875\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 111.1768 - mae: 111.1768 - mse: 43499.0352\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 111.0089 - mae: 111.0089 - mse: 43313.8281\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 110.8572 - mae: 110.8572 - mse: 43155.5234\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 110.7210 - mae: 110.7210 - mse: 43107.3555\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 110.5909 - mae: 110.5909 - mse: 43010.0391\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 0s 50us/step - loss: 110.4494 - mae: 110.4493 - mse: 42933.3359\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 110.3219 - mae: 110.3219 - mse: 42889.5469\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 110.1791 - mae: 110.1791 - mse: 42803.8047\n",
      "Epoch 95/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 110.0711 - mae: 110.0711 - mse: 42751.8359\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 109.8954 - mae: 109.8954 - mse: 42665.7578\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 109.7797 - mae: 109.7797 - mse: 42483.8867\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 109.6336 - mae: 109.6336 - mse: 42452.5859\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 109.4843 - mae: 109.4843 - mse: 42403.7773\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 109.3551 - mae: 109.3551 - mse: 42315.6250\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=44, activation = 'relu', input_dim=22))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error',  metrics=['mae','mse'])\n",
    "    return model\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "NN_Regressor = KerasRegressor(build_fn=build_model, batch_size=40,epochs=100)    \n",
    "\n",
    "scores = cross_val_score(NN_Regressor, X_train, y_train, cv=5, scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "NN = NN_Regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the scores for each model run\n",
      "[-108.60291955 -115.56424163 -104.61176985 -109.91084491 -129.1727929 ]\n",
      " \n",
      "Mean and variance: 113.57 (+/- 17.11)\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 132.336899041748\n",
      "Root Mean Squared Error: 65480.48822352548\n",
      "Time Taken =  54.1875\n"
     ]
    }
   ],
   "source": [
    "print(\"Below are the scores for each model run\")\n",
    "print(scores)\n",
    "print(\" \")\n",
    "print(\"Mean and variance: %0.2f (+/- %0.2f)\" % (abs(scores.mean()), scores.std() * 2))\n",
    "\n",
    "y_pred= NN_Regressor.predict(X_test_holdout)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', metrics.mean_squared_error(y_test_holdout, y_pred))\n",
    "\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Medium Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 521us/step - loss: 201.6505 - mae: 201.6505 - mse: 83891.0000\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 201.0971 - mae: 201.0971 - mse: 83666.3281\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 200.4282 - mae: 200.4281 - mse: 83385.2969\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 199.4010 - mae: 199.4011 - mse: 82998.7891\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 197.7650 - mae: 197.7650 - mse: 82341.0469\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 195.3042 - mae: 195.3042 - mse: 81345.4766\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 191.7153 - mae: 191.7153 - mse: 79950.7031\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 186.6175 - mae: 186.6175 - mse: 77933.9766\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 179.6943 - mae: 179.6943 - mse: 75268.4219\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 171.0046 - mae: 171.0047 - mse: 72055.1016\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 161.3226 - mae: 161.3227 - mse: 68161.8438\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 151.0911 - mae: 151.0911 - mse: 64055.0938\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 140.8446 - mae: 140.8446 - mse: 59849.5938\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 131.9044 - mae: 131.9044 - mse: 55693.6758\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 124.5054 - mae: 124.5054 - mse: 52349.0078\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 59us/step - loss: 120.4985 - mae: 120.4985 - mse: 49861.8984\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 119.0319 - mae: 119.0319 - mse: 48348.9609\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 118.6180 - mae: 118.6180 - mse: 47667.4805\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 118.3606 - mae: 118.3606 - mse: 47336.3555\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 118.1229 - mae: 118.1229 - mse: 47158.5859\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 117.9007 - mae: 117.9007 - mse: 47000.5508\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 117.7055 - mae: 117.7055 - mse: 46812.6484\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 117.4814 - mae: 117.4814 - mse: 46726.3438\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 56us/step - loss: 117.2528 - mae: 117.2528 - mse: 46603.1055\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 117.0350 - mae: 117.0350 - mse: 46467.2773\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 116.8478 - mae: 116.8478 - mse: 46406.3906\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 116.6027 - mae: 116.6027 - mse: 46285.1562\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 116.3890 - mae: 116.3890 - mse: 46114.6133\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 116.2260 - mae: 116.2260 - mse: 45921.2109\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 116.0002 - mae: 116.0002 - mse: 45945.0586\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 115.7882 - mae: 115.7882 - mse: 45956.4727\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 115.6028 - mae: 115.6028 - mse: 45805.6172\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 115.3525 - mae: 115.3525 - mse: 45632.9414\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 115.1467 - mae: 115.1467 - mse: 45540.5977\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 114.9486 - mae: 114.9486 - mse: 45453.7305\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 114.7420 - mae: 114.7419 - mse: 45225.8164\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 114.5215 - mae: 114.5215 - mse: 45016.1367\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 114.3436 - mae: 114.3436 - mse: 45094.1367\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 114.0752 - mae: 114.0752 - mse: 44950.1719\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 113.8503 - mae: 113.8503 - mse: 44693.5352\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 113.6434 - mae: 113.6434 - mse: 44471.0352\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 113.3941 - mae: 113.3941 - mse: 44377.8281\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 113.2102 - mae: 113.2102 - mse: 44329.8242\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 112.9822 - mae: 112.9821 - mse: 44096.3281\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 112.7619 - mae: 112.7619 - mse: 43999.5039\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 112.5208 - mae: 112.5208 - mse: 43908.1055\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 112.2705 - mae: 112.2705 - mse: 43835.4883\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 112.0327 - mae: 112.0327 - mse: 43620.4180\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 111.8063 - mae: 111.8064 - mse: 43424.6484\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 111.5454 - mae: 111.5454 - mse: 43296.6289\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 111.3416 - mae: 111.3416 - mse: 43279.9219\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 128us/step - loss: 111.0866 - mae: 111.0866 - mse: 43153.3906\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 135us/step - loss: 110.8646 - mae: 110.8646 - mse: 42833.7695\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 110.6684 - mae: 110.6684 - mse: 42903.4180\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 110.3393 - mae: 110.3393 - mse: 42702.7969\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 110.0767 - mae: 110.0767 - mse: 42356.3984\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 109.8116 - mae: 109.8116 - mse: 42371.5586\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 109.5672 - mae: 109.5672 - mse: 42294.4570\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 109.3335 - mae: 109.3335 - mse: 42030.7461\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 75us/step - loss: 109.1354 - mae: 109.1354 - mse: 41939.1914\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 108.8409 - mae: 108.8409 - mse: 41792.3750\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 108.6119 - mae: 108.6119 - mse: 41452.0078\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 108.3342 - mae: 108.3342 - mse: 41324.3008\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 108.0979 - mae: 108.0979 - mse: 41212.1562\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 107.8329 - mae: 107.8329 - mse: 41139.4219\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 107.5781 - mae: 107.5781 - mse: 40842.5430\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 107.3828 - mae: 107.3828 - mse: 40838.0352\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 107.0580 - mae: 107.0580 - mse: 40479.4922\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 106.7612 - mae: 106.7612 - mse: 40308.0117\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 106.4879 - mae: 106.4879 - mse: 40180.5273\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 106.2359 - mae: 106.2359 - mse: 39886.0234\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 105.9199 - mae: 105.9199 - mse: 39765.1094\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 105.6345 - mae: 105.6345 - mse: 39595.9258\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 105.3248 - mae: 105.3248 - mse: 39327.1289\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 105.0200 - mae: 105.0200 - mse: 39045.4531\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 104.8047 - mae: 104.8047 - mse: 39129.2969\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 104.6295 - mae: 104.6295 - mse: 38652.6367\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 104.1079 - mae: 104.1079 - mse: 38524.5352\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 103.8755 - mae: 103.8755 - mse: 38498.2461\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 103.4967 - mae: 103.4967 - mse: 38105.3828\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 103.3575 - mae: 103.3575 - mse: 37686.6797\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 103.0149 - mae: 103.0150 - mse: 37909.3945\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 102.6586 - mae: 102.6586 - mse: 37556.0352\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 102.4107 - mae: 102.4107 - mse: 37076.4883\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 102.0295 - mae: 102.0295 - mse: 37128.8789\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 101.8296 - mae: 101.8296 - mse: 37011.3867\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 101.4785 - mae: 101.4785 - mse: 36574.9805\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 101.1922 - mae: 101.1922 - mse: 36460.9922\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 100.8747 - mae: 100.8747 - mse: 36071.9102\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 100.6107 - mae: 100.6107 - mse: 36011.8945\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 100.3792 - mae: 100.3792 - mse: 35610.5156\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 100.1055 - mae: 100.1055 - mse: 35650.6016\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 99.7010 - mae: 99.7010 - mse: 35244.3438\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 99.4850 - mae: 99.4850 - mse: 35035.1211\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 99.1556 - mae: 99.1556 - mse: 34816.6836\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 98.8924 - mae: 98.8924 - mse: 34564.1602\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 98.6413 - mae: 98.6413 - mse: 34252.6172\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 98.3875 - mae: 98.3875 - mse: 34164.2578\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 98.1203 - mae: 98.1203 - mse: 34022.5781\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 25us/step - loss: 97.8531 - mae: 97.8531 - mse: 33681.8047\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 303us/step - loss: 199.8181 - mae: 199.8181 - mse: 82619.3203\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 199.2952 - mae: 199.2952 - mse: 82408.3672\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 198.6134 - mae: 198.6134 - mse: 82137.8359\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 197.5291 - mae: 197.5291 - mse: 81709.8047\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 195.7887 - mae: 195.7887 - mse: 81011.1562\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 193.0727 - mae: 193.0728 - mse: 79953.9531\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 189.0017 - mae: 189.0017 - mse: 78371.7734\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 183.2539 - mae: 183.2539 - mse: 76065.3672\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 175.4246 - mae: 175.4245 - mse: 73107.0703\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 165.6812 - mae: 165.6812 - mse: 69376.1719\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 154.6224 - mae: 154.6224 - mse: 64959.3945\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 143.5680 - mae: 143.5680 - mse: 60588.0742\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 132.2559 - mae: 132.2559 - mse: 55756.8516\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 123.6619 - mae: 123.6619 - mse: 52155.1055\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 118.5523 - mae: 118.5523 - mse: 49116.1133\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 116.7220 - mae: 116.7220 - mse: 47529.1133\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 116.2247 - mae: 116.2247 - mse: 46794.1719\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 115.9870 - mae: 115.9870 - mse: 46547.1680\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 115.7629 - mae: 115.7629 - mse: 46449.4219\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 115.5392 - mae: 115.5392 - mse: 46321.3867\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 115.3124 - mae: 115.3124 - mse: 46244.9102\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 115.0850 - mae: 115.0850 - mse: 46135.3516\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 114.8780 - mae: 114.8780 - mse: 46072.6602\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 114.6613 - mae: 114.6613 - mse: 45971.9961\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 114.4844 - mae: 114.4844 - mse: 45916.4727\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 114.2644 - mae: 114.2644 - mse: 45810.4141\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 114.0470 - mae: 114.0470 - mse: 45655.3164\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 113.8527 - mae: 113.8527 - mse: 45624.3555\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 113.6590 - mae: 113.6591 - mse: 45474.4609\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 113.4596 - mae: 113.4596 - mse: 45258.0781\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 113.2399 - mae: 113.2399 - mse: 45257.3477\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 113.0380 - mae: 113.0380 - mse: 45117.1172\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 112.8293 - mae: 112.8293 - mse: 44959.8555\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 112.5962 - mae: 112.5962 - mse: 44959.2344\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 112.4586 - mae: 112.4586 - mse: 44762.5312\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 112.1885 - mae: 112.1885 - mse: 44593.6406\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 27us/step - loss: 111.9415 - mae: 111.9415 - mse: 44582.6875\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 111.7273 - mae: 111.7273 - mse: 44467.5117\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 23us/step - loss: 111.5234 - mae: 111.5234 - mse: 44302.4688\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 25us/step - loss: 111.3241 - mae: 111.3241 - mse: 44158.7461\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 111.1363 - mae: 111.1364 - mse: 43935.8516\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 25us/step - loss: 110.8143 - mae: 110.8143 - mse: 43874.0820\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 110.6758 - mae: 110.6758 - mse: 44061.2109\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 110.5439 - mae: 110.5439 - mse: 43691.5820\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 110.3624 - mae: 110.3624 - mse: 43670.6016\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 109.9724 - mae: 109.9724 - mse: 43591.6094\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 109.8015 - mae: 109.8015 - mse: 43335.7266\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 109.6093 - mae: 109.6093 - mse: 43205.8633\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 109.3794 - mae: 109.3794 - mse: 43120.3008\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 109.1769 - mae: 109.1769 - mse: 43010.7852\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 109.0037 - mae: 109.0037 - mse: 42854.8281\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 108.7692 - mae: 108.7692 - mse: 42731.2148\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 108.5476 - mae: 108.5476 - mse: 42635.3984\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 108.3775 - mae: 108.3775 - mse: 42608.8867\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 25us/step - loss: 108.1481 - mae: 108.1481 - mse: 42360.4648\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 25us/step - loss: 107.9675 - mae: 107.9675 - mse: 42258.2852\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 107.8179 - mae: 107.8179 - mse: 42010.8984\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 107.5487 - mae: 107.5487 - mse: 42072.7422\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 107.3665 - mae: 107.3665 - mse: 42025.2930\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 22us/step - loss: 107.1622 - mae: 107.1622 - mse: 41935.5977\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 22us/step - loss: 106.9102 - mae: 106.9102 - mse: 41769.5352\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 23us/step - loss: 106.7702 - mae: 106.7702 - mse: 41452.1250\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 23us/step - loss: 106.5128 - mae: 106.5128 - mse: 41315.7383\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 25us/step - loss: 106.2793 - mae: 106.2793 - mse: 41356.2031\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 25us/step - loss: 106.1136 - mae: 106.1136 - mse: 41362.4414\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 105.8585 - mae: 105.8585 - mse: 41115.8281\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 105.6475 - mae: 105.6475 - mse: 40872.0781\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 105.3882 - mae: 105.3882 - mse: 40701.7500\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 25us/step - loss: 105.1565 - mae: 105.1565 - mse: 40657.3125\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 104.9436 - mae: 104.9436 - mse: 40517.5742\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 25us/step - loss: 104.7283 - mae: 104.7283 - mse: 40263.3633\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 104.5079 - mae: 104.5079 - mse: 40224.5078\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 104.2711 - mae: 104.2711 - mse: 40035.4570\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 23us/step - loss: 104.0454 - mae: 104.0454 - mse: 39833.5547\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 103.8344 - mae: 103.8344 - mse: 39623.2695\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 23us/step - loss: 103.6097 - mae: 103.6097 - mse: 39478.9336\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 103.4213 - mae: 103.4213 - mse: 39367.2812\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 103.2406 - mae: 103.2406 - mse: 39048.9141\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 103.0558 - mae: 103.0558 - mse: 39264.0547\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 102.7936 - mae: 102.7936 - mse: 38934.6523\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 102.5566 - mae: 102.5566 - mse: 38703.0039\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 23us/step - loss: 102.3364 - mae: 102.3364 - mse: 38680.8750\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 102.1385 - mae: 102.1385 - mse: 38386.6992\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 102.0332 - mae: 102.0332 - mse: 38439.8086\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 101.6888 - mae: 101.6888 - mse: 38084.7695\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 101.5024 - mae: 101.5024 - mse: 37926.7773\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 101.3127 - mae: 101.3127 - mse: 37681.1016\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 22us/step - loss: 101.1273 - mae: 101.1273 - mse: 37647.4648\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 23us/step - loss: 100.8766 - mae: 100.8766 - mse: 37561.5820\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 23us/step - loss: 100.6972 - mae: 100.6972 - mse: 37265.6016\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 25us/step - loss: 100.4779 - mae: 100.4779 - mse: 37136.9766\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 25us/step - loss: 100.3126 - mae: 100.3126 - mse: 36962.3516\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 100.1305 - mae: 100.1305 - mse: 36837.0859\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 25us/step - loss: 99.9216 - mae: 99.9216 - mse: 36722.3398\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 23us/step - loss: 99.7337 - mae: 99.7337 - mse: 36371.0977\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 25us/step - loss: 99.5590 - mae: 99.5590 - mse: 36301.0898\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 25us/step - loss: 99.3396 - mae: 99.3396 - mse: 36078.6484\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 99.1343 - mae: 99.1343 - mse: 35989.3086\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 99.0036 - mae: 99.0036 - mse: 35934.5664\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 23us/step - loss: 98.8287 - mae: 98.8287 - mse: 35777.8555\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 226us/step - loss: 199.6639 - mae: 199.6639 - mse: 83755.5391\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 199.0129 - mae: 199.0129 - mse: 83495.0312\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 198.1557 - mae: 198.1557 - mse: 83147.3906\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 196.9070 - mae: 196.9070 - mse: 82659.4141\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 195.0283 - mae: 195.0283 - mse: 81950.2891\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 192.3453 - mae: 192.3453 - mse: 80895.6172\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 25us/step - loss: 188.7014 - mae: 188.7015 - mse: 79462.0781\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 183.8379 - mae: 183.8379 - mse: 77570.3047\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 177.4813 - mae: 177.4813 - mse: 75253.6094\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 169.4012 - mae: 169.4012 - mse: 72139.4844\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 160.3851 - mae: 160.3851 - mse: 68523.8828\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 150.9806 - mae: 150.9805 - mse: 64797.2539\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 29us/step - loss: 141.7247 - mae: 141.7247 - mse: 60829.1328\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 132.7553 - mae: 132.7554 - mse: 56809.3125\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 126.0930 - mae: 126.0930 - mse: 53442.4375\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 121.9953 - mae: 121.9953 - mse: 51071.5078\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 25us/step - loss: 120.4677 - mae: 120.4677 - mse: 49564.8516\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 119.9967 - mae: 119.9967 - mse: 48824.5195\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 119.6988 - mae: 119.6988 - mse: 48524.4219\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 119.4734 - mae: 119.4734 - mse: 48338.2773\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 119.2285 - mae: 119.2285 - mse: 48181.1445\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 23us/step - loss: 118.9715 - mae: 118.9715 - mse: 47985.1016\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 118.7283 - mae: 118.7283 - mse: 47896.5586\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 118.5356 - mae: 118.5356 - mse: 47677.7188\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - ETA: 0s - loss: 85.9916 - mae: 85.9916 - mse: 12666.558 - 0s 27us/step - loss: 118.2220 - mae: 118.2220 - mse: 47561.9414\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 117.9622 - mae: 117.9622 - mse: 47382.1367\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 117.6902 - mae: 117.6902 - mse: 47259.3516\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 22us/step - loss: 117.4665 - mae: 117.4665 - mse: 46988.6797\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 117.1873 - mae: 117.1873 - mse: 46866.4922\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - ETA: 0s - loss: 118.6863 - mae: 118.6863 - mse: 47428.218 - 0s 27us/step - loss: 116.9342 - mae: 116.9342 - mse: 46742.2617\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 116.7006 - mae: 116.7006 - mse: 46635.0234\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 29us/step - loss: 116.4823 - mae: 116.4823 - mse: 46368.1289\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 116.2349 - mae: 116.2349 - mse: 46283.8359\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 23us/step - loss: 115.9789 - mae: 115.9789 - mse: 46107.1055\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 115.7675 - mae: 115.7675 - mse: 45819.9805\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 115.4729 - mae: 115.4729 - mse: 45775.3359\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 115.2250 - mae: 115.2250 - mse: 45712.8086\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 114.9302 - mae: 114.9302 - mse: 45489.5312\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 114.6678 - mae: 114.6678 - mse: 45275.3750\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 25us/step - loss: 114.3677 - mae: 114.3677 - mse: 45092.3555\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - ETA: 0s - loss: 119.8358 - mae: 119.8358 - mse: 42394.410 - 0s 27us/step - loss: 114.0674 - mae: 114.0674 - mse: 44968.5781\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 113.7416 - mae: 113.7416 - mse: 44829.3320\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 113.4288 - mae: 113.4288 - mse: 44528.7539\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - ETA: 0s - loss: 136.0905 - mae: 136.0905 - mse: 70858.312 - 0s 27us/step - loss: 113.1763 - mae: 113.1763 - mse: 44382.5234\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 29us/step - loss: 112.7860 - mae: 112.7860 - mse: 44182.2852\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 26us/step - loss: 112.4757 - mae: 112.4757 - mse: 44093.4805\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 112.1696 - mae: 112.1696 - mse: 43885.2812\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 111.8316 - mae: 111.8316 - mse: 43656.2656\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 111.5768 - mae: 111.5768 - mse: 43586.7812\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 25us/step - loss: 111.2499 - mae: 111.2499 - mse: 43338.6484\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 111.0005 - mae: 111.0005 - mse: 43203.5625\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 110.6097 - mae: 110.6097 - mse: 42993.8555\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 110.3007 - mae: 110.3006 - mse: 42745.0469\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 109.9793 - mae: 109.9793 - mse: 42519.4648\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 109.6315 - mae: 109.6315 - mse: 42313.7188\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 109.3272 - mae: 109.3272 - mse: 42177.4180\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 109.0043 - mae: 109.0044 - mse: 41943.3906\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 108.7023 - mae: 108.7023 - mse: 41627.5859\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 108.4063 - mae: 108.4063 - mse: 41547.9258\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 107.9771 - mae: 107.9771 - mse: 41197.2266\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 107.6382 - mae: 107.6382 - mse: 40956.9727\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 107.2804 - mae: 107.2804 - mse: 40671.3750\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 25us/step - loss: 106.9463 - mae: 106.9463 - mse: 40363.2266\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 106.5450 - mae: 106.5450 - mse: 40043.2188\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 106.1868 - mae: 106.1868 - mse: 39875.6680\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 105.7377 - mae: 105.7377 - mse: 39576.0938\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 105.4186 - mae: 105.4186 - mse: 39403.3594\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 105.0459 - mae: 105.0459 - mse: 38966.9961\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 104.5953 - mae: 104.5953 - mse: 38721.7812\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 104.1511 - mae: 104.1511 - mse: 38433.8984\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 32us/step - loss: 103.8170 - mae: 103.8170 - mse: 38106.0781\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 103.4063 - mae: 103.4063 - mse: 37940.5469\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 103.0102 - mae: 103.0102 - mse: 37477.9414\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 102.4962 - mae: 102.4962 - mse: 37144.2617\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 102.0898 - mae: 102.0898 - mse: 36865.9766\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 101.7200 - mae: 101.7200 - mse: 36698.0352\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 101.2833 - mae: 101.2833 - mse: 36278.1172\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 100.9748 - mae: 100.9748 - mse: 35874.8867\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 100.6734 - mae: 100.6734 - mse: 35991.7188\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 100.2430 - mae: 100.2430 - mse: 35403.3398\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 99.8703 - mae: 99.8703 - mse: 35042.3125\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 99.4711 - mae: 99.4712 - mse: 35067.1250\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 99.0779 - mae: 99.0779 - mse: 34577.4219\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 25us/step - loss: 98.7673 - mae: 98.7673 - mse: 34292.5352\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 24us/step - loss: 98.3876 - mae: 98.3876 - mse: 34211.6953\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 23us/step - loss: 98.0651 - mae: 98.0651 - mse: 34037.0938\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 97.7774 - mae: 97.7774 - mse: 33537.6133\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 97.4911 - mae: 97.4911 - mse: 33448.1055\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 97.0617 - mae: 97.0617 - mse: 33121.4648\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 96.7899 - mae: 96.7898 - mse: 32790.5977\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 96.5511 - mae: 96.5512 - mse: 32698.8770\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 96.1247 - mae: 96.1247 - mse: 32373.2539\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 95.8423 - mae: 95.8423 - mse: 32210.7539\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 95.5303 - mae: 95.5303 - mse: 31963.0293\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 95.2420 - mae: 95.2420 - mse: 31752.8066\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 95.0318 - mae: 95.0318 - mse: 31545.1543\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 94.8057 - mae: 94.8057 - mse: 31240.2441\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 94.4657 - mae: 94.4657 - mse: 31090.4160\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 94.2628 - mae: 94.2628 - mse: 30904.8906\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 94.0284 - mae: 94.0284 - mse: 30695.1562\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 281us/step - loss: 203.9495 - mae: 203.9495 - mse: 85099.6797\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 203.4884 - mae: 203.4884 - mse: 84920.2969\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 202.8307 - mae: 202.8307 - mse: 84654.8359\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 201.8003 - mae: 201.8003 - mse: 84252.7344\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 200.1648 - mae: 200.1648 - mse: 83589.5625\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 197.5674 - mae: 197.5674 - mse: 82548.0703\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 193.5650 - mae: 193.5650 - mse: 80967.9609\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 187.7266 - mae: 187.7267 - mse: 78651.0625\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 179.6078 - mae: 179.6078 - mse: 75473.6797\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - ETA: 0s - loss: 218.3284 - mae: 218.3284 - mse: 119433.00 - 0s 33us/step - loss: 169.3056 - mae: 169.3057 - mse: 71483.4297\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 23us/step - loss: 157.9786 - mae: 157.9786 - mse: 66937.1250\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 29us/step - loss: 146.1367 - mae: 146.1366 - mse: 62005.6875\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 134.2919 - mae: 134.2919 - mse: 57242.7188\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 125.9021 - mae: 125.9021 - mse: 53018.1094\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 120.8330 - mae: 120.8330 - mse: 50106.9766\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 119.0415 - mae: 119.0415 - mse: 48350.2305\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 118.3548 - mae: 118.3549 - mse: 47527.7734\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 118.0080 - mae: 118.0080 - mse: 47278.5547\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 117.6807 - mae: 117.6807 - mse: 47117.8906\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 117.3996 - mae: 117.3997 - mse: 46934.7188\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 117.0937 - mae: 117.0937 - mse: 46831.9922\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 116.8236 - mae: 116.8236 - mse: 46633.3477\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 116.5523 - mae: 116.5523 - mse: 46423.0000\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 116.2675 - mae: 116.2675 - mse: 46513.9648\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 116.0047 - mae: 116.0047 - mse: 46374.1211\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 115.7695 - mae: 115.7695 - mse: 45979.3711\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 115.4921 - mae: 115.4921 - mse: 45932.7773\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 115.1615 - mae: 115.1615 - mse: 45779.0977\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 114.8711 - mae: 114.8711 - mse: 45634.2852\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 114.6027 - mae: 114.6027 - mse: 45381.3281\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 114.3502 - mae: 114.3503 - mse: 45144.9883\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 114.0584 - mae: 114.0584 - mse: 45199.0156\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 113.6928 - mae: 113.6928 - mse: 44989.5547\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 113.4080 - mae: 113.4081 - mse: 44657.1523\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 113.1602 - mae: 113.1602 - mse: 44603.0586\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 112.7011 - mae: 112.7011 - mse: 44399.1484\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 112.4207 - mae: 112.4207 - mse: 44205.1914\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - ETA: 0s - loss: 79.2790 - mae: 79.2790 - mse: 11981.275 - 0s 33us/step - loss: 112.1730 - mae: 112.1730 - mse: 43981.6094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 111.8486 - mae: 111.8486 - mse: 43872.4883\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 111.5172 - mae: 111.5172 - mse: 43691.0781\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 111.2397 - mae: 111.2397 - mse: 43570.2891\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 110.9916 - mae: 110.9916 - mse: 43329.1055\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 110.6945 - mae: 110.6945 - mse: 43199.7383\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 110.4241 - mae: 110.4241 - mse: 42974.0078\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 110.1657 - mae: 110.1657 - mse: 42941.8086\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 109.9327 - mae: 109.9327 - mse: 42588.8281\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 109.6053 - mae: 109.6053 - mse: 42348.8867\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 109.3546 - mae: 109.3546 - mse: 42282.1875\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 109.1083 - mae: 109.1083 - mse: 41929.4883\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 108.7865 - mae: 108.7865 - mse: 41559.9453\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 108.4370 - mae: 108.4370 - mse: 41493.6914\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 108.2150 - mae: 108.2150 - mse: 41557.1172\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 107.8553 - mae: 107.8553 - mse: 41251.4062\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 107.5540 - mae: 107.5540 - mse: 40992.4648\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 107.1858 - mae: 107.1858 - mse: 40709.7305\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 106.8639 - mae: 106.8639 - mse: 40409.5938\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 106.5530 - mae: 106.5530 - mse: 40370.0781\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 106.1640 - mae: 106.1640 - mse: 40033.1133\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 105.8473 - mae: 105.8472 - mse: 39815.9023\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 105.4899 - mae: 105.4899 - mse: 39555.4219\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 105.1241 - mae: 105.1240 - mse: 39334.3984\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 104.7555 - mae: 104.7555 - mse: 39066.9141\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 104.4122 - mae: 104.4122 - mse: 38887.9961\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 103.9928 - mae: 103.9928 - mse: 38596.6445\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 103.6509 - mae: 103.6509 - mse: 38400.2734\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 103.2731 - mae: 103.2731 - mse: 38224.8281\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 102.9582 - mae: 102.9582 - mse: 37906.5195\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 102.6199 - mae: 102.6199 - mse: 37747.7305\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 102.2151 - mae: 102.2151 - mse: 37388.2578\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 101.8706 - mae: 101.8706 - mse: 37145.4883\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 101.4957 - mae: 101.4957 - mse: 36890.2969\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 101.1802 - mae: 101.1802 - mse: 36854.8984\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 100.7827 - mae: 100.7827 - mse: 36434.2930\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 100.4773 - mae: 100.4773 - mse: 36236.5781\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 100.1456 - mae: 100.1456 - mse: 35898.6953\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 99.7258 - mae: 99.7258 - mse: 35761.7500\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 99.4234 - mae: 99.4234 - mse: 35512.2617\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 99.0814 - mae: 99.0814 - mse: 35206.9609\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 98.7333 - mae: 98.7333 - mse: 34880.7812\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 98.3601 - mae: 98.3601 - mse: 34574.0156\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 98.0031 - mae: 98.0031 - mse: 34396.8125\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 97.6492 - mae: 97.6492 - mse: 33983.0859\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 97.3029 - mae: 97.3029 - mse: 33684.5898\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 97.0612 - mae: 97.0611 - mse: 33617.1367\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 96.7942 - mae: 96.7942 - mse: 33069.9219\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 96.3762 - mae: 96.3762 - mse: 32998.1680\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 96.1808 - mae: 96.1808 - mse: 32595.7207\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 95.7323 - mae: 95.7323 - mse: 32444.9297\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 95.4657 - mae: 95.4657 - mse: 32308.7559\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 95.1975 - mae: 95.1975 - mse: 31897.6934\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 95.0414 - mae: 95.0414 - mse: 31651.9199\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 94.7215 - mae: 94.7215 - mse: 31637.5293\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 94.4839 - mae: 94.4839 - mse: 31490.1602\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 94.3268 - mae: 94.3268 - mse: 31051.7695\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 94.1859 - mae: 94.1859 - mse: 31076.0371\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 93.9149 - mae: 93.9149 - mse: 30797.0000\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 93.6761 - mae: 93.6761 - mse: 30564.2441\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 93.4808 - mae: 93.4808 - mse: 30364.0137\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 93.4260 - mae: 93.4260 - mse: 30428.0059\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 93.2916 - mae: 93.2916 - mse: 30044.7305\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 278us/step - loss: 193.8902 - mae: 193.8902 - mse: 78172.1719\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 193.1675 - mae: 193.1675 - mse: 77897.7578\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 192.1548 - mae: 192.1548 - mse: 77514.5625\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 190.5223 - mae: 190.5223 - mse: 76882.8125\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 34us/step - loss: 187.9092 - mae: 187.9092 - mse: 75934.2969\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 183.9219 - mae: 183.9219 - mse: 74358.2109\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 178.1749 - mae: 178.1749 - mse: 72211.7188\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 170.0562 - mae: 170.0562 - mse: 69184.6172\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 160.1152 - mae: 160.1152 - mse: 65501.2188\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 149.5926 - mae: 149.5926 - mse: 61332.7617\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 138.6651 - mae: 138.6651 - mse: 57003.8398\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 128.1889 - mae: 128.1889 - mse: 52692.4336\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 119.8609 - mae: 119.8610 - mse: 49114.4336\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 115.3891 - mae: 115.3890 - mse: 46516.4922\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 113.4434 - mae: 113.4434 - mse: 44938.2188\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 113.0214 - mae: 113.0214 - mse: 44132.8945\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 112.7284 - mae: 112.7284 - mse: 43820.3281\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 112.5320 - mae: 112.5320 - mse: 43647.9766\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 112.2798 - mae: 112.2798 - mse: 43590.1445\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 112.0660 - mae: 112.0660 - mse: 43559.4453\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 111.8612 - mae: 111.8612 - mse: 43431.5352\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 111.6499 - mae: 111.6499 - mse: 43370.2109\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 111.4268 - mae: 111.4268 - mse: 43268.7656\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 111.2040 - mae: 111.2040 - mse: 43083.5938\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 111.0751 - mae: 111.0751 - mse: 42880.9258\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 110.7862 - mae: 110.7862 - mse: 42681.7188\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 110.7950 - mae: 110.7950 - mse: 42962.8516\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 110.3587 - mae: 110.3587 - mse: 42715.1016\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 110.1459 - mae: 110.1459 - mse: 42486.0938\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 109.9405 - mae: 109.9405 - mse: 42294.8984\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 109.6994 - mae: 109.6994 - mse: 42248.8945\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 109.4499 - mae: 109.4499 - mse: 42138.4883\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 109.2224 - mae: 109.2224 - mse: 41931.8320\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 108.9895 - mae: 108.9895 - mse: 41797.5352\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 108.7419 - mae: 108.7419 - mse: 41654.8984\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 108.5256 - mae: 108.5256 - mse: 41375.8516\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 108.2749 - mae: 108.2749 - mse: 41262.3086\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 108.0435 - mae: 108.0435 - mse: 41215.9883\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 107.7792 - mae: 107.7791 - mse: 40978.0938\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 107.5281 - mae: 107.5282 - mse: 40834.6875\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 107.3077 - mae: 107.3077 - mse: 40675.6680\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 107.0304 - mae: 107.0304 - mse: 40602.5547\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 106.7965 - mae: 106.7965 - mse: 40508.3711\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 106.5503 - mae: 106.5503 - mse: 40331.0938\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 106.2993 - mae: 106.2993 - mse: 40151.2266\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 106.1209 - mae: 106.1209 - mse: 40052.9414\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 105.8346 - mae: 105.8346 - mse: 39696.7617\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 105.5294 - mae: 105.5294 - mse: 39477.5156\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 105.2471 - mae: 105.2471 - mse: 39446.7617\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 104.9802 - mae: 104.9802 - mse: 39180.5938\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 104.6986 - mae: 104.6986 - mse: 38997.7227\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 104.4311 - mae: 104.4311 - mse: 38853.8477\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 104.1768 - mae: 104.1768 - mse: 38734.3242\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 103.8844 - mae: 103.8844 - mse: 38427.1953\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 103.5566 - mae: 103.5566 - mse: 38198.7344\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 103.2630 - mae: 103.2630 - mse: 38055.2383\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 102.9970 - mae: 102.9970 - mse: 37756.2148\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 102.6593 - mae: 102.6593 - mse: 37603.2148\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 102.3565 - mae: 102.3565 - mse: 37505.8477\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 102.1112 - mae: 102.1112 - mse: 37184.5586\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 101.6969 - mae: 101.6969 - mse: 37041.6680\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 101.3565 - mae: 101.3565 - mse: 36834.0312\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 101.0471 - mae: 101.0471 - mse: 36549.5742\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 100.6888 - mae: 100.6888 - mse: 36358.6016\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 100.3809 - mae: 100.3809 - mse: 36169.0781\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 100.0633 - mae: 100.0633 - mse: 35888.5312\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 99.7404 - mae: 99.7404 - mse: 35713.0898\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 99.4743 - mae: 99.4742 - mse: 35627.3477\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 99.1809 - mae: 99.1809 - mse: 35310.6758\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 98.8118 - mae: 98.8118 - mse: 35112.8281\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 98.5870 - mae: 98.5870 - mse: 34835.0234\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 98.2189 - mae: 98.2189 - mse: 34764.3516\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 97.9440 - mae: 97.9440 - mse: 34641.2188\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 97.5802 - mae: 97.5802 - mse: 34228.5469\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 40us/step - loss: 97.2893 - mae: 97.2893 - mse: 34022.6055\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 97.1236 - mae: 97.1236 - mse: 34158.4727\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 96.7320 - mae: 96.7320 - mse: 33739.9453\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 96.3702 - mae: 96.3702 - mse: 33377.7617\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 96.0802 - mae: 96.0802 - mse: 33405.1680\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 95.8304 - mae: 95.8304 - mse: 33298.0352\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 41us/step - loss: 95.4836 - mae: 95.4836 - mse: 32925.1406\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 95.1917 - mae: 95.1917 - mse: 32692.9668\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 94.8822 - mae: 94.8822 - mse: 32556.8594\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 94.6572 - mae: 94.6572 - mse: 32354.4473\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 94.4185 - mae: 94.4185 - mse: 32022.8691\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 94.1389 - mae: 94.1389 - mse: 31934.6309\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 93.8390 - mae: 93.8390 - mse: 31766.0332\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 93.5896 - mae: 93.5896 - mse: 31564.5859\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 93.3559 - mae: 93.3559 - mse: 31389.6738\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 93.1901 - mae: 93.1901 - mse: 31279.7539\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 92.9281 - mae: 92.9281 - mse: 30952.7207\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 92.7705 - mae: 92.7705 - mse: 30976.1660\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 92.5173 - mae: 92.5173 - mse: 30738.6641\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 92.3627 - mae: 92.3627 - mse: 30474.2461\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 92.0963 - mae: 92.0963 - mse: 30319.8105\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 91.9108 - mae: 91.9108 - mse: 30041.5625\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 91.6978 - mae: 91.6978 - mse: 29960.9492\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 91.5473 - mae: 91.5473 - mse: 29721.8457\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 91.3574 - mae: 91.3574 - mse: 29676.4961\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 91.1391 - mae: 91.1390 - mse: 29528.7773\n",
      "Epoch 1/100\n",
      "750/750 [==============================] - 0s 212us/step - loss: 199.7569 - mae: 199.7569 - mse: 82679.7578\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 0s 27us/step - loss: 199.1111 - mae: 199.1111 - mse: 82425.4531\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 0s 29us/step - loss: 197.8148 - mae: 197.8148 - mse: 81907.4453\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 0s 28us/step - loss: 195.2703 - mae: 195.2703 - mse: 80892.5625\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 0s 27us/step - loss: 190.7785 - mae: 190.7785 - mse: 79144.5938\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 0s 26us/step - loss: 183.5119 - mae: 183.5119 - mse: 76308.7656\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 0s 27us/step - loss: 172.6613 - mae: 172.6613 - mse: 72232.7344\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 0s 27us/step - loss: 159.2805 - mae: 159.2805 - mse: 67056.3906\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 0s 27us/step - loss: 144.7921 - mae: 144.7921 - mse: 61038.9023\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 0s 27us/step - loss: 131.4065 - mae: 131.4065 - mse: 55493.6680\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 0s 27us/step - loss: 121.3713 - mae: 121.3713 - mse: 50628.8359\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 0s 28us/step - loss: 117.8437 - mae: 117.8437 - mse: 47996.6836\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 0s 28us/step - loss: 116.9549 - mae: 116.9549 - mse: 46751.2305\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 0s 28us/step - loss: 116.6430 - mae: 116.6430 - mse: 46460.7734\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 0s 28us/step - loss: 116.3111 - mae: 116.3111 - mse: 46427.1484\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 0s 29us/step - loss: 116.0164 - mae: 116.0164 - mse: 46313.6914\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 0s 33us/step - loss: 115.7615 - mae: 115.7615 - mse: 46040.5352\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 0s 28us/step - loss: 115.4718 - mae: 115.4718 - mse: 45839.6484\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 0s 29us/step - loss: 115.2486 - mae: 115.2486 - mse: 45873.4258\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 0s 27us/step - loss: 114.9477 - mae: 114.9477 - mse: 45587.2695\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 0s 29us/step - loss: 114.6774 - mae: 114.6774 - mse: 45399.1055\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 0s 28us/step - loss: 114.3992 - mae: 114.3992 - mse: 45230.2344\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 0s 31us/step - loss: 114.1611 - mae: 114.1611 - mse: 45232.7188\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 0s 33us/step - loss: 113.8312 - mae: 113.8312 - mse: 44957.5156\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 0s 31us/step - loss: 113.5391 - mae: 113.5391 - mse: 44616.2539\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 0s 31us/step - loss: 113.2226 - mae: 113.2226 - mse: 44529.4688\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 0s 29us/step - loss: 112.9194 - mae: 112.9193 - mse: 44401.0195\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 0s 32us/step - loss: 112.5673 - mae: 112.5673 - mse: 44191.7188\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 0s 32us/step - loss: 112.2740 - mae: 112.2740 - mse: 43879.3828\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 0s 32us/step - loss: 112.0099 - mae: 112.0099 - mse: 43854.9297\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 0s 28us/step - loss: 111.6092 - mae: 111.6092 - mse: 43653.9453\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 111.2922 - mae: 111.2922 - mse: 43348.0625\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 0s 33us/step - loss: 110.9743 - mae: 110.9743 - mse: 43168.1797\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 0s 28us/step - loss: 110.6982 - mae: 110.6982 - mse: 42980.8945\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 0s 35us/step - loss: 110.3719 - mae: 110.3719 - mse: 43013.7266\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 0s 28us/step - loss: 110.0808 - mae: 110.0808 - mse: 42758.4414\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 0s 33us/step - loss: 109.7378 - mae: 109.7379 - mse: 42468.2031\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 0s 33us/step - loss: 109.4809 - mae: 109.4809 - mse: 42275.1172\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 0s 31us/step - loss: 109.1580 - mae: 109.1580 - mse: 42147.7773\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 0s 34us/step - loss: 108.8465 - mae: 108.8465 - mse: 42009.8867\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 0s 27us/step - loss: 108.5732 - mae: 108.5732 - mse: 41700.9102\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 0s 31us/step - loss: 108.3700 - mae: 108.3700 - mse: 41744.7031\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 0s 29us/step - loss: 107.9566 - mae: 107.9566 - mse: 41282.4336\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 107.6962 - mae: 107.6961 - mse: 41176.9219\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 0s 31us/step - loss: 107.3218 - mae: 107.3218 - mse: 40977.1836\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 0s 31us/step - loss: 107.0267 - mae: 107.0267 - mse: 40584.5898\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 0s 31us/step - loss: 106.6871 - mae: 106.6871 - mse: 40550.0703\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 0s 31us/step - loss: 106.3488 - mae: 106.3488 - mse: 40253.2891\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 0s 31us/step - loss: 106.0443 - mae: 106.0443 - mse: 39965.5273\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 0s 30us/step - loss: 105.6666 - mae: 105.6666 - mse: 39827.8945\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 0s 29us/step - loss: 105.3163 - mae: 105.3163 - mse: 39610.3672\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 0s 29us/step - loss: 104.9787 - mae: 104.9787 - mse: 39159.1367\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 0s 27us/step - loss: 104.6264 - mae: 104.6264 - mse: 39098.3789\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 0s 29us/step - loss: 104.2698 - mae: 104.2698 - mse: 38750.0469\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 0s 29us/step - loss: 103.9046 - mae: 103.9046 - mse: 38671.5898\n",
      "Epoch 56/100\n",
      "750/750 [==============================] - 0s 30us/step - loss: 103.5009 - mae: 103.5009 - mse: 38259.9531\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 0s 31us/step - loss: 103.1424 - mae: 103.1424 - mse: 37975.8789\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 0s 32us/step - loss: 102.7667 - mae: 102.7667 - mse: 37872.0469\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 0s 31us/step - loss: 102.4618 - mae: 102.4618 - mse: 37405.4961\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 0s 29us/step - loss: 102.1777 - mae: 102.1777 - mse: 37356.2500\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 0s 29us/step - loss: 101.7188 - mae: 101.7188 - mse: 36942.9766\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 0s 31us/step - loss: 101.3890 - mae: 101.3890 - mse: 36881.2852\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 0s 31us/step - loss: 101.0816 - mae: 101.0816 - mse: 36669.6680\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 0s 29us/step - loss: 100.7413 - mae: 100.7413 - mse: 36067.2461\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 0s 33us/step - loss: 100.3345 - mae: 100.3345 - mse: 36034.0938\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 0s 31us/step - loss: 100.0585 - mae: 100.0585 - mse: 35891.4180\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 0s 31us/step - loss: 99.6625 - mae: 99.6625 - mse: 35338.0312\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 0s 32us/step - loss: 99.3033 - mae: 99.3033 - mse: 35234.7539\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 0s 30us/step - loss: 98.9295 - mae: 98.9295 - mse: 34772.3125\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 0s 32us/step - loss: 98.5775 - mae: 98.5775 - mse: 34571.7930\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 0s 29us/step - loss: 98.2461 - mae: 98.2461 - mse: 34287.4922\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 0s 32us/step - loss: 97.9573 - mae: 97.9573 - mse: 34133.2969\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 0s 33us/step - loss: 97.6486 - mae: 97.6486 - mse: 33632.8320\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 0s 32us/step - loss: 97.3915 - mae: 97.3915 - mse: 33540.9531\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 0s 37us/step - loss: 97.0370 - mae: 97.0370 - mse: 33086.0469\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 0s 40us/step - loss: 96.6643 - mae: 96.6643 - mse: 32991.3477\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 0s 40us/step - loss: 96.4533 - mae: 96.4533 - mse: 32594.7500\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 0s 37us/step - loss: 96.0921 - mae: 96.0921 - mse: 32462.1523\n",
      "Epoch 79/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 95.8817 - mae: 95.8818 - mse: 32325.1016\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 95.5538 - mae: 95.5538 - mse: 31985.3652\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 0s 40us/step - loss: 95.3289 - mae: 95.3289 - mse: 31726.0527\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 95.0781 - mae: 95.0781 - mse: 31555.8340\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 95.0132 - mae: 95.0132 - mse: 31233.4160\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 94.7642 - mae: 94.7642 - mse: 31244.2695\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 94.4725 - mae: 94.4725 - mse: 30988.4102\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 94.3055 - mae: 94.3055 - mse: 30734.7520\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 0s 43us/step - loss: 94.2301 - mae: 94.2300 - mse: 30545.9492\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 93.9511 - mae: 93.9511 - mse: 30588.0371\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 93.8082 - mae: 93.8082 - mse: 30172.3789\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 93.5960 - mae: 93.5960 - mse: 30122.1328\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 0s 40us/step - loss: 93.5154 - mae: 93.5154 - mse: 29935.6484\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 93.3094 - mae: 93.3094 - mse: 29877.2266\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 93.1335 - mae: 93.1335 - mse: 29671.6191\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 0s 43us/step - loss: 93.0014 - mae: 93.0014 - mse: 29587.3008\n",
      "Epoch 95/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 92.9140 - mae: 92.9140 - mse: 29438.0488\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 0s 40us/step - loss: 92.7222 - mae: 92.7222 - mse: 29355.4473\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 0s 39us/step - loss: 92.6136 - mae: 92.6136 - mse: 29079.1777\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 92.5494 - mae: 92.5494 - mse: 29162.3574\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 0s 37us/step - loss: 92.5048 - mae: 92.5048 - mse: 28972.8691\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 92.3363 - mae: 92.3363 - mse: 28920.7598\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=22, activation = 'relu', input_dim=22))\n",
    "    model.add(Dense(units=22, activation = 'relu'))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error',  metrics=['mae','mse'])\n",
    "    return model\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "NN_Regressor = KerasRegressor(build_fn=build_model, batch_size=40,epochs=100)    \n",
    "\n",
    "scores = cross_val_score(NN_Regressor, X_train, y_train, cv=5, scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "NN = NN_Regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the scores for each model run\n",
      "[ -94.6321493   -95.18351877  -97.39047255  -96.68357474 -112.04744902]\n",
      " \n",
      "Mean and variance: 99.19 (+/- 13.01)\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 107.73620826843262\n",
      "Root Mean Squared Error: 41054.84083833669\n",
      "Time Taken =  38.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Below are the scores for each model run\")\n",
    "print(scores)\n",
    "print(\" \")\n",
    "print(\"Mean and variance: %0.2f (+/- %0.2f)\" % (abs(scores.mean()), scores.std() * 2))\n",
    "\n",
    "y_pred= NN_Regressor.predict(X_test_holdout)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', metrics.mean_squared_error(y_test_holdout, y_pred))\n",
    "\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 293us/step - loss: 201.5205 - mae: 201.5205 - mse: 83843.5156\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 201.1532 - mae: 201.1532 - mse: 83692.1328\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 200.6095 - mae: 200.6095 - mse: 83475.3281\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 199.7005 - mae: 199.7005 - mse: 83116.7031\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 197.9934 - mae: 197.9934 - mse: 82419.3281\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 194.6833 - mae: 194.6833 - mse: 81106.0625\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 188.5416 - mae: 188.5416 - mse: 78725.9141\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 177.8460 - mae: 177.8460 - mse: 74649.6562\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 162.2391 - mae: 162.2391 - mse: 68657.3359\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 143.6310 - mae: 143.6310 - mse: 60795.2812\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 125.6945 - mae: 125.6945 - mse: 52714.1680\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 118.8835 - mae: 118.8835 - mse: 48015.5977\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 118.5045 - mae: 118.5045 - mse: 46704.7773\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 118.0201 - mae: 118.0201 - mse: 47170.7734\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 117.6030 - mae: 117.6030 - mse: 47214.1406\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 117.3512 - mae: 117.3512 - mse: 47237.1641\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 117.0765 - mae: 117.0765 - mse: 46698.0703\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 116.7357 - mae: 116.7357 - mse: 46683.6328\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 116.4760 - mae: 116.4760 - mse: 46645.3516\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 116.1292 - mae: 116.1292 - mse: 46425.6914\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 115.9163 - mae: 115.9163 - mse: 45908.1641\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 115.7171 - mae: 115.7171 - mse: 46081.1992\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 115.2757 - mae: 115.2757 - mse: 45780.9648\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 115.0289 - mae: 115.0289 - mse: 45686.1016\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 114.7513 - mae: 114.7513 - mse: 45495.9648\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 114.4909 - mae: 114.4909 - mse: 45311.3711\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 114.1886 - mae: 114.1886 - mse: 45166.3281\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 113.9093 - mae: 113.9093 - mse: 44992.8984\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 113.6354 - mae: 113.6354 - mse: 44835.3086\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 113.3564 - mae: 113.3564 - mse: 44744.6719\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 113.3045 - mae: 113.3045 - mse: 44191.9219\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 112.7253 - mae: 112.7253 - mse: 44146.8906\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 112.6122 - mae: 112.6122 - mse: 44472.3867\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 112.1555 - mae: 112.1555 - mse: 43926.1719\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 111.9049 - mae: 111.9049 - mse: 43772.2305\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 111.5740 - mae: 111.5740 - mse: 43594.5977\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 111.3954 - mae: 111.3954 - mse: 43632.9258\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 111.1064 - mae: 111.1064 - mse: 42958.2383\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 110.6467 - mae: 110.6467 - mse: 42819.5664\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 110.3511 - mae: 110.3511 - mse: 42945.0898\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 109.9871 - mae: 109.9871 - mse: 42333.8750\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 109.6459 - mae: 109.6460 - mse: 42217.5039\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 109.2957 - mae: 109.2957 - mse: 41983.9414\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 109.0435 - mae: 109.0435 - mse: 41613.1094\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 108.6685 - mae: 108.6685 - mse: 41611.2617\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 108.1877 - mae: 108.1877 - mse: 41233.0508\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 107.8046 - mae: 107.8046 - mse: 40854.3125\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 107.4234 - mae: 107.4234 - mse: 40659.1445\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 107.0032 - mae: 107.0032 - mse: 40400.5586\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 106.6212 - mae: 106.6212 - mse: 39911.9805\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 106.1619 - mae: 106.1619 - mse: 39909.2383\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 105.6944 - mae: 105.6944 - mse: 39446.3242\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 105.2234 - mae: 105.2234 - mse: 39081.2031\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 104.7091 - mae: 104.7091 - mse: 38680.6172\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 104.2580 - mae: 104.2580 - mse: 38640.6484\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 103.6898 - mae: 103.6898 - mse: 37909.9766\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 103.1027 - mae: 103.1027 - mse: 37798.4766\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 102.5592 - mae: 102.5592 - mse: 37487.0586\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 101.9863 - mae: 101.9863 - mse: 36853.3125\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 101.4738 - mae: 101.4738 - mse: 36605.7461\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 100.9148 - mae: 100.9148 - mse: 36204.7031\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 100.3748 - mae: 100.3748 - mse: 35648.2617\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 99.8626 - mae: 99.8626 - mse: 35383.7500\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 99.4309 - mae: 99.4309 - mse: 34737.9883\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 98.7606 - mae: 98.7606 - mse: 34426.9609\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 98.3452 - mae: 98.3452 - mse: 34242.6914\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 39us/step - loss: 97.8434 - mae: 97.8434 - mse: 33471.5352\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 97.2673 - mae: 97.2673 - mse: 33204.9844\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 96.9124 - mae: 96.9124 - mse: 33187.7773\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 96.3959 - mae: 96.3959 - mse: 32416.2227\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 95.8242 - mae: 95.8242 - mse: 31910.0742\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 95.4418 - mae: 95.4418 - mse: 31818.9707\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 95.0049 - mae: 95.0049 - mse: 31348.1074\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 94.7062 - mae: 94.7062 - mse: 31118.8398\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 94.2807 - mae: 94.2807 - mse: 30678.2559\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 93.9096 - mae: 93.9096 - mse: 30555.9395\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 93.6470 - mae: 93.6470 - mse: 30148.9629\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 93.2574 - mae: 93.2574 - mse: 30004.6465\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 92.9893 - mae: 92.9893 - mse: 29775.2461\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 92.6737 - mae: 92.6737 - mse: 29393.2793\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 92.4494 - mae: 92.4494 - mse: 29272.8730\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 92.5793 - mae: 92.5793 - mse: 28853.2637\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 92.1660 - mae: 92.1660 - mse: 29110.3594\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 92.0157 - mae: 92.0157 - mse: 28702.2695\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 91.5823 - mae: 91.5823 - mse: 28567.0391\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 91.3920 - mae: 91.3920 - mse: 28405.5605\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 91.2531 - mae: 91.2531 - mse: 28184.3457\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 91.1125 - mae: 91.1125 - mse: 28247.9707\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 90.8660 - mae: 90.8660 - mse: 27982.8262\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 90.7072 - mae: 90.7072 - mse: 27776.7207\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 90.5405 - mae: 90.5406 - mse: 27764.2559\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 90.5561 - mae: 90.5561 - mse: 27658.4297\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 90.2434 - mae: 90.2434 - mse: 27475.0742\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 90.1249 - mae: 90.1249 - mse: 27375.6348\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 90.0534 - mae: 90.0534 - mse: 27263.3086\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 90.0452 - mae: 90.0452 - mse: 27347.9727\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 90.0795 - mae: 90.0795 - mse: 27027.5039\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 90.0690 - mae: 90.0690 - mse: 27342.7559\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 89.8672 - mae: 89.8672 - mse: 26735.4648\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 90.1816 - mae: 90.1816 - mse: 27372.1133\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 323us/step - loss: 199.8788 - mae: 199.8788 - mse: 82640.7188\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 199.4438 - mae: 199.4438 - mse: 82473.8828\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 34us/step - loss: 198.6747 - mae: 198.6747 - mse: 82178.3125\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 197.1432 - mae: 197.1432 - mse: 81571.9297\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 193.9898 - mae: 193.9898 - mse: 80373.9297\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 187.8611 - mae: 187.8611 - mse: 78043.6719\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 31us/step - loss: 176.7570 - mae: 176.7570 - mse: 73826.8984\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 25us/step - loss: 160.5294 - mae: 160.5294 - mse: 67609.8906\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 141.1453 - mae: 141.1453 - mse: 59774.5859\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 123.8705 - mae: 123.8705 - mse: 52212.5547\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 118.6502 - mae: 118.6502 - mse: 47639.0625\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 118.1366 - mae: 118.1366 - mse: 46638.7422\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 117.6234 - mae: 117.6233 - mse: 47164.3477\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 117.0117 - mae: 117.0117 - mse: 47129.1602\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 116.6006 - mae: 116.6006 - mse: 46785.8906\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 116.2294 - mae: 116.2294 - mse: 46772.8633\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 115.9300 - mae: 115.9300 - mse: 46586.2812\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 115.5540 - mae: 115.5540 - mse: 46143.8086\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 115.2055 - mae: 115.2055 - mse: 45905.0938\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 115.1062 - mae: 115.1062 - mse: 46286.7109\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 114.4918 - mae: 114.4918 - mse: 45841.1758\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 114.1355 - mae: 114.1355 - mse: 45342.0820\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 113.7903 - mae: 113.7903 - mse: 45197.6016\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 113.4341 - mae: 113.4341 - mse: 45336.5117\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 113.1613 - mae: 113.1613 - mse: 44873.0781\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 112.7102 - mae: 112.7102 - mse: 44854.2461\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 112.3529 - mae: 112.3529 - mse: 44508.5352\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 111.9411 - mae: 111.9411 - mse: 44487.2539\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 111.5888 - mae: 111.5888 - mse: 44434.0742\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 111.2081 - mae: 111.2081 - mse: 43931.9570\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 110.8243 - mae: 110.8243 - mse: 43829.9414\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 110.4100 - mae: 110.4100 - mse: 43854.0781\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 110.2462 - mae: 110.2462 - mse: 43301.9062\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 109.7134 - mae: 109.7134 - mse: 43523.7852\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 109.3247 - mae: 109.3247 - mse: 43211.5039\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 109.0484 - mae: 109.0484 - mse: 42777.0508\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 108.7666 - mae: 108.7666 - mse: 42990.2617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 108.3267 - mae: 108.3267 - mse: 42503.5977\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 107.9678 - mae: 107.9678 - mse: 42276.9688\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 107.6079 - mae: 107.6079 - mse: 42014.6250\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 107.2316 - mae: 107.2316 - mse: 42007.6914\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 106.8611 - mae: 106.8611 - mse: 41803.5820\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 106.4974 - mae: 106.4974 - mse: 41431.7812\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 106.2030 - mae: 106.2029 - mse: 41320.5430\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 105.8538 - mae: 105.8538 - mse: 40840.5586\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 105.4199 - mae: 105.4199 - mse: 40721.7578\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 105.0185 - mae: 105.0185 - mse: 40359.8516\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 104.6008 - mae: 104.6008 - mse: 40218.6953\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 104.1865 - mae: 104.1865 - mse: 39794.1719\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 103.7662 - mae: 103.7662 - mse: 39644.1133\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 103.4204 - mae: 103.4204 - mse: 39200.5352\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 102.9040 - mae: 102.9040 - mse: 38999.2539\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 102.4833 - mae: 102.4833 - mse: 38743.1094\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 102.1076 - mae: 102.1077 - mse: 38540.1172\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 101.6306 - mae: 101.6306 - mse: 38005.2617\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 101.2896 - mae: 101.2896 - mse: 37807.3281\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 100.9228 - mae: 100.9228 - mse: 37494.4297\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 100.5845 - mae: 100.5845 - mse: 37285.9609\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 100.3336 - mae: 100.3335 - mse: 36814.4961\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 99.8675 - mae: 99.8675 - mse: 36705.5078\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 99.5242 - mae: 99.5242 - mse: 36274.6406\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 99.1264 - mae: 99.1264 - mse: 35996.1953\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 98.8340 - mae: 98.8340 - mse: 35805.0586\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 98.4432 - mae: 98.4432 - mse: 35511.6484\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 98.1256 - mae: 98.1256 - mse: 35178.4180\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 97.8962 - mae: 97.8962 - mse: 34958.8398\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 97.5721 - mae: 97.5721 - mse: 34906.1875\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 97.4820 - mae: 97.4820 - mse: 34403.6250\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 97.0490 - mae: 97.0490 - mse: 34272.7383\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 96.7260 - mae: 96.7260 - mse: 34027.0742\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 96.5095 - mae: 96.5095 - mse: 33635.0898\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 96.1346 - mae: 96.1346 - mse: 33663.7461\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 34us/step - loss: 95.9138 - mae: 95.9138 - mse: 33409.5195\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 95.5934 - mae: 95.5934 - mse: 33229.7109\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 95.4320 - mae: 95.4320 - mse: 32875.7734\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 95.1894 - mae: 95.1894 - mse: 32983.3750\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 95.0035 - mae: 95.0035 - mse: 32573.9805\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 94.7799 - mae: 94.7799 - mse: 32473.6543\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 94.6019 - mae: 94.6019 - mse: 32350.4727\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 94.5395 - mae: 94.5395 - mse: 31899.1191\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 94.3558 - mae: 94.3558 - mse: 32291.4238\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 94.1642 - mae: 94.1642 - mse: 31769.1738\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 93.8405 - mae: 93.8405 - mse: 31568.5840\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 93.7550 - mae: 93.7550 - mse: 31658.3340\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 93.6432 - mae: 93.6432 - mse: 31603.8633\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 93.5142 - mae: 93.5142 - mse: 31046.4062\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 93.2375 - mae: 93.2375 - mse: 31043.0859\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 93.2318 - mae: 93.2318 - mse: 31180.3301\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 93.0929 - mae: 93.0929 - mse: 30780.4902\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 92.9924 - mae: 92.9924 - mse: 30951.6602\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 92.8980 - mae: 92.8980 - mse: 30864.9902\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 92.9586 - mae: 92.9586 - mse: 30593.5293\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 92.7850 - mae: 92.7850 - mse: 30623.1562\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 92.5605 - mae: 92.5606 - mse: 30677.4258\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 92.6460 - mae: 92.6460 - mse: 30385.7559\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 92.4667 - mae: 92.4667 - mse: 30621.6758\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - ETA: 0s - loss: 99.3410 - mae: 99.3410 - mse: 22664.619 - 0s 38us/step - loss: 92.4012 - mae: 92.4012 - mse: 30340.4434\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 92.2521 - mae: 92.2521 - mse: 30320.1426\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 92.1135 - mae: 92.1134 - mse: 30148.7637\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 92.0953 - mae: 92.0953 - mse: 30216.1836\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 332us/step - loss: 199.9616 - mae: 199.9616 - mse: 83857.2734\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 199.4104 - mae: 199.4104 - mse: 83637.0078\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 198.4472 - mae: 198.4472 - mse: 83249.0156\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 196.6836 - mae: 196.6836 - mse: 82594.8672\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 193.5105 - mae: 193.5105 - mse: 81333.8828\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 187.7632 - mae: 187.7632 - mse: 79074.2500\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 29us/step - loss: 177.7401 - mae: 177.7401 - mse: 75349.7031\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 31us/step - loss: 162.3127 - mae: 162.3127 - mse: 69255.1875\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 143.3043 - mae: 143.3043 - mse: 61712.6875\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 125.6157 - mae: 125.6157 - mse: 53737.7852\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 118.8110 - mae: 118.8110 - mse: 48448.8086\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 118.5798 - mae: 118.5798 - mse: 47393.0703\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 117.8290 - mae: 117.8290 - mse: 47517.0469\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - ETA: 0s - loss: 101.2243 - mae: 101.2243 - mse: 18899.363 - 0s 36us/step - loss: 117.3605 - mae: 117.3605 - mse: 47173.4336\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 116.8966 - mae: 116.8966 - mse: 46975.0977\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 34us/step - loss: 116.4810 - mae: 116.4810 - mse: 46889.1484\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 34us/step - loss: 116.0629 - mae: 116.0629 - mse: 46720.8867\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 115.5945 - mae: 115.5945 - mse: 46150.6016\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 115.1437 - mae: 115.1437 - mse: 45613.7070\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 114.7207 - mae: 114.7207 - mse: 45708.7539\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 114.2027 - mae: 114.2027 - mse: 45371.1719\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 113.7071 - mae: 113.7071 - mse: 45200.7930\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 113.2433 - mae: 113.2433 - mse: 44657.2148\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 112.7801 - mae: 112.7801 - mse: 44569.3008\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 112.1793 - mae: 112.1793 - mse: 44171.3867\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 111.7345 - mae: 111.7345 - mse: 43771.8008\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 111.2144 - mae: 111.2144 - mse: 43407.8281\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 110.6739 - mae: 110.6739 - mse: 43025.3125\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 110.2032 - mae: 110.2032 - mse: 42488.1406\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 109.5391 - mae: 109.5391 - mse: 42215.6406\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 109.0100 - mae: 109.0100 - mse: 41816.9297\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 108.4519 - mae: 108.4519 - mse: 41273.1133\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 107.8729 - mae: 107.8729 - mse: 41203.3789\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 107.3298 - mae: 107.3298 - mse: 40379.9023\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 39us/step - loss: 106.6753 - mae: 106.6753 - mse: 40324.2539\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 106.0050 - mae: 106.0050 - mse: 39732.3594\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 105.3779 - mae: 105.3779 - mse: 38911.2891\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 104.6384 - mae: 104.6384 - mse: 38829.7812\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 103.8256 - mae: 103.8255 - mse: 38116.7852\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 103.1025 - mae: 103.1025 - mse: 37496.8867\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 102.3999 - mae: 102.3999 - mse: 36964.3906\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 101.6858 - mae: 101.6859 - mse: 36556.2852\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 100.9353 - mae: 100.9353 - mse: 36152.5156\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 100.2689 - mae: 100.2689 - mse: 35206.0781\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 99.6016 - mae: 99.6016 - mse: 35014.4453\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 99.0335 - mae: 99.0335 - mse: 34264.9922\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 98.2909 - mae: 98.2909 - mse: 34244.7461\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 97.7217 - mae: 97.7217 - mse: 33385.1797\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 97.1226 - mae: 97.1226 - mse: 32707.3828\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 96.4182 - mae: 96.4182 - mse: 32701.7734\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 95.8783 - mae: 95.8783 - mse: 32033.9707\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 95.2345 - mae: 95.2345 - mse: 31429.2793\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 94.7246 - mae: 94.7246 - mse: 31210.3262\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 94.3515 - mae: 94.3515 - mse: 30642.5508\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 93.7471 - mae: 93.7471 - mse: 30028.0938\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 93.2409 - mae: 93.2409 - mse: 29797.6738\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 92.8605 - mae: 92.8605 - mse: 29300.0840\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 92.8193 - mae: 92.8193 - mse: 29450.8125\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 92.3072 - mae: 92.3072 - mse: 28494.0391\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 91.9594 - mae: 91.9594 - mse: 28564.7168\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 91.5086 - mae: 91.5086 - mse: 27848.0371\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 91.3013 - mae: 91.3013 - mse: 27817.9707\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 91.0707 - mae: 91.0707 - mse: 27552.1816\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 90.8134 - mae: 90.8134 - mse: 27368.2930\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 90.6120 - mae: 90.6120 - mse: 27231.8652\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 90.4567 - mae: 90.4567 - mse: 26874.0625\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 90.4622 - mae: 90.4622 - mse: 26775.7031\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 90.2616 - mae: 90.2616 - mse: 26694.7012\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 90.1853 - mae: 90.1853 - mse: 26239.6562\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 89.9465 - mae: 89.9465 - mse: 26461.3145\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 89.6343 - mae: 89.6343 - mse: 25930.2930\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 89.6028 - mae: 89.6028 - mse: 26047.9844\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 89.4217 - mae: 89.4217 - mse: 25623.9473\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 36us/step - loss: 89.2011 - mae: 89.2011 - mse: 25596.3145\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 89.0728 - mae: 89.0728 - mse: 25353.0195\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 89.0887 - mae: 89.0887 - mse: 25306.2793\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 88.8435 - mae: 88.8435 - mse: 25043.3730\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 88.8116 - mae: 88.8115 - mse: 25055.7852\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 88.8097 - mae: 88.8097 - mse: 25086.6074\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 88.3285 - mae: 88.3285 - mse: 24661.1465\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 88.2279 - mae: 88.2279 - mse: 24534.5410\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 88.3065 - mae: 88.3064 - mse: 24641.0977\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 87.9556 - mae: 87.9556 - mse: 24267.6680\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 87.8102 - mae: 87.8102 - mse: 24279.7891\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 87.8405 - mae: 87.8404 - mse: 24275.4121\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 87.6723 - mae: 87.6724 - mse: 24106.1465\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 87.5987 - mae: 87.5987 - mse: 23952.4297\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 87.4049 - mae: 87.4049 - mse: 23933.0039\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 87.3737 - mae: 87.3737 - mse: 23846.3496\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 87.3038 - mae: 87.3038 - mse: 23910.1152\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 87.0657 - mae: 87.0658 - mse: 23574.8652\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 87.1930 - mae: 87.1930 - mse: 23498.9355\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 87.2413 - mae: 87.2413 - mse: 23722.8691\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 86.8709 - mae: 86.8709 - mse: 23318.9863\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 86.6182 - mae: 86.6182 - mse: 23346.4434\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 86.5521 - mae: 86.5521 - mse: 23187.4570\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 39us/step - loss: 86.4026 - mae: 86.4025 - mse: 23187.0723\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 86.3200 - mae: 86.3201 - mse: 23025.8203\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 86.2148 - mae: 86.2148 - mse: 23113.3848\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 86.1058 - mae: 86.1058 - mse: 22990.8789\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 356us/step - loss: 203.8558 - mae: 203.8558 - mse: 85054.2500\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 203.4630 - mae: 203.4630 - mse: 84898.0703\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 202.7007 - mae: 202.7007 - mse: 84597.8203\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 201.1341 - mae: 201.1341 - mse: 83970.9453\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 198.0165 - mae: 198.0165 - mse: 82771.1250\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 191.9449 - mae: 191.9449 - mse: 80339.1562\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 181.0250 - mae: 181.0251 - mse: 76060.6172\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 164.1686 - mae: 164.1686 - mse: 69711.2109\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 143.8493 - mae: 143.8493 - mse: 61397.4805\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 126.2922 - mae: 126.2922 - mse: 53132.3711\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 119.6546 - mae: 119.6546 - mse: 48760.6094\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 31us/step - loss: 118.9050 - mae: 118.9050 - mse: 47510.9219\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 118.3208 - mae: 118.3208 - mse: 47518.3516\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 117.9762 - mae: 117.9762 - mse: 47659.0820\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 117.5901 - mae: 117.5901 - mse: 47303.6797\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 117.2400 - mae: 117.2400 - mse: 47108.6914\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 116.9770 - mae: 116.9770 - mse: 46844.7617\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 116.6437 - mae: 116.6437 - mse: 46814.9961\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 116.2442 - mae: 116.2442 - mse: 46702.2695\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 115.8926 - mae: 115.8926 - mse: 46265.3125\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 115.5620 - mae: 115.5620 - mse: 46091.7188\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 115.1854 - mae: 115.1854 - mse: 45881.4531\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 114.8821 - mae: 114.8821 - mse: 45918.2266\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 114.6357 - mae: 114.6357 - mse: 45831.3164\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 114.1482 - mae: 114.1482 - mse: 45244.6680\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 113.7956 - mae: 113.7956 - mse: 44975.1367\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 39us/step - loss: 113.3985 - mae: 113.3985 - mse: 44807.4648\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 113.1021 - mae: 113.1021 - mse: 44849.6055\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 112.7055 - mae: 112.7055 - mse: 44548.8828\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 112.3702 - mae: 112.3702 - mse: 44208.1680\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 112.1306 - mae: 112.1306 - mse: 44341.5859\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 111.7638 - mae: 111.7638 - mse: 43837.0820\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 111.6396 - mae: 111.6396 - mse: 44151.0781\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 111.2150 - mae: 111.2150 - mse: 43382.7266\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 110.8588 - mae: 110.8588 - mse: 43267.9102\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 110.7383 - mae: 110.7383 - mse: 43525.6133\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 110.1920 - mae: 110.1920 - mse: 43053.6680\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 110.0438 - mae: 110.0438 - mse: 42521.1016\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 109.6371 - mae: 109.6371 - mse: 42672.4883\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 109.4614 - mae: 109.4614 - mse: 42287.3555\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 108.9898 - mae: 108.9898 - mse: 42140.0039\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 108.7265 - mae: 108.7265 - mse: 42115.1602\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 108.2977 - mae: 108.2977 - mse: 41650.1094\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 108.0410 - mae: 108.0410 - mse: 41192.5000\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 107.5772 - mae: 107.5772 - mse: 41231.3906\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 107.2111 - mae: 107.2111 - mse: 40978.9805\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 106.8434 - mae: 106.8434 - mse: 40683.4648\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 39us/step - loss: 106.4388 - mae: 106.4388 - mse: 40535.6445\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 106.0741 - mae: 106.0741 - mse: 40202.3867\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 105.6657 - mae: 105.6657 - mse: 39843.5898\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 105.2325 - mae: 105.2325 - mse: 39408.6914\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 104.8840 - mae: 104.8840 - mse: 39398.4531\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 104.4913 - mae: 104.4912 - mse: 39165.3555\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 104.1470 - mae: 104.1470 - mse: 38429.9766\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 34us/step - loss: 103.5182 - mae: 103.5182 - mse: 38379.8047\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 102.9728 - mae: 102.9728 - mse: 37939.5039\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 34us/step - loss: 102.4586 - mae: 102.4586 - mse: 37600.3945\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 102.0868 - mae: 102.0868 - mse: 37454.8086\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 101.6730 - mae: 101.6730 - mse: 36726.4375\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 101.0538 - mae: 101.0538 - mse: 36573.7656\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 100.6905 - mae: 100.6905 - mse: 36254.2578\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 100.2377 - mae: 100.2377 - mse: 36055.7656\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 99.6460 - mae: 99.6460 - mse: 35363.3828\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 99.1550 - mae: 99.1550 - mse: 35194.7461\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 98.5174 - mae: 98.5174 - mse: 34809.1523\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 98.1776 - mae: 98.1776 - mse: 34096.8477\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 39us/step - loss: 97.5592 - mae: 97.5592 - mse: 34058.0820\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 97.0477 - mae: 97.0477 - mse: 33455.7188\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 96.5584 - mae: 96.5584 - mse: 32993.4219\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 96.0884 - mae: 96.0884 - mse: 32757.5508\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 95.7515 - mae: 95.7514 - mse: 32203.4668\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 95.3319 - mae: 95.3319 - mse: 31913.6504\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 94.9291 - mae: 94.9291 - mse: 31583.1133\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 94.6149 - mae: 94.6149 - mse: 31266.1504\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 94.3502 - mae: 94.3502 - mse: 30679.8438\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 93.9449 - mae: 93.9449 - mse: 30763.9297\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 93.6417 - mae: 93.6417 - mse: 30364.8926\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 93.2592 - mae: 93.2592 - mse: 30019.7695\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 93.1006 - mae: 93.1006 - mse: 30042.6074\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 92.9230 - mae: 92.9230 - mse: 29380.2363\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 41us/step - loss: 92.5850 - mae: 92.5850 - mse: 29504.1934\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 92.3858 - mae: 92.3858 - mse: 29056.1172\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 92.0666 - mae: 92.0666 - mse: 28708.4297\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 92.1439 - mae: 92.1439 - mse: 29077.1270\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 34us/step - loss: 92.0247 - mae: 92.0247 - mse: 28355.9473\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 91.6870 - mae: 91.6870 - mse: 28540.4102\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 91.4239 - mae: 91.4239 - mse: 28239.7070\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 91.3515 - mae: 91.3515 - mse: 27867.2500\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 91.1866 - mae: 91.1865 - mse: 27715.6680\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 91.0188 - mae: 91.0188 - mse: 27746.2090\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 90.7911 - mae: 90.7911 - mse: 27451.9375\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 90.6395 - mae: 90.6395 - mse: 27276.0078\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 90.5159 - mae: 90.5159 - mse: 27126.2832\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 90.3759 - mae: 90.3759 - mse: 27029.5430\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 90.2346 - mae: 90.2345 - mse: 26864.2207\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 90.1035 - mae: 90.1035 - mse: 26799.9141\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 89.9869 - mae: 89.9869 - mse: 26601.2578\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 89.8487 - mae: 89.8487 - mse: 26649.2617\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 89.6855 - mae: 89.6855 - mse: 26502.7852\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 89.6909 - mae: 89.6909 - mse: 26387.6758\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 363us/step - loss: 194.2264 - mae: 194.2264 - mse: 78301.5469\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 193.7637 - mae: 193.7637 - mse: 78128.1484\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 192.8636 - mae: 192.8636 - mse: 77780.4453\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 190.9673 - mae: 190.9673 - mse: 77053.5703\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 187.1954 - mae: 187.1954 - mse: 75615.7031\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 180.2479 - mae: 180.2479 - mse: 72988.0156\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 168.0596 - mae: 168.0596 - mse: 68497.9453\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 150.3697 - mae: 150.3697 - mse: 61829.5195\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 130.2314 - mae: 130.2314 - mse: 53893.9219\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 116.4064 - mae: 116.4064 - mse: 47225.1250\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 33us/step - loss: 114.1441 - mae: 114.1441 - mse: 44422.1484\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 113.6885 - mae: 113.6885 - mse: 44269.2383\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 113.3989 - mae: 113.3989 - mse: 44783.2383\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 112.9827 - mae: 112.9827 - mse: 44322.9648\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 112.6248 - mae: 112.6248 - mse: 43895.9961\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 112.2885 - mae: 112.2885 - mse: 43875.4336\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 111.9803 - mae: 111.9803 - mse: 43770.3398\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 111.6732 - mae: 111.6732 - mse: 43352.5234\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 111.3420 - mae: 111.3420 - mse: 43378.1055\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 110.9920 - mae: 110.9920 - mse: 43076.2266\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 110.7160 - mae: 110.7160 - mse: 42748.6797\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 110.3791 - mae: 110.3791 - mse: 42597.4258\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 110.2224 - mae: 110.2224 - mse: 42795.6875\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 109.8412 - mae: 109.8412 - mse: 42205.8672\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 109.4063 - mae: 109.4063 - mse: 42071.7148\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 109.0738 - mae: 109.0738 - mse: 42035.1289\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 108.7603 - mae: 108.7603 - mse: 41866.6328\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 108.5736 - mae: 108.5736 - mse: 41423.8438\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 108.3288 - mae: 108.3288 - mse: 41809.7812\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 107.7086 - mae: 107.7086 - mse: 41355.9648\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 107.4219 - mae: 107.4219 - mse: 40762.1758\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 39us/step - loss: 106.9479 - mae: 106.9480 - mse: 40526.7266\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 106.8173 - mae: 106.8173 - mse: 40946.6641\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 106.4043 - mae: 106.4043 - mse: 40318.0430\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 105.9169 - mae: 105.9169 - mse: 39937.1172\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 105.6064 - mae: 105.6064 - mse: 40085.0586\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 105.1699 - mae: 105.1699 - mse: 39662.9102\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 104.8463 - mae: 104.8463 - mse: 39222.9492\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 104.3822 - mae: 104.3822 - mse: 38938.6836\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 103.9607 - mae: 103.9607 - mse: 38784.6445\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 103.5878 - mae: 103.5878 - mse: 38414.2891\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 103.0956 - mae: 103.0956 - mse: 38071.4141\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 102.6314 - mae: 102.6313 - mse: 37758.4258\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 102.2020 - mae: 102.2020 - mse: 37590.3242\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 101.7483 - mae: 101.7483 - mse: 36914.9023\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 101.2893 - mae: 101.2893 - mse: 37052.4414\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 100.8431 - mae: 100.8431 - mse: 36486.7695\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 100.2273 - mae: 100.2273 - mse: 36289.0156\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 34us/step - loss: 99.7295 - mae: 99.7294 - mse: 35828.2500\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 99.2097 - mae: 99.2097 - mse: 35603.0469\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 98.6907 - mae: 98.6907 - mse: 35281.1250\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 98.2949 - mae: 98.2949 - mse: 35064.4570\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 97.8835 - mae: 97.8835 - mse: 34632.6836\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 97.2047 - mae: 97.2047 - mse: 34393.9062\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 39us/step - loss: 96.6647 - mae: 96.6647 - mse: 33961.0820\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 96.1447 - mae: 96.1447 - mse: 33567.8398\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 95.6120 - mae: 95.6120 - mse: 33292.1719\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 95.1151 - mae: 95.1151 - mse: 32876.2969\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 94.6431 - mae: 94.6431 - mse: 32290.8027\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 94.1467 - mae: 94.1467 - mse: 31986.3828\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 93.7550 - mae: 93.7550 - mse: 31889.2070\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 93.3031 - mae: 93.3031 - mse: 31372.8594\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 93.0228 - mae: 93.0229 - mse: 30990.2793\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 92.5861 - mae: 92.5861 - mse: 30811.4004\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 92.0385 - mae: 92.0385 - mse: 30320.5664\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 91.7595 - mae: 91.7595 - mse: 30182.7266\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 91.3467 - mae: 91.3467 - mse: 29822.9570\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 91.0424 - mae: 91.0424 - mse: 29568.3203\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 90.7475 - mae: 90.7475 - mse: 28972.8340\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 90.4821 - mae: 90.4821 - mse: 29009.9570\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 90.0966 - mae: 90.0966 - mse: 28401.0527\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 89.8745 - mae: 89.8745 - mse: 28322.5273\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 89.4621 - mae: 89.4620 - mse: 28046.6562\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 89.1332 - mae: 89.1332 - mse: 27763.5898\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 88.9719 - mae: 88.9719 - mse: 27315.8223\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 88.7380 - mae: 88.7380 - mse: 27398.4062\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 88.5119 - mae: 88.5119 - mse: 26954.9004\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 88.2749 - mae: 88.2749 - mse: 26940.6309\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 88.1783 - mae: 88.1783 - mse: 26687.7227\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 87.9860 - mae: 87.9860 - mse: 26558.8398\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 87.7941 - mae: 87.7941 - mse: 26341.7559\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 87.6265 - mae: 87.6265 - mse: 26112.3613\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 87.4161 - mae: 87.4161 - mse: 26040.4414\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 87.3810 - mae: 87.3810 - mse: 25876.2871\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 87.2259 - mae: 87.2259 - mse: 25705.0664\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 87.1176 - mae: 87.1176 - mse: 25695.2930\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 86.9934 - mae: 86.9934 - mse: 25518.9473\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 86.8693 - mae: 86.8693 - mse: 25281.7324\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 86.6767 - mae: 86.6767 - mse: 25252.6875\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 86.6487 - mae: 86.6488 - mse: 25019.9648\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 86.4981 - mae: 86.4981 - mse: 24931.8906\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 86.5550 - mae: 86.5550 - mse: 24791.1328\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 86.3198 - mae: 86.3198 - mse: 24892.8477\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 86.1767 - mae: 86.1767 - mse: 24702.4141\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 86.1773 - mae: 86.1773 - mse: 24620.2324\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 86.0257 - mae: 86.0257 - mse: 24543.7891\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 85.9203 - mae: 85.9203 - mse: 24520.4883\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 85.9869 - mae: 85.9869 - mse: 24394.2969\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 85.7918 - mae: 85.7917 - mse: 24245.0430\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 85.7367 - mae: 85.7367 - mse: 24424.8574\n",
      "Epoch 1/100\n",
      "750/750 [==============================] - 0s 306us/step - loss: 199.2154 - mae: 199.2155 - mse: 82469.6797\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 0s 33us/step - loss: 198.0688 - mae: 198.0688 - mse: 82017.3516\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 0s 38us/step - loss: 195.6314 - mae: 195.6314 - mse: 81089.1875\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 190.3744 - mae: 190.3744 - mse: 79018.9219\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 179.4476 - mae: 179.4476 - mse: 74765.6328\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 0s 34us/step - loss: 160.5153 - mae: 160.5154 - mse: 67620.1328\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 0s 33us/step - loss: 136.8838 - mae: 136.8838 - mse: 58258.1914\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 0s 33us/step - loss: 119.7953 - mae: 119.7952 - mse: 49447.6680\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 0s 31us/step - loss: 117.6757 - mae: 117.6757 - mse: 46345.5469\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 0s 33us/step - loss: 116.7479 - mae: 116.7479 - mse: 46712.3945\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 0s 31us/step - loss: 116.3243 - mae: 116.3243 - mse: 46653.0977\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 0s 35us/step - loss: 115.8993 - mae: 115.8993 - mse: 46180.2578\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 0s 31us/step - loss: 115.5183 - mae: 115.5183 - mse: 45926.2969\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 0s 32us/step - loss: 115.1170 - mae: 115.1170 - mse: 45681.6094\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 0s 35us/step - loss: 114.8097 - mae: 114.8097 - mse: 45491.2383\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 0s 33us/step - loss: 114.3854 - mae: 114.3854 - mse: 45192.8477\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 0s 34us/step - loss: 113.9046 - mae: 113.9046 - mse: 45071.7852\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 113.4981 - mae: 113.4981 - mse: 44866.8789\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 0s 30us/step - loss: 113.1326 - mae: 113.1326 - mse: 44390.4766\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 112.7232 - mae: 112.7232 - mse: 44365.5547\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 0s 39us/step - loss: 112.3526 - mae: 112.3526 - mse: 44231.0977\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 111.7963 - mae: 111.7963 - mse: 43768.1484\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 0s 37us/step - loss: 111.5088 - mae: 111.5088 - mse: 43468.6016\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 0s 33us/step - loss: 110.9913 - mae: 110.9913 - mse: 43378.3906\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 110.5567 - mae: 110.5567 - mse: 43103.2734\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 0s 33us/step - loss: 110.1443 - mae: 110.1442 - mse: 42809.4531\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 0s 41us/step - loss: 109.6945 - mae: 109.6945 - mse: 42472.5664\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 0s 33us/step - loss: 109.2874 - mae: 109.2874 - mse: 42352.2500\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 0s 41us/step - loss: 108.8361 - mae: 108.8361 - mse: 41879.4180\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 108.4094 - mae: 108.4094 - mse: 41630.8242\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 0s 43us/step - loss: 107.9850 - mae: 107.9850 - mse: 41486.6602\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 0s 34us/step - loss: 107.5751 - mae: 107.5751 - mse: 40872.9883\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 0s 40us/step - loss: 107.0626 - mae: 107.0626 - mse: 40906.6758\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 0s 35us/step - loss: 106.6230 - mae: 106.6230 - mse: 40276.6367\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 106.0894 - mae: 106.0894 - mse: 40146.8633\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 0s 42us/step - loss: 105.5266 - mae: 105.5267 - mse: 39681.3906\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 0s 33us/step - loss: 104.9903 - mae: 104.9903 - mse: 39143.7695\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 0s 38us/step - loss: 104.4669 - mae: 104.4669 - mse: 38727.6055\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 0s 40us/step - loss: 103.9919 - mae: 103.9919 - mse: 38729.2305\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 0s 34us/step - loss: 103.2111 - mae: 103.2111 - mse: 37998.0469\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 0s 39us/step - loss: 102.6255 - mae: 102.6255 - mse: 37540.7930\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 102.1503 - mae: 102.1503 - mse: 37095.4180\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 101.5318 - mae: 101.5318 - mse: 36891.6328\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 101.0478 - mae: 101.0478 - mse: 36662.2422\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 0s 35us/step - loss: 100.5714 - mae: 100.5714 - mse: 36116.5938\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 99.8410 - mae: 99.8410 - mse: 35620.3320\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 34us/step - loss: 99.3414 - mae: 99.3414 - mse: 35422.7617\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 0s 39us/step - loss: 98.7227 - mae: 98.7227 - mse: 34506.7539\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 98.2271 - mae: 98.2271 - mse: 34493.6836\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 97.6938 - mae: 97.6938 - mse: 33818.5859\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 97.1721 - mae: 97.1721 - mse: 33446.9141\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 0s 39us/step - loss: 96.7238 - mae: 96.7238 - mse: 32979.5039\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 0s 38us/step - loss: 96.0871 - mae: 96.0871 - mse: 32556.6191\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 0s 43us/step - loss: 95.7338 - mae: 95.7338 - mse: 32400.5195\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 0s 33us/step - loss: 95.2440 - mae: 95.2440 - mse: 31890.1738\n",
      "Epoch 56/100\n",
      "750/750 [==============================] - 0s 39us/step - loss: 94.7897 - mae: 94.7897 - mse: 31553.3379\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 94.3631 - mae: 94.3631 - mse: 30971.4102\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 94.0242 - mae: 94.0242 - mse: 30934.6836\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 0s 37us/step - loss: 93.4958 - mae: 93.4958 - mse: 30285.6074\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 0s 39us/step - loss: 93.2749 - mae: 93.2749 - mse: 30028.7422\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 92.9222 - mae: 92.9221 - mse: 29644.2539\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 0s 37us/step - loss: 92.5507 - mae: 92.5508 - mse: 29761.2637\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 0s 41us/step - loss: 92.3652 - mae: 92.3652 - mse: 29220.2637\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 0s 32us/step - loss: 91.9799 - mae: 91.9799 - mse: 29128.3457\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 0s 40us/step - loss: 91.7554 - mae: 91.7554 - mse: 29012.3516\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 0s 35us/step - loss: 91.5775 - mae: 91.5775 - mse: 28678.1094\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 91.4206 - mae: 91.4206 - mse: 28553.8770\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 0s 38us/step - loss: 91.1271 - mae: 91.1271 - mse: 28244.1406\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 0s 55us/step - loss: 91.2542 - mae: 91.2542 - mse: 28273.5840\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 91.0308 - mae: 91.0308 - mse: 27841.8613\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 0s 33us/step - loss: 90.6599 - mae: 90.6599 - mse: 27744.9512\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 0s 41us/step - loss: 90.4780 - mae: 90.4780 - mse: 27684.0957\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 0s 35us/step - loss: 90.3707 - mae: 90.3707 - mse: 27536.2461\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 0s 37us/step - loss: 90.2081 - mae: 90.2081 - mse: 27315.6113\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 0s 37us/step - loss: 90.1681 - mae: 90.1681 - mse: 27243.9512\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 0s 39us/step - loss: 90.0264 - mae: 90.0264 - mse: 27238.6562\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 89.9033 - mae: 89.9033 - mse: 27039.1406\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 0s 39us/step - loss: 89.8320 - mae: 89.8320 - mse: 26948.7930\n",
      "Epoch 79/100\n",
      "750/750 [==============================] - 0s 39us/step - loss: 89.6535 - mae: 89.6535 - mse: 26835.8965\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 0s 39us/step - loss: 89.6248 - mae: 89.6248 - mse: 26652.3379\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 89.4647 - mae: 89.4648 - mse: 26732.3555\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 0s 35us/step - loss: 89.4267 - mae: 89.4267 - mse: 26399.0957\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 0s 43us/step - loss: 89.1949 - mae: 89.1949 - mse: 26460.0566\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 0s 34us/step - loss: 89.0386 - mae: 89.0386 - mse: 26217.5938\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 0s 40us/step - loss: 88.9135 - mae: 88.9135 - mse: 26232.9512\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 88.8258 - mae: 88.8258 - mse: 25942.1621\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 88.7373 - mae: 88.7373 - mse: 26070.2715\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 88.6536 - mae: 88.6536 - mse: 25925.3359\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 0s 37us/step - loss: 88.4773 - mae: 88.4773 - mse: 25802.4160\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 0s 40us/step - loss: 88.4274 - mae: 88.4274 - mse: 25818.4961\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 88.2345 - mae: 88.2345 - mse: 25757.6367\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 0s 39us/step - loss: 88.3697 - mae: 88.3697 - mse: 25711.8047\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 88.0787 - mae: 88.0787 - mse: 25591.6992\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 0s 33us/step - loss: 87.9697 - mae: 87.9697 - mse: 25423.5469\n",
      "Epoch 95/100\n",
      "750/750 [==============================] - 0s 39us/step - loss: 87.9587 - mae: 87.9587 - mse: 25470.7734\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 0s 39us/step - loss: 87.8534 - mae: 87.8534 - mse: 25345.7949\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 87.6914 - mae: 87.6914 - mse: 25358.4609\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 0s 41us/step - loss: 87.6827 - mae: 87.6827 - mse: 25185.9258\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 0s 33us/step - loss: 87.5008 - mae: 87.5008 - mse: 25188.6035\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 0s 37us/step - loss: 87.5257 - mae: 87.5257 - mse: 25011.5117\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=11, activation = 'relu', input_dim=22))\n",
    "    model.add(Dense(units=11, activation = 'relu'))\n",
    "    model.add(Dense(units=11, activation = 'relu'))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error',  metrics=['mae','mse'])\n",
    "    return model\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "NN_Regressor = KerasRegressor(build_fn=build_model, batch_size=40,epochs=100)    \n",
    "\n",
    "scores = cross_val_score(NN_Regressor, X_train, y_train, cv=5, scoring=\"neg_mean_absolute_error\")\n",
    "\n",
    "NN = NN_Regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the scores for each model run\n",
      "[ -91.19046319  -83.89188298  -99.1992263   -94.6201038  -107.01524451]\n",
      " \n",
      "Mean and variance: 95.18 (+/- 15.49)\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 101.0555049255371\n",
      "Root Mean Squared Error: 34979.84705879639\n",
      "Time Taken =  41.4375\n"
     ]
    }
   ],
   "source": [
    "print(\"Below are the scores for each model run\")\n",
    "print(scores)\n",
    "print(\" \")\n",
    "print(\"Mean and variance: %0.2f (+/- %0.2f)\" % (abs(scores.mean()), scores.std() * 2))\n",
    "\n",
    "y_pred= NN_Regressor.predict(X_test_holdout)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', metrics.mean_squared_error(y_test_holdout, y_pred))\n",
    "\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
