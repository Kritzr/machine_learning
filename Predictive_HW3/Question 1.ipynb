{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as sckplt\n",
    "import time\n",
    "import re\n",
    "import scipy.stats as stat\n",
    "from math import sqrt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
    "from sklearn import linear_model, tree, neighbors, svm, ensemble\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting OS directory\n",
    "os.chdir('C:\\\\Users\\\\rckar\\\\OneDrive\\\\Documents\\\\MSBA\\\\Fall Semester\\\\6420 Predictive Analytics\\\\HW3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_number</th>\n",
       "      <th>US</th>\n",
       "      <th>source_a</th>\n",
       "      <th>source_c</th>\n",
       "      <th>source_b</th>\n",
       "      <th>source_d</th>\n",
       "      <th>source_e</th>\n",
       "      <th>source_m</th>\n",
       "      <th>source_o</th>\n",
       "      <th>source_h</th>\n",
       "      <th>...</th>\n",
       "      <th>source_x</th>\n",
       "      <th>source_w</th>\n",
       "      <th>Freq</th>\n",
       "      <th>last_update_days_ago</th>\n",
       "      <th>1st_update_days_ago</th>\n",
       "      <th>Web order</th>\n",
       "      <th>Gender=male</th>\n",
       "      <th>Address_is_res</th>\n",
       "      <th>Purchase</th>\n",
       "      <th>Spending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2900</td>\n",
       "      <td>2900</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>829</td>\n",
       "      <td>829</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_number  US  source_a  source_c  source_b  source_d  source_e  \\\n",
       "0                2   1         0         0         0         0         1   \n",
       "1                4   1         0         1         0         0         0   \n",
       "\n",
       "   source_m  source_o  source_h  ...  source_x  source_w  Freq  \\\n",
       "0         0         0         0  ...         0         0     0   \n",
       "1         0         0         0  ...         0         0     1   \n",
       "\n",
       "   last_update_days_ago  1st_update_days_ago  Web order  Gender=male  \\\n",
       "0                  2900                 2900          1            1   \n",
       "1                   829                  829          0            1   \n",
       "\n",
       "   Address_is_res  Purchase  Spending  \n",
       "0               0         0       0.0  \n",
       "1               0         0       0.0  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading Data\n",
    "df = pd.read_excel(\"HW3.xlsx\")\n",
    "df.head(2)\n",
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data pre-processing\n",
    "\n",
    "# checking for null values\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting required columns\n",
    "X_df = df.iloc[:,1:23]\n",
    "y_df = df.iloc[:,24:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating the Train and Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test_holdout, y_train, y_test_holdout = train_test_split(X_df, y_df, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train_scaled)\n",
    "\n",
    "x_test_scaled = scaler.fit_transform(X_test_holdout)\n",
    "X_test_holdout = pd.DataFrame(x_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the mean squared errors for each model run\n",
      "[-26275.29554033 -14376.09803371 -17587.92789557 -20491.5690275\n",
      "  -8717.39746787]\n",
      " \n",
      "Mean score: 17489.66 \n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 74.91249390506677\n",
      "Root Mean Squared Error: 116.83025324452498\n",
      "r2: 0.5681889233817079\n",
      " \n",
      "Time Taken =  0.09375\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "# create linear regression object \n",
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "# cross validation \n",
    "scores = cross_val_score(lr, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "print(\"Below are the mean squared errors for each model run\")\n",
    "print(scores)\n",
    "print(\" \")\n",
    "print(\"Mean score: %0.2f \" % (abs(scores.mean())))\n",
    "\n",
    "# Model fit on training data and predicting on testing data\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test_holdout)\n",
    "\n",
    "# Model performance on testing data\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "# print('Explained Variance:',metrics.explained_variance_score(y_test_holdout, y_pred))\n",
    "print('r2:',metrics.r2_score(y_test_holdout, y_pred))\n",
    "\n",
    "print(\" \")\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score achieved across all parameters:  17392.052253586684\n",
      " \n",
      "Best parameters\n",
      "{'alpha': 0.30000000000000004}\n",
      " \n",
      "Best estimator\n",
      "Lasso(alpha=0.30000000000000004, copy_X=True, fit_intercept=True,\n",
      "   max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "   random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 73.91843476603411\n",
      "Root Mean Squared Error: 116.69198704602064\n",
      "r2: 0.5692103976083474\n",
      "Time Taken =  1.0625\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "lasso = linear_model.Lasso()\n",
    "\n",
    "#Hyper Parameter tuning\n",
    "param_set ={'alpha': list(np.arange(0.1,2,0.2))}\n",
    "grid_lasso = GridSearchCV(lasso, param_grid = param_set, cv=5, scoring='neg_mean_squared_error', verbose = 0)\n",
    "grid_lasso.fit(X_train,y_train)\n",
    "\n",
    "# examine the best model\n",
    "print(\"Best score achieved across all parameters: \", abs(grid_lasso.best_score_))\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(\" \")\n",
    "print(\"Best parameters\")\n",
    "print (grid_lasso.best_params_)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Best estimator\")\n",
    "print (grid_lasso.best_estimator_)\n",
    "\n",
    "# predicting on test data\n",
    "lasso = grid_lasso.best_estimator_\n",
    "lasso.fit(X_train,y_train)\n",
    "y_pred = lasso.predict(X_test_holdout)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "print('r2:',metrics.r2_score(y_test_holdout, y_pred))\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score achieved across all parameters:  17488.69461332572\n",
      " \n",
      "Best parameters\n",
      "{'alpha': 0.1}\n",
      " \n",
      "Best estimator\n",
      "Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 74.7465722508253\n",
      "Root Mean Squared Error: 116.81233210323924\n",
      "r2: 0.5683213882796581\n",
      "Time Taken =  1.125\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "ridge = linear_model.Ridge()\n",
    "\n",
    "#Hyper Parameter tuning\n",
    "param_set ={'alpha': list(np.arange(0.1,2,0.2))}\n",
    "grid_ridge = GridSearchCV(ridge, param_grid = param_set, cv=5, scoring='neg_mean_squared_error', verbose = 0)\n",
    "grid_ridge.fit(X_train,y_train)\n",
    "\n",
    "# examine the best model\n",
    "print(\"Best score achieved across all parameters: \", abs(grid_ridge.best_score_))\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(\" \")\n",
    "print(\"Best parameters\")\n",
    "print (grid_ridge.best_params_)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Best estimator\")\n",
    "print (grid_ridge.best_estimator_)\n",
    "\n",
    "# predicting on test data\n",
    "ridge = grid_ridge.best_estimator_\n",
    "ridge.fit(X_train,y_train)\n",
    "y_pred = ridge.predict(X_test_holdout)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "print('r2:',metrics.r2_score(y_test_holdout, y_pred))\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score achieved across all parameters:  29408.948720197557\n",
      " \n",
      "Best parameters\n",
      "{'n_neighbors': 6, 'weights': 'distance'}\n",
      " \n",
      "Best estimator\n",
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=None, n_neighbors=6, p=2,\n",
      "          weights='distance')\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 87.49654931477475\n",
      "Root Mean Squared Error: 156.19356346084825\n",
      "r2: 0.22819176395089769\n",
      "Time Taken =  20.34375\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "knn = neighbors.KNeighborsRegressor()\n",
    "\n",
    "#Hyper Parameter tuning\n",
    "param_set ={'n_neighbors': list(range(1,30)), 'weights': [\"uniform\", \"distance\"]}\n",
    "grid_knn = GridSearchCV(knn, param_grid = param_set, cv=5, scoring='neg_mean_squared_error', verbose = 0)\n",
    "grid_knn.fit(X_train,y_train)\n",
    "\n",
    "# examine the best model\n",
    "print(\"Best score achieved across all parameters: \", abs(grid_knn.best_score_))\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(\" \")\n",
    "print(\"Best parameters\")\n",
    "print (grid_knn.best_params_)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Best estimator\")\n",
    "print (grid_knn.best_estimator_)\n",
    "\n",
    "# predicting on test data\n",
    "knn = grid_knn.best_estimator_\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test_holdout)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "print('r2:',metrics.r2_score(y_test_holdout, y_pred))\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score achieved across all parameters:  18994.77142166768\n",
      " \n",
      "Best parameters\n",
      "{'max_depth': 5, 'min_samples_split': 23}\n",
      " \n",
      "Best estimator\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=23, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best')\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 71.19281199747084\n",
      "Root Mean Squared Error: 126.25980914215464\n",
      "r2: 0.4956716299205547\n",
      "Time Taken =  17.71875\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "DTree = tree.DecisionTreeRegressor()\n",
    "\n",
    "#Hyper parameter tuning\n",
    "param_set ={'max_depth': range(1,20), 'min_samples_split' : range(2,30)}\n",
    "grid_DTree = GridSearchCV(DTree, param_grid = param_set, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_DTree.fit(X_train,y_train)\n",
    "\n",
    "# examine the best model\n",
    "print(\"Best score achieved across all parameters: \", abs(grid_DTree.best_score_))\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(\" \")\n",
    "print(\"Best parameters\")\n",
    "print (grid_DTree.best_params_)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Best estimator\")\n",
    "print (grid_DTree.best_estimator_)\n",
    "\n",
    "# predicting on test data\n",
    "DTree = grid_DTree.best_estimator_\n",
    "DTree.fit(X_train,y_train)\n",
    "y_pred = DTree.predict(X_test_holdout)\n",
    "\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "print('r2:',metrics.r2_score(y_test_holdout, y_pred))\n",
    "\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score achieved across all parameters:  20500.123168359678\n",
      " \n",
      "Best parameters\n",
      "{'C': 100, 'epsilon': 0.5, 'kernel': 'linear'}\n",
      " \n",
      "Best estimator\n",
      "SVR(C=100, cache_size=200, coef0=0.0, degree=3, epsilon=0.5,\n",
      "  gamma='auto_deprecated', kernel='linear', max_iter=-1, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 69.88486548166671\n",
      "Root Mean Squared Error: 129.4836060521223\n",
      "r2: 0.504335538704678\n",
      "Time Taken =  48.796875\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "SVR = svm.SVR()\n",
    "# Hyper parameter tuning using GridSearch\n",
    "param_set = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1,2,10,100,1000], 'epsilon':[0.05,0.1,0.2,0.3,0.5]},\n",
    "                    {'kernel': ['linear'], 'C': [1,2,5,10,100], 'epsilon':[0.05,0.1,0.2,0.3,0.5]}]\n",
    "grid_SVR = GridSearchCV(SVR, param_grid = param_set, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_SVR.fit(X_train,y_train)\n",
    "\n",
    "# examine the best model\n",
    "print(\"Best score achieved across all parameters: \", abs(grid_SVR.best_score_))\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(\" \")\n",
    "print(\"Best parameters\")\n",
    "print (grid_SVR.best_params_)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Best estimator\")\n",
    "print (grid_SVR.best_estimator_)\n",
    "\n",
    "# predicting on test data\n",
    "SVR = grid_SVR.best_estimator_\n",
    "SVR.fit(X_train,y_train)\n",
    "y_pred = SVR.predict(X_test_holdout)\n",
    "\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "print('r2:',metrics.explained_variance_score(y_test_holdout, y_pred))\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble model : Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score achieved across all parameters:  18302.950738293828\n",
      " \n",
      "Best parameters\n",
      "{'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_split': 10, 'n_estimators': 500, 'n_jobs': -1}\n",
      " \n",
      "Best estimator\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=10,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 65.43789920107508\n",
      "Root Mean Squared Error: 115.2175324613487\n",
      "r2: 0.5800521264304828\n",
      " \n",
      "Time Taken =  192.671875\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "RF = ensemble.RandomForestRegressor()\n",
    "\n",
    "# Hyper parameter tuning using GridSearch\n",
    "param_set ={'max_depth': [3,10,20],\n",
    "            'min_samples_split' :[4,5,10],\n",
    "            'n_estimators': [100,250,500],\n",
    "            'bootstrap':[True, False] ,\n",
    "            'max_features':['auto','sqrt'],\n",
    "            'n_jobs':[-1]\n",
    "           }\n",
    "grid_RF = GridSearchCV(RF, param_grid = param_set, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_RF.fit(X_train,y_train)\n",
    "\n",
    "# examine the best model\n",
    "print(\"Best score achieved across all parameters: \", abs(grid_RF.best_score_))\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(\" \")\n",
    "print(\"Best parameters\")\n",
    "print (grid_RF.best_params_)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Best estimator\")\n",
    "print (grid_RF.best_estimator_)\n",
    "\n",
    "# predicting on test data\n",
    "RF = grid_RF.best_estimator_\n",
    "RF.fit(X_train,y_train)\n",
    "y_pred = RF.predict(X_test_holdout)\n",
    "\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "print('r2:',metrics.explained_variance_score(y_test_holdout, y_pred))\n",
    "print(\" \")\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble model : XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:06:42] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:43] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:43] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:43] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:44] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:44] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:44] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:44] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:44] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:44] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:45] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:45] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:45] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:48] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:48] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:48] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:48] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:48] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:49] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:49] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:49] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:49] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:49] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:50] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:50] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:50] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:51] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:51] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:51] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:51] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:51] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:06:51] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score achieved across all parameters:  20004.950942708016\n",
      " \n",
      "Best parameters\n",
      "{'colsample_bytree': 0.9816823845945403, 'gamma': 9.52308795761162, 'learning_rate': 0.16537402362986742, 'max_depth': 9, 'n_estimators': 17, 'n_jobs': -1, 'subsample': 0.9837701891769275}\n",
      " \n",
      "Best estimator\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bynode=1, colsample_bytree=0.9816823845945403,\n",
      "       gamma=9.52308795761162, importance_type='gain',\n",
      "       learning_rate=0.16537402362986742, max_delta_step=0, max_depth=9,\n",
      "       min_child_weight=1, missing=None, n_estimators=17, n_jobs=-1,\n",
      "       nthread=None, nthreads=-1, objective='reg:linear', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=None, subsample=0.9837701891769275, verbosity=1)\n",
      "[16:06:51] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Time Taken =  61.265625\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "XGB = xgboost.XGBRegressor(nthreads=-1)\n",
    "\n",
    "a = stat.beta(10, 1)\n",
    "\n",
    "# Hyper parameter tuning using GridSearch\n",
    "param_set ={\"n_estimators\": stat.randint(3, 40),\n",
    "            \"max_depth\": stat.randint(3, 40),\n",
    "            \"learning_rate\": stat.uniform(0.05, 0.4),\n",
    "            \"colsample_bytree\": a,\n",
    "            \"subsample\": a,\n",
    "            \"gamma\": stat.uniform(0, 10),\n",
    "            'n_jobs':[-1]\n",
    "           }\n",
    "\n",
    "grid_XGB = RandomizedSearchCV(XGB, param_set, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_XGB.fit(X_train,y_train)\n",
    "\n",
    "# examine the best model\n",
    "print(\"Best score achieved across all parameters: \", abs(grid_XGB.best_score_))\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(\" \")\n",
    "print(\"Best parameters\")\n",
    "print (grid_XGB.best_params_)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Best estimator\")\n",
    "print (grid_XGB.best_estimator_)\n",
    "\n",
    "# predicting on test data\n",
    "XGB = grid_XGB.best_estimator_\n",
    "XGB.fit(X_train,y_train)\n",
    "y_pred = XGB.predict(X_test_holdout)\n",
    "\n",
    "# print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "# print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "# print('r2:',metrics.explained_variance_score(y_test_holdout, y_pred))\n",
    "# print(\" \")\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:06:51] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 66.09869929092885\n",
      "Root Mean Squared Error: 118.75969887205845\n",
      "r2: 0.5566621246892616\n"
     ]
    }
   ],
   "source": [
    "# predicting on test data\n",
    "XGB = grid_XGB.best_estimator_\n",
    "XGB.fit(X_train,y_train)\n",
    "y_pred = XGB.predict(X_test_holdout)\n",
    "\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "print('r2:',metrics.explained_variance_score(y_test_holdout, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shallow Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 86408.9516 - mae: 205.0695 - mse: 86408.9375\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 86231.3344 - mae: 204.6306 - mse: 86231.3438\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 86057.6057 - mae: 204.1972 - mse: 86057.6172\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 85872.2539 - mae: 203.7346 - mse: 85872.2500\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 85663.6621 - mae: 203.2155 - mse: 85663.6562\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 85418.0018 - mae: 202.6086 - mse: 85417.9922\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 85138.1362 - mae: 201.9070 - mse: 85138.1328\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 84814.7635 - mae: 201.1113 - mse: 84814.7500\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 84460.2926 - mae: 200.2202 - mse: 84460.2969\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 84065.8320 - mae: 199.2241 - mse: 84065.8438\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 83631.7802 - mae: 198.1267 - mse: 83631.7812\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 83156.3784 - mae: 196.9318 - mse: 83156.3750\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 82638.1398 - mae: 195.6400 - mse: 82638.1484\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 82089.6104 - mae: 194.2406 - mse: 82089.6094\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 81492.3148 - mae: 192.7802 - mse: 81492.3125\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 119us/step - loss: 80877.9366 - mae: 191.2167 - mse: 80877.9297\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 80221.3052 - mae: 189.5629 - mse: 80221.3047\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 79525.7973 - mae: 187.8290 - mse: 79525.7969\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 78827.1266 - mae: 186.0134 - mse: 78827.1250\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 78089.6151 - mae: 184.0751 - mse: 78089.6172\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 98us/step - loss: 77327.2729 - mae: 182.0948 - mse: 77327.2812\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 76566.9893 - mae: 180.0311 - mse: 76566.9844\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 75752.8464 - mae: 177.9771 - mse: 75752.8438\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 74927.4199 - mae: 175.8315 - mse: 74927.4219\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 74074.4729 - mae: 173.6898 - mse: 74074.4766\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 109us/step - loss: 73203.5087 - mae: 171.3961 - mse: 73203.5078\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 72284.0723 - mae: 169.1612 - mse: 72284.0703\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 127us/step - loss: 71372.4902 - mae: 166.8630 - mse: 71372.4922\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 70451.5158 - mae: 164.5213 - mse: 70451.5234\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 69489.0969 - mae: 162.1848 - mse: 69489.1016\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 68565.1872 - mae: 159.8541 - mse: 68565.1875\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 67612.9738 - mae: 157.5780 - mse: 67612.9688\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 97us/step - loss: 66662.9517 - mae: 155.3193 - mse: 66662.9453\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 65717.7384 - mae: 153.1571 - mse: 65717.7344\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 112us/step - loss: 64813.2505 - mae: 150.9732 - mse: 64813.2539\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 63875.5033 - mae: 148.7727 - mse: 63875.5078\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 62998.1022 - mae: 146.6979 - mse: 62998.1055\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 62118.7859 - mae: 144.6290 - mse: 62118.7852\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 61237.1388 - mae: 142.6526 - mse: 61237.1328\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 60413.5827 - mae: 140.7123 - mse: 60413.5859\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 59580.9628 - mae: 138.8812 - mse: 59580.9609\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 142us/step - loss: 58803.5306 - mae: 137.1587 - mse: 58803.5352\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 58015.0093 - mae: 135.4610 - mse: 58015.0078\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 57263.6124 - mae: 133.8542 - mse: 57263.6133\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 109us/step - loss: 56585.2001 - mae: 132.2308 - mse: 56585.1992\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 55856.4880 - mae: 130.7368 - mse: 55856.4922\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 55210.2288 - mae: 129.4093 - mse: 55210.2383\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 54566.2263 - mae: 128.1890 - mse: 54566.2266\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 53969.4996 - mae: 127.0523 - mse: 53969.5000\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 53399.1875 - mae: 126.0943 - mse: 53399.1914\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 52829.7209 - mae: 125.1699 - mse: 52829.7227\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 52315.2930 - mae: 124.3979 - mse: 52315.2930\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 51834.7375 - mae: 123.6870 - mse: 51834.7344\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 51343.8885 - mae: 123.1680 - mse: 51343.8867\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 94us/step - loss: 50889.5883 - mae: 122.7246 - mse: 50889.5859\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 126us/step - loss: 50478.9246 - mae: 122.3523 - mse: 50478.9219\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 50071.6970 - mae: 122.0873 - mse: 50071.6953\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 49691.1927 - mae: 121.9212 - mse: 49691.1953\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 49368.6701 - mae: 121.8001 - mse: 49368.6719\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 49038.9357 - mae: 121.7778 - mse: 49038.9375\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 48730.9982 - mae: 121.8083 - mse: 48731.0000\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 48456.9376 - mae: 121.8769 - mse: 48456.9414\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 48209.7094 - mae: 122.0100 - mse: 48209.7148\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 47964.0756 - mae: 122.2101 - mse: 47964.0742\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 47746.5854 - mae: 122.4405 - mse: 47746.5820\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 47550.2611 - mae: 122.6714 - mse: 47550.2539\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 111us/step - loss: 47367.1505 - mae: 122.9415 - mse: 47367.1484\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 47187.7520 - mae: 123.1646 - mse: 47187.7500\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 47032.3105 - mae: 123.4492 - mse: 47032.3086\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 46883.9021 - mae: 123.7406 - mse: 46883.8984\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 46757.9192 - mae: 124.0537 - mse: 46757.9180\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 107us/step - loss: 46635.8461 - mae: 124.3782 - mse: 46635.8477\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 46518.8475 - mae: 124.5692 - mse: 46518.8516\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 46410.2217 - mae: 124.8043 - mse: 46410.2227\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 46327.4534 - mae: 125.0752 - mse: 46327.4531\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 128us/step - loss: 46226.4943 - mae: 125.2733 - mse: 46226.4961\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 46160.1928 - mae: 125.5695 - mse: 46160.1914\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 46058.9619 - mae: 125.7122 - mse: 46058.9648\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 45994.5445 - mae: 125.9034 - mse: 45994.5469\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 45925.4189 - mae: 126.1367 - mse: 45925.4219\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 126us/step - loss: 45856.7339 - mae: 126.3173 - mse: 45856.7305\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 45795.3923 - mae: 126.4815 - mse: 45795.3945\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 45733.9464 - mae: 126.6979 - mse: 45733.9453\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 45671.1129 - mae: 126.8393 - mse: 45671.1055\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 45615.5493 - mae: 126.8595 - mse: 45615.5469\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 45558.7792 - mae: 126.9858 - mse: 45558.7773\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 45502.6115 - mae: 127.1596 - mse: 45502.6133\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 45440.1698 - mae: 127.1999 - mse: 45440.1719\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 45394.1969 - mae: 127.3167 - mse: 45394.1914\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 45335.2467 - mae: 127.3792 - mse: 45335.2383\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 45280.1967 - mae: 127.3252 - mse: 45280.1953\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 45228.8835 - mae: 127.4003 - mse: 45228.8828\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 45175.4258 - mae: 127.3645 - mse: 45175.4297\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 45125.6100 - mae: 127.4516 - mse: 45125.6016\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 109us/step - loss: 45067.7782 - mae: 127.4704 - mse: 45067.7773\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 45012.3119 - mae: 127.4624 - mse: 45012.3086\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 44966.2410 - mae: 127.4012 - mse: 44966.2422\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 44915.2154 - mae: 127.4506 - mse: 44915.2148\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 44857.6516 - mae: 127.4442 - mse: 44857.6484\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 44810.0691 - mae: 127.4683 - mse: 44810.0703\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 89016.0750 - mae: 205.4669 - mse: 89016.0703\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 88833.3104 - mae: 205.0118 - mse: 88833.3047\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 83us/step - loss: 88641.6044 - mae: 204.5318 - mse: 88641.6016\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 88425.1721 - mae: 204.0010 - mse: 88425.1719\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 88178.1716 - mae: 203.3809 - mse: 88178.1641\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 87880.4186 - mae: 202.6631 - mse: 87880.4297\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 114us/step - loss: 87538.3094 - mae: 201.7994 - mse: 87538.3203\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 87125.2486 - mae: 200.7810 - mse: 87125.2500\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 86659.3164 - mae: 199.6077 - mse: 86659.3203\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 86119.4844 - mae: 198.2866 - mse: 86119.4844\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 85537.9885 - mae: 196.8224 - mse: 85537.9844\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 84884.5060 - mae: 195.2538 - mse: 84884.5000\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 84188.0568 - mae: 193.5388 - mse: 84188.0469\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 83431.0276 - mae: 191.6806 - mse: 83431.0312\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 82627.9070 - mae: 189.6759 - mse: 82627.9062\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 119us/step - loss: 81781.7659 - mae: 187.4863 - mse: 81781.7734\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 80907.0182 - mae: 185.1782 - mse: 80907.0234\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 79969.3289 - mae: 182.7201 - mse: 79969.3438\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 78984.4151 - mae: 180.2466 - mse: 78984.4219\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 78012.5918 - mae: 177.7119 - mse: 78012.6016\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 76976.5018 - mae: 175.0683 - mse: 76976.5000\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 75942.7323 - mae: 172.4467 - mse: 75942.7266\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 74897.9641 - mae: 169.7885 - mse: 74897.9688\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 73806.5901 - mae: 167.0462 - mse: 73806.5781\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 72719.0842 - mae: 164.3759 - mse: 72719.0781\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 71613.4160 - mae: 161.6634 - mse: 71613.4219\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 70514.7517 - mae: 159.0540 - mse: 70514.7500\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 69393.2635 - mae: 156.4673 - mse: 69393.2656\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 68292.5260 - mae: 153.8891 - mse: 68292.5312\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 67199.9264 - mae: 151.2269 - mse: 67199.9297\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 126us/step - loss: 66130.7462 - mae: 148.6624 - mse: 66130.7500\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 65050.2967 - mae: 146.3144 - mse: 65050.3008\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 116us/step - loss: 64024.8953 - mae: 143.9886 - mse: 64024.8945\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 119us/step - loss: 63013.1906 - mae: 141.7873 - mse: 63013.1875\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 134us/step - loss: 62021.7443 - mae: 139.6353 - mse: 62021.7461\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 61074.7951 - mae: 137.5847 - mse: 61074.8008\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 60171.2630 - mae: 135.6227 - mse: 60171.2617\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 59269.5309 - mae: 133.7991 - mse: 59269.5391\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 58470.4533 - mae: 132.0267 - mse: 58470.4609\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 57664.8647 - mae: 130.4414 - mse: 57664.8672\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 56897.8085 - mae: 129.0047 - mse: 56897.8125\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 56192.8919 - mae: 127.8427 - mse: 56192.8945\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 55492.4486 - mae: 126.7738 - mse: 55492.4453\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 54860.4797 - mae: 125.8513 - mse: 54860.4805\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 54289.5533 - mae: 125.0337 - mse: 54289.5547\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 114us/step - loss: 53728.5919 - mae: 124.3480 - mse: 53728.5938\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 53211.1905 - mae: 123.7924 - mse: 53211.1914\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 52749.4408 - mae: 123.4293 - mse: 52749.4375\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 52292.4992 - mae: 123.1565 - mse: 52292.5000\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 51878.2199 - mae: 122.8708 - mse: 51878.2227\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 51520.1410 - mae: 122.8248 - mse: 51520.1406\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 51155.5043 - mae: 122.6773 - mse: 51155.5078\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 122us/step - loss: 50840.2222 - mae: 122.7588 - mse: 50840.2188\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 50597.5546 - mae: 122.9039 - mse: 50597.5586\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 50292.0747 - mae: 123.0308 - mse: 50292.0742\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 50072.0869 - mae: 123.2518 - mse: 50072.0820\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 49852.0919 - mae: 123.4536 - mse: 49852.0938\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 49663.2044 - mae: 123.7314 - mse: 49663.2031\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 49476.7309 - mae: 123.9910 - mse: 49476.7344\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 122us/step - loss: 49303.5451 - mae: 124.2443 - mse: 49303.5469\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 49166.0554 - mae: 124.5192 - mse: 49166.0547\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 49031.5991 - mae: 124.7818 - mse: 49031.5938\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 48895.2900 - mae: 125.0339 - mse: 48895.2891\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 48797.3473 - mae: 125.2966 - mse: 48797.3477\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 48681.4203 - mae: 125.5751 - mse: 48681.4219\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 112us/step - loss: 48584.8701 - mae: 125.8498 - mse: 48584.8711\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 48498.9345 - mae: 126.1373 - mse: 48498.9414\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 48400.6122 - mae: 126.3380 - mse: 48400.6094\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 48330.1215 - mae: 126.5288 - mse: 48330.1250\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 48259.3134 - mae: 126.8254 - mse: 48259.3086\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 48176.2724 - mae: 127.0020 - mse: 48176.2734\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 48110.8364 - mae: 127.1731 - mse: 48110.8320\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 104us/step - loss: 48043.6941 - mae: 127.3226 - mse: 48043.6953\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 47990.3641 - mae: 127.5353 - mse: 47990.3633\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 47920.8408 - mae: 127.6941 - mse: 47920.8438\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 47857.5469 - mae: 127.7768 - mse: 47857.5469\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 47802.2183 - mae: 127.8536 - mse: 47802.2227\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 124us/step - loss: 47742.7063 - mae: 127.9466 - mse: 47742.7109\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 122us/step - loss: 47689.5695 - mae: 128.0425 - mse: 47689.5742\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 47631.0738 - mae: 128.0753 - mse: 47631.0742\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 47578.7187 - mae: 128.1396 - mse: 47578.7188\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 47522.4757 - mae: 128.2117 - mse: 47522.4766\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 47470.3819 - mae: 128.2380 - mse: 47470.3789\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 47424.5281 - mae: 128.4065 - mse: 47424.5273\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 47362.2364 - mae: 128.3993 - mse: 47362.2344\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 47311.2060 - mae: 128.3334 - mse: 47311.2109\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 47260.4171 - mae: 128.3605 - mse: 47260.4141\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 47208.4564 - mae: 128.3389 - mse: 47208.4570\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 47155.1935 - mae: 128.3472 - mse: 47155.1914\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 47102.3531 - mae: 128.4688 - mse: 47102.3477\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 114us/step - loss: 47051.6755 - mae: 128.4357 - mse: 47051.6758\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 47005.5686 - mae: 128.4965 - mse: 47005.5625\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 107us/step - loss: 46943.8328 - mae: 128.4885 - mse: 46943.8359\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 46892.1546 - mae: 128.4572 - mse: 46892.1523\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 46851.5938 - mae: 128.5334 - mse: 46851.6016\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 46786.1465 - mae: 128.4222 - mse: 46786.1484\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 46739.6274 - mae: 128.2509 - mse: 46739.6250\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 46691.3583 - mae: 128.2590 - mse: 46691.3594\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 123us/step - loss: 46630.1695 - mae: 128.1787 - mse: 46630.1680\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 46573.3979 - mae: 128.1124 - mse: 46573.3984\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 78031.5372 - mae: 195.4512 - mse: 78031.5312\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 77900.8827 - mae: 195.1091 - mse: 77900.8828\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 77756.4608 - mae: 194.7412 - mse: 77756.4609\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 77589.6331 - mae: 194.3027 - mse: 77589.6328\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 77380.4841 - mae: 193.7699 - mse: 77380.4844\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 77128.6013 - mae: 193.1083 - mse: 77128.6094\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 76825.9576 - mae: 192.3130 - mse: 76825.9453\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 76475.3547 - mae: 191.3818 - mse: 76475.3516\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 98us/step - loss: 76073.8583 - mae: 190.3500 - mse: 76073.8672\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 75626.6395 - mae: 189.1973 - mse: 75626.6328\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 109us/step - loss: 75152.8807 - mae: 187.9229 - mse: 75152.8750\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 74629.2469 - mae: 186.5485 - mse: 74629.2422\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 74071.6448 - mae: 185.1187 - mse: 74071.6484\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 73480.6568 - mae: 183.6035 - mse: 73480.6562\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 72883.2915 - mae: 182.0023 - mse: 72883.2969\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 72233.0486 - mae: 180.2807 - mse: 72233.0391\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 71539.6497 - mae: 178.4846 - mse: 71539.6484\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 112us/step - loss: 70842.5396 - mae: 176.5713 - mse: 70842.5391\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 70107.3573 - mae: 174.5539 - mse: 70107.3516\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 69341.9422 - mae: 172.4627 - mse: 69341.9375\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 126us/step - loss: 68542.1669 - mae: 170.3396 - mse: 68542.1641\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 133us/step - loss: 67756.3783 - mae: 168.1301 - mse: 67756.3750\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 66928.9807 - mae: 165.8948 - mse: 66928.9766\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 66100.0419 - mae: 163.6134 - mse: 66100.0312\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 65256.0675 - mae: 161.3337 - mse: 65256.0664\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 64398.8694 - mae: 159.0217 - mse: 64398.8672\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 63550.9098 - mae: 156.7773 - mse: 63550.9062\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 62670.4456 - mae: 154.4530 - mse: 62670.4453\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 61835.3742 - mae: 152.2854 - mse: 61835.3672\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 60951.9673 - mae: 150.0269 - mse: 60951.9648\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 60118.5428 - mae: 147.8904 - mse: 60118.5469\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 59258.0555 - mae: 145.7464 - mse: 59258.0547\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 58418.7212 - mae: 143.6557 - mse: 58418.7266\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 57591.6392 - mae: 141.6102 - mse: 57591.6406\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 56785.1659 - mae: 139.5567 - mse: 56785.1680\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 55967.8852 - mae: 137.5447 - mse: 55967.8867\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 130us/step - loss: 55181.0318 - mae: 135.5771 - mse: 55181.0273\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 54422.6947 - mae: 133.6981 - mse: 54422.6914\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 53662.3535 - mae: 131.8610 - mse: 53662.3516\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 52923.8396 - mae: 130.0877 - mse: 52923.8398\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 52225.8634 - mae: 128.3903 - mse: 52225.8594\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 119us/step - loss: 51548.4098 - mae: 126.6901 - mse: 51548.4062\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 50889.5433 - mae: 125.1722 - mse: 50889.5430\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 128us/step - loss: 50236.3144 - mae: 123.6249 - mse: 50236.3125\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 49648.5768 - mae: 122.2082 - mse: 49648.5781\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 49039.8058 - mae: 120.8439 - mse: 49039.8086\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 48497.9042 - mae: 119.7002 - mse: 48497.9023\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 47970.7878 - mae: 118.5459 - mse: 47970.7891\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 47453.5939 - mae: 117.6457 - mse: 47453.5977\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 46975.6743 - mae: 116.7932 - mse: 46975.6719\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 46526.4294 - mae: 116.0153 - mse: 46526.4297\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 46085.9203 - mae: 115.4144 - mse: 46085.9219\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 45699.0713 - mae: 114.8362 - mse: 45699.0664\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 45299.3196 - mae: 114.3374 - mse: 45299.3164\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 112us/step - loss: 44939.4236 - mae: 113.9364 - mse: 44939.4219\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 44636.0033 - mae: 113.6940 - mse: 44636.0078\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 44295.1580 - mae: 113.3028 - mse: 44295.1602\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 44028.4510 - mae: 113.2642 - mse: 44028.4531\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 43750.2320 - mae: 113.0881 - mse: 43750.2344\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 43499.0014 - mae: 113.0085 - mse: 43499.0039\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 43266.1863 - mae: 112.9657 - mse: 43266.1836\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 43054.6654 - mae: 113.0747 - mse: 43054.6641\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 42866.1033 - mae: 113.1964 - mse: 42866.1016\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 42680.7993 - mae: 113.3506 - mse: 42680.8008\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 116us/step - loss: 42513.3040 - mae: 113.4993 - mse: 42513.3047\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 42353.4087 - mae: 113.6662 - mse: 42353.4102\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 42222.2393 - mae: 113.9107 - mse: 42222.2383\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 126us/step - loss: 42084.7783 - mae: 114.1310 - mse: 42084.7734\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 41968.3167 - mae: 114.4181 - mse: 41968.3125\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 41858.0033 - mae: 114.6479 - mse: 41858.0039\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 41750.1720 - mae: 114.8549 - mse: 41750.1680\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 41660.3246 - mae: 115.1229 - mse: 41660.3242\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 41566.9323 - mae: 115.3424 - mse: 41566.9336\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 41488.4430 - mae: 115.5214 - mse: 41488.4414\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 41421.4354 - mae: 115.7782 - mse: 41421.4336\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 41337.4462 - mae: 115.9525 - mse: 41337.4453\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 41286.7343 - mae: 116.2015 - mse: 41286.7383\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 41213.0391 - mae: 116.3447 - mse: 41213.0391\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 41154.4372 - mae: 116.5028 - mse: 41154.4375\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 41102.5285 - mae: 116.6971 - mse: 41102.5312\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 41050.1962 - mae: 116.8585 - mse: 41050.1992\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 133us/step - loss: 40998.5467 - mae: 116.9993 - mse: 40998.5508\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 40945.1364 - mae: 117.1045 - mse: 40945.1406\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 40905.0783 - mae: 117.2201 - mse: 40905.0781\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 40855.0081 - mae: 117.3185 - mse: 40855.0078\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 119us/step - loss: 40824.7698 - mae: 117.4870 - mse: 40824.7656\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 40768.6660 - mae: 117.5594 - mse: 40768.6680\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 128us/step - loss: 40729.1013 - mae: 117.6073 - mse: 40729.1016\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 40690.6049 - mae: 117.7270 - mse: 40690.6016\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 40653.7897 - mae: 117.8927 - mse: 40653.7891\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 40609.5741 - mae: 117.9421 - mse: 40609.5703\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 40571.8626 - mae: 118.0013 - mse: 40571.8711\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 40531.9531 - mae: 118.0376 - mse: 40531.9492\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 126us/step - loss: 40496.6253 - mae: 118.0553 - mse: 40496.6250\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 40456.5043 - mae: 118.1699 - mse: 40456.5078\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 40407.7559 - mae: 118.1111 - mse: 40407.7578\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 80us/step - loss: 40361.6656 - mae: 117.9927 - mse: 40361.6641\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 40315.3953 - mae: 117.9305 - mse: 40315.3984\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 40267.7482 - mae: 117.9104 - mse: 40267.7539\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 107us/step - loss: 40233.8984 - mae: 117.9988 - mse: 40233.8984\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 85264.0371 - mae: 196.4230 - mse: 85264.0391\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 85126.1771 - mae: 196.0903 - mse: 85126.1719\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 84988.2688 - mae: 195.7368 - mse: 84988.2578\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 84832.1792 - mae: 195.3402 - mse: 84832.1719\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 84646.6802 - mae: 194.8747 - mse: 84646.6797\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 84428.1117 - mae: 194.3020 - mse: 84428.1094\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 119us/step - loss: 84151.0365 - mae: 193.5929 - mse: 84151.0391\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 83811.5063 - mae: 192.7276 - mse: 83811.5078\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 83418.6263 - mae: 191.6736 - mse: 83418.6250\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 82955.1383 - mae: 190.4702 - mse: 82955.1328\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 82431.6280 - mae: 189.1431 - mse: 82431.6250\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 81875.8674 - mae: 187.6623 - mse: 81875.8672\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 81249.4280 - mae: 186.1093 - mse: 81249.4297\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 80601.2092 - mae: 184.4316 - mse: 80601.2031\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 79903.2439 - mae: 182.6392 - mse: 79903.2344\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 126us/step - loss: 79158.1544 - mae: 180.7432 - mse: 79158.1562\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 78371.1814 - mae: 178.6732 - mse: 78371.1953\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 77558.5630 - mae: 176.4832 - mse: 77558.5625\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 76700.0695 - mae: 174.2412 - mse: 76700.0703\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 75838.4600 - mae: 171.8350 - mse: 75838.4609\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 74926.1835 - mae: 169.5124 - mse: 74926.1875\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 74022.1453 - mae: 167.0545 - mse: 74022.1406\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 73066.9288 - mae: 164.6683 - mse: 73066.9297\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 72143.7326 - mae: 162.2783 - mse: 72143.7422\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 71173.7115 - mae: 159.7984 - mse: 71173.7109\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 70221.4538 - mae: 157.4461 - mse: 70221.4531\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 69260.7650 - mae: 155.0564 - mse: 69260.7656\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 68302.4683 - mae: 152.7473 - mse: 68302.4766\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 126us/step - loss: 67331.0173 - mae: 150.5106 - mse: 67331.0234\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 66402.4461 - mae: 148.3215 - mse: 66402.4453\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 120us/step - loss: 65468.4062 - mae: 146.2320 - mse: 65468.4062\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 64550.2102 - mae: 144.0920 - mse: 64550.2148\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 63628.9897 - mae: 142.0658 - mse: 63628.9922\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 62771.7020 - mae: 140.0671 - mse: 62771.6992\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 61888.5656 - mae: 138.0858 - mse: 61888.5586\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 61036.6160 - mae: 136.2916 - mse: 61036.6211\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 60214.8934 - mae: 134.4348 - mse: 60214.8984\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 59436.3815 - mae: 132.7569 - mse: 59436.3789\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 128us/step - loss: 58637.0753 - mae: 131.0565 - mse: 58637.0781\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 57945.7163 - mae: 129.5706 - mse: 57945.7148\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 57200.6438 - mae: 128.0112 - mse: 57200.6406\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 56538.4197 - mae: 126.6993 - mse: 56538.4219\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 55888.6645 - mae: 125.3608 - mse: 55888.6562\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 127us/step - loss: 55270.8318 - mae: 124.2178 - mse: 55270.8320\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 54693.4152 - mae: 123.2971 - mse: 54693.4219\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 54150.8168 - mae: 122.4945 - mse: 54150.8164\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 53595.9181 - mae: 121.7284 - mse: 53595.9219\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 53096.4733 - mae: 121.0657 - mse: 53096.4727\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 52624.6799 - mae: 120.5840 - mse: 52624.6836\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 52200.2292 - mae: 120.1511 - mse: 52200.2344\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 51760.8507 - mae: 119.9002 - mse: 51760.8516\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 51391.8277 - mae: 119.7554 - mse: 51391.8281\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 51025.5768 - mae: 119.6910 - mse: 51025.5781\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 133us/step - loss: 50706.5121 - mae: 119.6808 - mse: 50706.5156\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 50381.7795 - mae: 119.6811 - mse: 50381.7812\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 50115.3187 - mae: 119.8402 - mse: 50115.3203\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 122us/step - loss: 49877.2397 - mae: 120.0881 - mse: 49877.2383\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 49610.0493 - mae: 120.2538 - mse: 49610.0508\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 137us/step - loss: 49421.9831 - mae: 120.5660 - mse: 49421.9883\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 49206.4118 - mae: 120.8096 - mse: 49206.4141\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 49032.3334 - mae: 121.1598 - mse: 49032.3320\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 48860.1264 - mae: 121.4928 - mse: 48860.1250\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 48703.0657 - mae: 121.7416 - mse: 48703.0586\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 48580.0501 - mae: 122.1816 - mse: 48580.0547\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 48442.7387 - mae: 122.4723 - mse: 48442.7422\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 48326.5578 - mae: 122.8148 - mse: 48326.5586\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 130us/step - loss: 48211.8951 - mae: 123.1391 - mse: 48211.8945\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 122us/step - loss: 48117.8343 - mae: 123.4132 - mse: 48117.8359\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 48017.1020 - mae: 123.7014 - mse: 48017.1055\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 47935.6096 - mae: 123.9799 - mse: 47935.6133\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 128us/step - loss: 47849.8465 - mae: 124.2115 - mse: 47849.8516\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 47779.3887 - mae: 124.4964 - mse: 47779.3906\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 47693.6575 - mae: 124.6444 - mse: 47693.6602\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 47632.6128 - mae: 124.8714 - mse: 47632.6133\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 47559.6344 - mae: 125.0285 - mse: 47559.6328\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 47495.4337 - mae: 125.1843 - mse: 47495.4336\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 47432.7304 - mae: 125.3143 - mse: 47432.7266\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 47377.7930 - mae: 125.4562 - mse: 47377.7930\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 199us/step - loss: 47313.1240 - mae: 125.6304 - mse: 47313.1250 0s - loss: 50700.5818 - mae: 128.8993 - mse: 50700.585\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 47254.0215 - mae: 125.7198 - mse: 47254.0195\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 47203.1235 - mae: 125.8381 - mse: 47203.1250\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 47146.2260 - mae: 125.9284 - mse: 47146.2266\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 47090.9868 - mae: 126.0622 - mse: 47090.9883\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 135us/step - loss: 47037.9117 - mae: 126.0542 - mse: 47037.9102\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 46987.2527 - mae: 126.1756 - mse: 46987.2539\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 46938.8199 - mae: 126.2789 - mse: 46938.8203\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 46877.0909 - mae: 126.3513 - mse: 46877.0938\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 46828.8581 - mae: 126.3295 - mse: 46828.8555\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 46774.6867 - mae: 126.3025 - mse: 46774.6875\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 46733.7562 - mae: 126.4470 - mse: 46733.7578\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 131us/step - loss: 46677.5067 - mae: 126.4013 - mse: 46677.5078\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 46622.5779 - mae: 126.3547 - mse: 46622.5742\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 46578.6818 - mae: 126.4997 - mse: 46578.6758\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 46511.5533 - mae: 126.4650 - mse: 46511.5547\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 46462.1133 - mae: 126.3714 - mse: 46462.1094\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 46407.1075 - mae: 126.3126 - mse: 46407.1016\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 118us/step - loss: 46353.3715 - mae: 126.2851 - mse: 46353.3672\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 130us/step - loss: 46298.0714 - mae: 126.2777 - mse: 46298.0742\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 46241.4316 - mae: 126.2400 - mse: 46241.4375\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 46188.5081 - mae: 126.2360 - mse: 46188.5117\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 83523.1938 - mae: 203.0974 - mse: 83523.1953\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 83368.3693 - mae: 202.7131 - mse: 83368.3672\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 83186.4378 - mae: 202.2709 - mse: 83186.4453\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 82962.8467 - mae: 201.7295 - mse: 82962.8516\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 82696.2052 - mae: 201.0507 - mse: 82696.1953\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 82361.9482 - mae: 200.2176 - mse: 82361.9453\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 81964.8859 - mae: 199.2207 - mse: 81964.8906\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 81496.5273 - mae: 198.0470 - mse: 81496.5234\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 80956.3595 - mae: 196.6994 - mse: 80956.3594\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 80348.8667 - mae: 195.1452 - mse: 80348.8672\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 79664.4042 - mae: 193.4184 - mse: 79664.3906\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 78913.7628 - mae: 191.5984 - mse: 78913.7656\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 78149.9602 - mae: 189.6495 - mse: 78149.9531\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 124us/step - loss: 77342.6451 - mae: 187.5257 - mse: 77342.6484\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 76458.8548 - mae: 185.3180 - mse: 76458.8516\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 75583.7443 - mae: 182.9659 - mse: 75583.7422\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 74646.0810 - mae: 180.5088 - mse: 74646.0703\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 73673.8661 - mae: 178.0280 - mse: 73673.8672\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 134us/step - loss: 72717.7344 - mae: 175.4362 - mse: 72717.7344\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 71708.2832 - mae: 172.8011 - mse: 71708.2891\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 70679.3188 - mae: 170.1090 - mse: 70679.3203\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 69626.2716 - mae: 167.4739 - mse: 69626.2734\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 68583.1402 - mae: 164.7991 - mse: 68583.1328\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 67533.7901 - mae: 162.0847 - mse: 67533.7969\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 66473.3224 - mae: 159.4136 - mse: 66473.3281\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 65420.3727 - mae: 156.7735 - mse: 65420.3750\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 64355.3988 - mae: 154.2039 - mse: 64355.3984\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 63307.9221 - mae: 151.6930 - mse: 63307.9219\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 62271.9980 - mae: 149.1969 - mse: 62271.9922\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 61256.8357 - mae: 146.7908 - mse: 61256.8398\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 133us/step - loss: 60266.5319 - mae: 144.4771 - mse: 60266.5352\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 130us/step - loss: 59280.9122 - mae: 142.1539 - mse: 59280.9062\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 124us/step - loss: 58288.2213 - mae: 139.9050 - mse: 58288.2148\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 57393.6660 - mae: 137.8019 - mse: 57393.6680\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 56511.6767 - mae: 135.7831 - mse: 56511.6797\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 55596.4275 - mae: 133.9023 - mse: 55596.4336\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 54777.4719 - mae: 132.0529 - mse: 54777.4727\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 53950.1126 - mae: 130.3017 - mse: 53950.1133\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 53197.3558 - mae: 128.6276 - mse: 53197.3516\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 52438.6174 - mae: 127.1380 - mse: 52438.6172\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 51759.2749 - mae: 125.7912 - mse: 51759.2695\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 119us/step - loss: 51092.5009 - mae: 124.6157 - mse: 51092.5039\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 129us/step - loss: 50453.9340 - mae: 123.6022 - mse: 50453.9414\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 49851.9025 - mae: 122.6639 - mse: 49851.8984\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 49317.7125 - mae: 121.8679 - mse: 49317.7148\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 130us/step - loss: 48792.2671 - mae: 121.1995 - mse: 48792.2656\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 48303.8155 - mae: 120.7507 - mse: 48303.8125\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 47842.2142 - mae: 120.3208 - mse: 47842.2148\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 47431.8115 - mae: 120.0047 - mse: 47431.8164\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 47029.7002 - mae: 119.7465 - mse: 47029.7031\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 46706.0139 - mae: 119.6626 - mse: 46706.0117\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 128us/step - loss: 46343.7831 - mae: 119.5356 - mse: 46343.7852\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 46053.9309 - mae: 119.6322 - mse: 46053.9297\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 45782.4071 - mae: 119.8046 - mse: 45782.4102\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 128us/step - loss: 45538.2143 - mae: 119.9446 - mse: 45538.2148\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 45269.0434 - mae: 120.0860 - mse: 45269.0469\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 127us/step - loss: 45074.8874 - mae: 120.2556 - mse: 45074.8906\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 133us/step - loss: 44885.5368 - mae: 120.5112 - mse: 44885.5352\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 44721.4537 - mae: 120.8098 - mse: 44721.4453\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 131us/step - loss: 44539.7025 - mae: 121.1007 - mse: 44539.7070\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 126us/step - loss: 44400.8842 - mae: 121.3814 - mse: 44400.8789\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 44268.8673 - mae: 121.6863 - mse: 44268.8672\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 131us/step - loss: 44139.1642 - mae: 121.9798 - mse: 44139.1641\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 98us/step - loss: 44015.6619 - mae: 122.1960 - mse: 44015.6641\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 43924.9560 - mae: 122.4251 - mse: 43924.9609\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 43815.0268 - mae: 122.6211 - mse: 43815.0312\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 100us/step - loss: 43743.8632 - mae: 122.9047 - mse: 43743.8633\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 43646.5900 - mae: 123.2193 - mse: 43646.5859\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 97us/step - loss: 43564.2456 - mae: 123.3585 - mse: 43564.2461\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 43491.7260 - mae: 123.5540 - mse: 43491.7266\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 43431.7411 - mae: 123.9058 - mse: 43431.7383\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 43348.9290 - mae: 124.0091 - mse: 43348.9297\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 43291.0915 - mae: 124.1749 - mse: 43291.0898\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 43223.5369 - mae: 124.3493 - mse: 43223.5352\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 122us/step - loss: 43167.1400 - mae: 124.5077 - mse: 43167.1406\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 43111.0629 - mae: 124.6950 - mse: 43111.0664\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 43047.6383 - mae: 124.7165 - mse: 43047.6367\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 114us/step - loss: 42993.5148 - mae: 124.7535 - mse: 42993.5117\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 42941.6339 - mae: 124.9032 - mse: 42941.6289\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 42883.2112 - mae: 124.9854 - mse: 42883.2109\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 42832.7476 - mae: 125.0498 - mse: 42832.7461\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 42781.7514 - mae: 125.2008 - mse: 42781.7539\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 42720.1960 - mae: 125.1749 - mse: 42720.1992\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 42676.4516 - mae: 125.2577 - mse: 42676.4531\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 114us/step - loss: 42612.6115 - mae: 125.2478 - mse: 42612.6133\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 42561.6260 - mae: 125.2157 - mse: 42561.6250\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 42508.4947 - mae: 125.1724 - mse: 42508.4922\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 42452.6242 - mae: 125.1688 - mse: 42452.6250\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 42397.6686 - mae: 125.1311 - mse: 42397.6719\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 42342.3741 - mae: 125.1213 - mse: 42342.3750\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 42282.2662 - mae: 125.0938 - mse: 42282.2656\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 42225.2096 - mae: 125.0814 - mse: 42225.2109\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 42163.4035 - mae: 124.9941 - mse: 42163.4062\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 42104.9948 - mae: 124.8846 - mse: 42104.9922\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 42045.6951 - mae: 124.8253 - mse: 42045.6914\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 41984.9061 - mae: 124.6695 - mse: 41984.9062\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 41923.9290 - mae: 124.6055 - mse: 41923.9297\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 41867.7320 - mae: 124.6111 - mse: 41867.7305\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 119us/step - loss: 41807.3717 - mae: 124.6335 - mse: 41807.3750\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 41744.5201 - mae: 124.5309 - mse: 41744.5195\n",
      "Epoch 1/100\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 84160.4037 - mae: 200.3712 - mse: 84160.4062\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 0s 122us/step - loss: 83933.4715 - mae: 199.8065 - mse: 83933.4688\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 0s 119us/step - loss: 83656.8109 - mae: 199.1180 - mse: 83656.8047\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 0s 124us/step - loss: 83305.2142 - mae: 198.2386 - mse: 83305.2109\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 0s 129us/step - loss: 82871.0252 - mae: 197.1294 - mse: 82871.0156\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 0s 116us/step - loss: 82337.8852 - mae: 195.7763 - mse: 82337.8984\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 0s 118us/step - loss: 81721.9033 - mae: 194.1869 - mse: 81721.9062\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 0s 109us/step - loss: 81012.1235 - mae: 192.4033 - mse: 81012.1250\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 0s 110us/step - loss: 80244.0510 - mae: 190.4139 - mse: 80244.0547\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 0s 105us/step - loss: 79387.7043 - mae: 188.3202 - mse: 79387.7031\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 0s 125us/step - loss: 78506.1955 - mae: 186.0056 - mse: 78506.1953\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 0s 118us/step - loss: 77536.9368 - mae: 183.5117 - mse: 77536.9375\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 0s 110us/step - loss: 76519.4699 - mae: 180.9205 - mse: 76519.4688\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 0s 112us/step - loss: 75491.4398 - mae: 178.0841 - mse: 75491.4453\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 0s 118us/step - loss: 74372.3098 - mae: 175.1562 - mse: 74372.3125\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 0s 125us/step - loss: 73250.0610 - mae: 172.2610 - mse: 73250.0625\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 0s 118us/step - loss: 72093.3177 - mae: 169.2725 - mse: 72093.3125\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 0s 114us/step - loss: 70915.4754 - mae: 166.1930 - mse: 70915.4766\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 0s 117us/step - loss: 69706.9491 - mae: 163.1719 - mse: 69706.9531\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 0s 109us/step - loss: 68498.5367 - mae: 160.1043 - mse: 68498.5469\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 0s 114us/step - loss: 67294.5294 - mae: 157.0192 - mse: 67294.5312\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 0s 120us/step - loss: 66086.6490 - mae: 154.0613 - mse: 66086.6562\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 0s 116us/step - loss: 64850.0669 - mae: 151.2992 - mse: 64850.0586\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 0s 120us/step - loss: 63691.2255 - mae: 148.4342 - mse: 63691.2266\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 0s 116us/step - loss: 62512.3878 - mae: 145.6414 - mse: 62512.3945\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 0s 121us/step - loss: 61344.9202 - mae: 142.9557 - mse: 61344.9219\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 0s 113us/step - loss: 60253.6968 - mae: 140.3804 - mse: 60253.6953\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 0s 120us/step - loss: 59160.1710 - mae: 137.8668 - mse: 59160.1797\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 104us/step - loss: 58074.4727 - mae: 135.4175 - mse: 58074.4805\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 0s 84us/step - loss: 57054.2667 - mae: 133.1459 - mse: 57054.2734\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 0s 97us/step - loss: 56054.6070 - mae: 131.0011 - mse: 56054.6133\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 0s 122us/step - loss: 55092.1847 - mae: 128.9374 - mse: 55092.1797\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 0s 90us/step - loss: 54180.1234 - mae: 127.1163 - mse: 54180.1172\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 0s 123us/step - loss: 53346.9783 - mae: 125.3175 - mse: 53346.9805\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 0s 106us/step - loss: 52550.4298 - mae: 124.0093 - mse: 52550.4375\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 0s 123us/step - loss: 51794.9271 - mae: 122.8790 - mse: 51794.9336\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 0s 121us/step - loss: 51114.0949 - mae: 121.8170 - mse: 51114.0977\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 0s 121us/step - loss: 50449.3628 - mae: 120.9752 - mse: 50449.3672\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 0s 120us/step - loss: 49847.8297 - mae: 120.2928 - mse: 49847.8359\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 0s 113us/step - loss: 49301.0505 - mae: 119.8482 - mse: 49301.0508\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 0s 112us/step - loss: 48799.4620 - mae: 119.5842 - mse: 48799.4609\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 0s 106us/step - loss: 48387.0029 - mae: 119.5600 - mse: 48387.0078\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 0s 121us/step - loss: 47954.6303 - mae: 119.4348 - mse: 47954.6250\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 0s 110us/step - loss: 47604.3117 - mae: 119.5652 - mse: 47604.3086\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 0s 118us/step - loss: 47273.0655 - mae: 119.8029 - mse: 47273.0664\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 0s 110us/step - loss: 46996.7428 - mae: 120.0724 - mse: 46996.7461\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 0s 118us/step - loss: 46734.7284 - mae: 120.4421 - mse: 46734.7266\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 0s 121us/step - loss: 46514.4906 - mae: 120.7562 - mse: 46514.4922\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 0s 118us/step - loss: 46315.8768 - mae: 121.1756 - mse: 46315.8711\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 0s 117us/step - loss: 46136.5484 - mae: 121.5025 - mse: 46136.5508\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 0s 110us/step - loss: 45977.0821 - mae: 121.8847 - mse: 45977.0781\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 0s 113us/step - loss: 45853.1704 - mae: 122.3705 - mse: 45853.1680\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 0s 113us/step - loss: 45716.5793 - mae: 122.6671 - mse: 45716.5742\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 0s 120us/step - loss: 45606.6060 - mae: 122.9774 - mse: 45606.6133\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 0s 122us/step - loss: 45501.2986 - mae: 123.1813 - mse: 45501.2969\n",
      "Epoch 56/100\n",
      "750/750 [==============================] - 0s 120us/step - loss: 45413.8808 - mae: 123.4829 - mse: 45413.8789\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 0s 121us/step - loss: 45322.3597 - mae: 123.6892 - mse: 45322.3555\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 0s 109us/step - loss: 45241.8578 - mae: 123.9607 - mse: 45241.8555\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 0s 118us/step - loss: 45165.4853 - mae: 124.2035 - mse: 45165.4883\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 0s 121us/step - loss: 45088.6420 - mae: 124.4861 - mse: 45088.6406\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 0s 120us/step - loss: 45012.2399 - mae: 124.5260 - mse: 45012.2383\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 0s 110us/step - loss: 44947.1212 - mae: 124.6201 - mse: 44947.1211\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 0s 117us/step - loss: 44880.7341 - mae: 124.8417 - mse: 44880.7344\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 0s 116us/step - loss: 44814.0439 - mae: 125.0671 - mse: 44814.0430\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 0s 121us/step - loss: 44742.7970 - mae: 125.0776 - mse: 44742.8008\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 0s 120us/step - loss: 44687.6693 - mae: 125.2279 - mse: 44687.6680\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 0s 106us/step - loss: 44610.1621 - mae: 125.3257 - mse: 44610.1641\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 0s 120us/step - loss: 44547.7590 - mae: 125.2768 - mse: 44547.7656\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 0s 114us/step - loss: 44479.5994 - mae: 125.2357 - mse: 44479.5938\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 0s 128us/step - loss: 44412.8349 - mae: 125.2394 - mse: 44412.8359\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 0s 126us/step - loss: 44350.7517 - mae: 125.2356 - mse: 44350.7500\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 0s 102us/step - loss: 44286.8697 - mae: 125.1686 - mse: 44286.8711\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 0s 120us/step - loss: 44219.2166 - mae: 125.1103 - mse: 44219.2148\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 0s 113us/step - loss: 44157.4135 - mae: 125.1828 - mse: 44157.4141\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 0s 120us/step - loss: 44096.4586 - mae: 125.0513 - mse: 44096.4570\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 0s 107us/step - loss: 44024.6474 - mae: 124.9992 - mse: 44024.6523\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 0s 124us/step - loss: 43958.9657 - mae: 125.0447 - mse: 43958.9688\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 0s 117us/step - loss: 43894.6724 - mae: 125.0398 - mse: 43894.6719\n",
      "Epoch 79/100\n",
      "750/750 [==============================] - 0s 109us/step - loss: 43829.9379 - mae: 124.9399 - mse: 43829.9414\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 0s 112us/step - loss: 43765.7522 - mae: 124.7822 - mse: 43765.7461\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 0s 105us/step - loss: 43702.4607 - mae: 124.6269 - mse: 43702.4609\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 0s 116us/step - loss: 43632.1470 - mae: 124.6026 - mse: 43632.1484\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 0s 124us/step - loss: 43571.4590 - mae: 124.7327 - mse: 43571.4570\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 0s 121us/step - loss: 43503.9417 - mae: 124.5944 - mse: 43503.9414\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 0s 121us/step - loss: 43433.5032 - mae: 124.4974 - mse: 43433.5039\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 0s 110us/step - loss: 43368.2689 - mae: 124.3639 - mse: 43368.2734\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 0s 112us/step - loss: 43307.6940 - mae: 124.4231 - mse: 43307.6992\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 0s 122us/step - loss: 43229.3213 - mae: 124.3616 - mse: 43229.3242\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 0s 125us/step - loss: 43162.8974 - mae: 124.2120 - mse: 43162.8945\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 0s 118us/step - loss: 43101.3135 - mae: 124.1922 - mse: 43101.3164\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 0s 115us/step - loss: 43025.7261 - mae: 124.1370 - mse: 43025.7266\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 0s 110us/step - loss: 42953.3330 - mae: 123.9863 - mse: 42953.3320\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 0s 108us/step - loss: 42878.2659 - mae: 123.6500 - mse: 42878.2656\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 0s 128us/step - loss: 42807.6617 - mae: 123.4421 - mse: 42807.6602\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 122us/step - loss: 42735.2954 - mae: 123.2876 - mse: 42735.2969\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 0s 112us/step - loss: 42657.1660 - mae: 123.2964 - mse: 42657.1641\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 0s 116us/step - loss: 42589.8319 - mae: 123.1308 - mse: 42589.8281\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 0s 109us/step - loss: 42514.4216 - mae: 123.0910 - mse: 42514.4141\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 0s 128us/step - loss: 42438.6078 - mae: 123.0540 - mse: 42438.6094\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 0s 114us/step - loss: 42365.5973 - mae: 122.8712 - mse: 42365.6016\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=44, activation = 'relu', input_dim=22))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae','mse'])\n",
    "    return model\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "NN_Regressor = KerasRegressor(build_fn=build_model, batch_size=40,epochs=100)    \n",
    "\n",
    "scores = cross_val_score(NN_Regressor, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "NN = NN_Regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the scores for each model run\n",
      "[-41914.73196494 -32352.36187907 -61978.81451279 -34767.00028121\n",
      " -51511.55042781]\n",
      " \n",
      "Mean and variance: 44504.89 (+/- 21975.45)\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 140.13280337402344\n",
      "Root Mean Squared Error: 247.63615895745144\n",
      "Time Taken =  137.84375\n"
     ]
    }
   ],
   "source": [
    "print(\"Below are the scores for each model run\")\n",
    "print(scores)\n",
    "print(\" \")\n",
    "print(\"Mean and variance: %0.2f (+/- %0.2f)\" % (abs(scores.mean()), scores.std() * 2))\n",
    "\n",
    "y_pred= NN_Regressor.predict(X_test_holdout)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Medium Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 86025.2585 - mae: 204.1486 - mse: 86025.2578\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 85810.5232 - mae: 203.6063 - mse: 85810.5234\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 100us/step - loss: 85524.5107 - mae: 202.9254 - mse: 85524.5156\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 85104.1729 - mae: 201.9057 - mse: 85104.1797\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 84472.1242 - mae: 200.3135 - mse: 84472.1172\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 83519.0888 - mae: 197.9651 - mse: 83519.0938\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 82207.0527 - mae: 194.5683 - mse: 82207.0547\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 80349.8766 - mae: 190.0406 - mse: 80349.8828\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 78010.5147 - mae: 184.0059 - mse: 78010.5234\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 84us/step - loss: 75118.6112 - mae: 176.6380 - mse: 75118.6172\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 71883.8495 - mae: 168.2144 - mse: 71883.8438\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 98us/step - loss: 68134.2466 - mae: 159.3028 - mse: 68134.2422\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 100us/step - loss: 64248.1872 - mae: 149.9632 - mse: 64248.1914\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 60302.3949 - mae: 140.8651 - mse: 60302.3984\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 81us/step - loss: 56516.4469 - mae: 132.9828 - mse: 56516.4453\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 53326.3000 - mae: 126.2325 - mse: 53326.2969\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 82us/step - loss: 50687.8052 - mae: 122.8196 - mse: 50687.8086\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 48714.9581 - mae: 121.7726 - mse: 48714.9570\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 87us/step - loss: 47346.5604 - mae: 122.6861 - mse: 47346.5586\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 46499.2321 - mae: 124.1293 - mse: 46499.2344\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 45999.9134 - mae: 125.3381 - mse: 45999.9141\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 45694.3965 - mae: 126.5612 - mse: 45694.3945\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 87us/step - loss: 45464.5636 - mae: 127.7190 - mse: 45464.5625\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 82us/step - loss: 45291.1209 - mae: 128.3849 - mse: 45291.1211\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 94us/step - loss: 45112.4596 - mae: 128.9091 - mse: 45112.4609\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 99us/step - loss: 44937.3976 - mae: 128.6874 - mse: 44937.3945\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 44793.0259 - mae: 128.7402 - mse: 44793.0195\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 44612.0875 - mae: 128.2346 - mse: 44612.0859\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 44476.7661 - mae: 128.4208 - mse: 44476.7617\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 44270.2031 - mae: 128.1394 - mse: 44270.2070\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 98us/step - loss: 44116.6040 - mae: 127.7672 - mse: 44116.6016\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 92us/step - loss: 43944.1232 - mae: 127.3684 - mse: 43944.1211\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 43794.6252 - mae: 127.2550 - mse: 43794.6250\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 43612.2953 - mae: 127.3176 - mse: 43612.2969\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 43438.4235 - mae: 126.9538 - mse: 43438.4219\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 43283.8256 - mae: 126.4463 - mse: 43283.8242\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 43123.4639 - mae: 125.9770 - mse: 43123.4648\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 87us/step - loss: 42967.6691 - mae: 126.2754 - mse: 42967.6719\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 42804.1322 - mae: 125.9597 - mse: 42804.1367\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 42592.8679 - mae: 125.6241 - mse: 42592.8672\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 99us/step - loss: 42430.3630 - mae: 125.8862 - mse: 42430.3633\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 84us/step - loss: 42255.9120 - mae: 125.8641 - mse: 42255.9062\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 42075.4255 - mae: 125.2715 - mse: 42075.4219\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 41900.6963 - mae: 124.9874 - mse: 41900.6992\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 41737.1859 - mae: 124.8864 - mse: 41737.1836\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 41537.0048 - mae: 124.1261 - mse: 41537.0000\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 41344.6960 - mae: 123.7511 - mse: 41344.6953\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 41177.4688 - mae: 123.5275 - mse: 41177.4688\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 40986.7882 - mae: 123.5481 - mse: 40986.7930\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 40796.0250 - mae: 123.5843 - mse: 40796.0312\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 107us/step - loss: 40602.7063 - mae: 123.0129 - mse: 40602.7070\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 40415.5007 - mae: 122.3857 - mse: 40415.5039\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 40223.2609 - mae: 122.6307 - mse: 40223.2617\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 92us/step - loss: 40010.7309 - mae: 122.2152 - mse: 40010.7344\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 39815.5260 - mae: 121.8276 - mse: 39815.5234\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 87us/step - loss: 39605.0364 - mae: 121.2443 - mse: 39605.0352\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 124us/step - loss: 39414.7893 - mae: 121.0220 - mse: 39414.7852\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 39183.9988 - mae: 120.7344 - mse: 39183.9961\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 38992.4055 - mae: 120.5907 - mse: 38992.4062\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 76us/step - loss: 38763.3211 - mae: 120.3974 - mse: 38763.3242\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 38571.4124 - mae: 119.4683 - mse: 38571.4062\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 38347.6357 - mae: 119.5384 - mse: 38347.6367\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 38103.0348 - mae: 118.9042 - mse: 38103.0352\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 37881.5412 - mae: 118.3726 - mse: 37881.5391\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 37649.6792 - mae: 118.0193 - mse: 37649.6797\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 37439.3218 - mae: 117.9737 - mse: 37439.3242\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 37191.1575 - mae: 117.3853 - mse: 37191.1602\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 106us/step - loss: 36976.8757 - mae: 117.1197 - mse: 36976.8750\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 36726.5620 - mae: 116.8241 - mse: 36726.5625\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 94us/step - loss: 36497.9427 - mae: 116.4123 - mse: 36497.9414\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 36236.8722 - mae: 115.8274 - mse: 36236.8750\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 36017.0533 - mae: 115.5790 - mse: 36017.0547\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 35757.7006 - mae: 114.8851 - mse: 35757.6992\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 35520.7813 - mae: 114.1862 - mse: 35520.7852\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 35306.3555 - mae: 114.2244 - mse: 35306.3555\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 35024.5131 - mae: 113.9879 - mse: 35024.5117\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 34789.0561 - mae: 113.2908 - mse: 34789.0508\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 34518.6673 - mae: 112.6933 - mse: 34518.6680\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 34288.7956 - mae: 112.1879 - mse: 34288.7969\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 34040.2810 - mae: 111.6995 - mse: 34040.2812\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 33775.2355 - mae: 111.3425 - mse: 33775.2383\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 33541.0380 - mae: 110.9126 - mse: 33541.0391\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 33292.9160 - mae: 110.7321 - mse: 33292.9141\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 33082.8941 - mae: 111.1367 - mse: 33082.8984\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 86us/step - loss: 32804.0964 - mae: 110.0464 - mse: 32804.1016\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 32545.7045 - mae: 108.7392 - mse: 32545.7070\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 102us/step - loss: 32295.9623 - mae: 108.5401 - mse: 32295.9609\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 32054.0274 - mae: 108.4882 - mse: 32054.0293\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 31794.3576 - mae: 108.0398 - mse: 31794.3535\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 31591.6441 - mae: 107.9666 - mse: 31591.6426\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 109us/step - loss: 31312.5182 - mae: 107.5824 - mse: 31312.5176\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 31125.9031 - mae: 106.1744 - mse: 31125.9043\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 30891.2936 - mae: 106.2731 - mse: 30891.2930\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 30633.5258 - mae: 106.0723 - mse: 30633.5273\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 30396.0850 - mae: 105.6611 - mse: 30396.0859\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 30166.2364 - mae: 105.1888 - mse: 30166.2324\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 104us/step - loss: 29974.1714 - mae: 105.0014 - mse: 29974.1699\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 87us/step - loss: 29753.1556 - mae: 104.7469 - mse: 29753.1543\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 79us/step - loss: 29516.1583 - mae: 103.7167 - mse: 29516.1562\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 29364.0473 - mae: 102.7793 - mse: 29364.0469\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 89083.9676 - mae: 205.6281 - mse: 89083.9688\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 89006.1125 - mae: 205.4450 - mse: 89006.1172\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 88914.2674 - mae: 205.2185 - mse: 88914.2656\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 88781.6553 - mae: 204.8960 - mse: 88781.6562\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 107us/step - loss: 88575.7208 - mae: 204.3964 - mse: 88575.7188\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 88254.5331 - mae: 203.6088 - mse: 88254.5391\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 100us/step - loss: 87763.9482 - mae: 202.3879 - mse: 87763.9531\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 87032.2971 - mae: 200.5552 - mse: 87032.3047\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 85951.4008 - mae: 197.9301 - mse: 85951.3984\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 84516.8238 - mae: 194.3192 - mse: 84516.8203\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 82637.3939 - mae: 189.5801 - mse: 82637.3906\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 98us/step - loss: 80224.8680 - mae: 183.5107 - mse: 80224.8672\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 77357.8581 - mae: 176.1781 - mse: 77357.8672\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 74097.5849 - mae: 167.7988 - mse: 74097.5781\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 70540.0694 - mae: 158.5528 - mse: 70540.0703\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 87us/step - loss: 66601.2891 - mae: 149.8642 - mse: 66601.2969\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 62865.1826 - mae: 141.4604 - mse: 62865.1875\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 59340.5734 - mae: 134.1239 - mse: 59340.5664\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 56129.0526 - mae: 128.0230 - mse: 56129.0547\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 53656.7072 - mae: 124.4032 - mse: 53656.7070\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 51614.5932 - mae: 122.7900 - mse: 51614.5898\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 50368.3390 - mae: 123.1940 - mse: 50368.3438\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 49503.4396 - mae: 124.9349 - mse: 49503.4414\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 48895.2715 - mae: 126.0192 - mse: 48895.2734\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 48555.6924 - mae: 127.4603 - mse: 48555.6914\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 48289.3542 - mae: 128.2987 - mse: 48289.3516\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 48096.4711 - mae: 128.9369 - mse: 48096.4766\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 47928.0844 - mae: 129.8414 - mse: 47928.0859\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 47730.7850 - mae: 129.9895 - mse: 47730.7852\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 47565.1324 - mae: 129.7795 - mse: 47565.1328\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 47406.9954 - mae: 129.9429 - mse: 47407.0000\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 47219.6667 - mae: 129.8973 - mse: 47219.6680\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 47070.6016 - mae: 129.7992 - mse: 47070.6016\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 46889.7288 - mae: 129.7937 - mse: 46889.7305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 46730.5284 - mae: 129.5389 - mse: 46730.5312\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 46584.6176 - mae: 129.5682 - mse: 46584.6172\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 100us/step - loss: 46419.0508 - mae: 128.8889 - mse: 46419.0547\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 46249.7536 - mae: 128.5937 - mse: 46249.7617\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 46098.2464 - mae: 128.6640 - mse: 46098.2461\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 45925.4208 - mae: 128.7363 - mse: 45925.4141\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 45782.5098 - mae: 128.7450 - mse: 45782.5117\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 45606.1266 - mae: 128.1819 - mse: 45606.1250\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 100us/step - loss: 45444.1182 - mae: 127.8354 - mse: 45444.1211\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 45288.0143 - mae: 127.4875 - mse: 45288.0117\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 80us/step - loss: 45140.0369 - mae: 127.7651 - mse: 45140.0391\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 44946.1954 - mae: 127.5939 - mse: 44946.1992\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 44804.8158 - mae: 127.6045 - mse: 44804.8164\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 44635.6958 - mae: 127.3438 - mse: 44635.6914\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 44453.1480 - mae: 126.8607 - mse: 44453.1484\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 44297.5010 - mae: 126.4468 - mse: 44297.5000\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 44135.6668 - mae: 126.0984 - mse: 44135.6680\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 43999.6423 - mae: 126.5517 - mse: 43999.6406\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 43776.4856 - mae: 126.3420 - mse: 43776.4883\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 43630.9089 - mae: 126.3581 - mse: 43630.9102\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 43466.9676 - mae: 125.3394 - mse: 43466.9648\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 43271.8951 - mae: 124.9778 - mse: 43271.8945\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 43083.7589 - mae: 124.9173 - mse: 43083.7578\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 75us/step - loss: 42896.2528 - mae: 124.8850 - mse: 42896.2539\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 42742.2238 - mae: 124.9264 - mse: 42742.2227\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 42538.9913 - mae: 124.5923 - mse: 42538.9961\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 42345.5636 - mae: 123.9619 - mse: 42345.5625\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 42110.6905 - mae: 123.3693 - mse: 42110.6914\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 41871.6204 - mae: 122.9925 - mse: 41871.6250\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 41646.3475 - mae: 122.3330 - mse: 41646.3477\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 41413.9635 - mae: 121.8919 - mse: 41413.9648\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 41184.0066 - mae: 121.7425 - mse: 41184.0117\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 40999.4577 - mae: 122.3365 - mse: 40999.4492\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 40708.8260 - mae: 121.7707 - mse: 40708.8281\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 40450.7367 - mae: 120.7852 - mse: 40450.7344\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 40245.0417 - mae: 120.1728 - mse: 40245.0391\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 132us/step - loss: 39993.0284 - mae: 119.4636 - mse: 39993.0312\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 39745.4336 - mae: 119.2371 - mse: 39745.4297\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 89us/step - loss: 39519.8819 - mae: 119.6322 - mse: 39519.8828\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 39233.5742 - mae: 119.1876 - mse: 39233.5781\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 38995.0103 - mae: 118.5873 - mse: 38995.0117\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 38737.4693 - mae: 118.1402 - mse: 38737.4727\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 38498.2402 - mae: 117.8534 - mse: 38498.2422\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 76us/step - loss: 38215.6393 - mae: 117.3218 - mse: 38215.6367\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 75us/step - loss: 37939.4141 - mae: 116.7466 - mse: 37939.4141\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 37701.5030 - mae: 116.0370 - mse: 37701.5039\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 74us/step - loss: 37451.6046 - mae: 116.2214 - mse: 37451.6016\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 37141.0001 - mae: 116.0139 - mse: 37140.9961\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 83us/step - loss: 36874.0348 - mae: 115.5202 - mse: 36874.0352\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 92us/step - loss: 36606.6251 - mae: 114.9702 - mse: 36606.6289\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 36318.6005 - mae: 114.5777 - mse: 36318.6016\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 36051.2514 - mae: 113.9378 - mse: 36051.2461\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 35775.3449 - mae: 113.7460 - mse: 35775.3438\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 81us/step - loss: 35508.5251 - mae: 113.2049 - mse: 35508.5234\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 35214.8410 - mae: 112.8652 - mse: 35214.8398\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 83us/step - loss: 34958.8489 - mae: 112.8946 - mse: 34958.8516\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 126us/step - loss: 34657.8919 - mae: 112.2014 - mse: 34657.8867\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 34444.0189 - mae: 112.2476 - mse: 34444.0195\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 34145.3977 - mae: 110.9577 - mse: 34145.3984\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 33880.7189 - mae: 110.3293 - mse: 33880.7188\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 100us/step - loss: 33606.5919 - mae: 109.9141 - mse: 33606.5898\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 33387.7314 - mae: 110.3672 - mse: 33387.7227\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 33111.6130 - mae: 109.7415 - mse: 33111.6133\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 83us/step - loss: 32854.5168 - mae: 109.4954 - mse: 32854.5156\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 32612.0264 - mae: 108.4563 - mse: 32612.0273\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 32363.7673 - mae: 108.1572 - mse: 32363.7695\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 1s 1ms/step - loss: 77803.9430 - mae: 194.8648 - mse: 77803.9453\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 77634.9992 - mae: 194.4208 - mse: 77635.0078\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 77388.3615 - mae: 193.7826 - mse: 77388.3594\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 77030.3457 - mae: 192.8145 - mse: 77030.3516\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 76493.0771 - mae: 191.3977 - mse: 76493.0703\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 75711.8935 - mae: 189.3199 - mse: 75711.8906\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 74592.9849 - mae: 186.3808 - mse: 74592.9922\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 92us/step - loss: 73111.9357 - mae: 182.4806 - mse: 73111.9297\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 71232.5951 - mae: 177.4582 - mse: 71232.5859\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 68960.9863 - mae: 171.1940 - mse: 68960.9844\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 66328.1038 - mae: 163.8544 - mse: 66328.1016\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 102us/step - loss: 63314.3572 - mae: 156.0639 - mse: 63314.3516\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 60178.2637 - mae: 147.8609 - mse: 60178.2656\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 56851.0078 - mae: 139.5764 - mse: 56851.0078\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 53646.6219 - mae: 131.7246 - mse: 53646.6172\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 50603.1729 - mae: 124.7293 - mse: 50603.1719\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 48047.9193 - mae: 118.8637 - mse: 48047.9219\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 45805.2674 - mae: 115.2905 - mse: 45805.2656\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 44261.4306 - mae: 114.0431 - mse: 44261.4258\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 43033.0188 - mae: 113.7991 - mse: 43033.0117\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 42357.7306 - mae: 114.8254 - mse: 42357.7344\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 41837.7240 - mae: 116.3666 - mse: 41837.7227\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 41561.5331 - mae: 117.6519 - mse: 41561.5352\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 41333.6062 - mae: 118.4607 - mse: 41333.6055\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 112us/step - loss: 41194.7279 - mae: 119.0805 - mse: 41194.7305\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 41057.5775 - mae: 119.7620 - mse: 41057.5781\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 40914.6100 - mae: 120.0954 - mse: 40914.6094\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 40787.7984 - mae: 120.1083 - mse: 40787.7969\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 40658.7288 - mae: 119.8867 - mse: 40658.7266\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 40523.3885 - mae: 119.4884 - mse: 40523.3867\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 109us/step - loss: 40399.8107 - mae: 119.2890 - mse: 40399.8086\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 40253.8723 - mae: 119.1995 - mse: 40253.8750\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 40137.7288 - mae: 119.4428 - mse: 40137.7305\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 39999.1021 - mae: 119.4528 - mse: 39999.1016\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 39857.3531 - mae: 118.8529 - mse: 39857.3516\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 39710.4529 - mae: 118.5468 - mse: 39710.4531\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 39581.7710 - mae: 118.7357 - mse: 39581.7656\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 107us/step - loss: 39450.2725 - mae: 118.3525 - mse: 39450.2695\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 39295.0146 - mae: 118.1849 - mse: 39295.0117\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 102us/step - loss: 39158.7374 - mae: 118.2305 - mse: 39158.7344\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 39021.4470 - mae: 117.9943 - mse: 39021.4492\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 38867.0973 - mae: 117.8837 - mse: 38867.1016\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 38721.0033 - mae: 117.1727 - mse: 38721.0039\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 38578.1546 - mae: 116.9815 - mse: 38578.1523\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 109us/step - loss: 38432.9547 - mae: 116.9643 - mse: 38432.9531\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 38286.8809 - mae: 117.0143 - mse: 38286.8828\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 38132.2779 - mae: 117.0522 - mse: 38132.2812\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 37980.8685 - mae: 116.6942 - mse: 37980.8672\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 37824.5731 - mae: 116.2598 - mse: 37824.5742\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 37673.7714 - mae: 115.6653 - mse: 37673.7656\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 37540.9463 - mae: 115.7836 - mse: 37540.9453\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 37361.6456 - mae: 115.3892 - mse: 37361.6484\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 37218.6405 - mae: 115.2660 - mse: 37218.6445\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 37047.5675 - mae: 115.2441 - mse: 37047.5703\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 98us/step - loss: 36875.6894 - mae: 114.5248 - mse: 36875.6914\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 83us/step - loss: 36708.8573 - mae: 114.3847 - mse: 36708.8555\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 36563.7984 - mae: 114.3442 - mse: 36563.7969\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 36380.4327 - mae: 114.2591 - mse: 36380.4336\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 36208.0094 - mae: 113.7577 - mse: 36208.0117\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 36036.3682 - mae: 113.4225 - mse: 36036.3672\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 35879.4889 - mae: 112.6889 - mse: 35879.4883\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 35672.8706 - mae: 112.7055 - mse: 35672.8711\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 107us/step - loss: 35497.6301 - mae: 112.7224 - mse: 35497.6250\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 35318.5533 - mae: 112.0892 - mse: 35318.5547\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 35157.8727 - mae: 112.4211 - mse: 35157.8750\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 34949.7110 - mae: 112.1622 - mse: 34949.7109\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 34762.4062 - mae: 111.7206 - mse: 34762.4062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 34575.4179 - mae: 111.5041 - mse: 34575.4180\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 34387.8380 - mae: 111.2783 - mse: 34387.8398\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 34167.0758 - mae: 110.7965 - mse: 34167.0781\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 33973.9263 - mae: 110.3912 - mse: 33973.9258\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 33760.5988 - mae: 109.8293 - mse: 33760.6016\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 33595.7555 - mae: 108.7980 - mse: 33595.7578\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 33379.6081 - mae: 108.7910 - mse: 33379.6055\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 33153.2620 - mae: 108.9047 - mse: 33153.2617\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 32954.4011 - mae: 108.3608 - mse: 32954.3984\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 32758.6730 - mae: 108.3441 - mse: 32758.6758\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 75us/step - loss: 32530.1121 - mae: 107.2992 - mse: 32530.1094\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 81us/step - loss: 32314.3002 - mae: 107.2363 - mse: 32314.3008\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 78us/step - loss: 32101.8931 - mae: 107.2991 - mse: 32101.8926\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 81us/step - loss: 31873.6794 - mae: 106.7882 - mse: 31873.6797\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 99us/step - loss: 31643.0199 - mae: 106.0509 - mse: 31643.0195\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 131us/step - loss: 31441.6700 - mae: 105.8884 - mse: 31441.6660\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 78us/step - loss: 31214.3923 - mae: 105.3908 - mse: 31214.3906\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 30989.8020 - mae: 104.9733 - mse: 30989.8027\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 81us/step - loss: 30793.6354 - mae: 105.0359 - mse: 30793.6367\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 76us/step - loss: 30518.4048 - mae: 104.2071 - mse: 30518.4043\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 30342.4428 - mae: 103.1706 - mse: 30342.4395\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 30099.3561 - mae: 103.1900 - mse: 30099.3574\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 29855.2787 - mae: 103.0985 - mse: 29855.2793\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 76us/step - loss: 29636.8163 - mae: 103.0175 - mse: 29636.8164\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 29428.7290 - mae: 102.6110 - mse: 29428.7305\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 29165.3899 - mae: 101.6720 - mse: 29165.3906\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 28969.6833 - mae: 101.3055 - mse: 28969.6836\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 78us/step - loss: 28730.6455 - mae: 100.5033 - mse: 28730.6465\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 28505.9119 - mae: 100.3030 - mse: 28505.9102\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 28274.3626 - mae: 100.1212 - mse: 28274.3633\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 28059.9026 - mae: 99.6715 - mse: 28059.9004\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 27840.6458 - mae: 99.5489 - mse: 27840.6465\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 27609.0495 - mae: 99.0679 - mse: 27609.0469\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 85181.3786 - mae: 196.2166 - mse: 85181.3828\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 85051.6807 - mae: 195.8826 - mse: 85051.6719\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 84895.9402 - mae: 195.4849 - mse: 84895.9375\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 98us/step - loss: 84686.0193 - mae: 194.9318 - mse: 84686.0156\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 84374.3632 - mae: 194.1200 - mse: 84374.3672\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 83894.2177 - mae: 192.8895 - mse: 83894.2109\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 130us/step - loss: 83175.3758 - mae: 191.0460 - mse: 83175.3828\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 82139.1758 - mae: 188.3596 - mse: 82139.1719\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 80740.6176 - mae: 184.7876 - mse: 80740.6172\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 78947.8505 - mae: 180.1161 - mse: 78947.8516\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 76691.5323 - mae: 174.1375 - mse: 76691.5312\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 74007.3221 - mae: 166.8929 - mse: 74007.3203\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 70905.3225 - mae: 158.9431 - mse: 70905.3203\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 67636.0202 - mae: 150.5632 - mse: 67636.0234\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 63961.4417 - mae: 142.4589 - mse: 63961.4414\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 60319.6324 - mae: 134.3470 - mse: 60319.6328\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 56968.3440 - mae: 127.1360 - mse: 56968.3398\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 54215.0497 - mae: 122.0278 - mse: 54215.0469\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 51774.8405 - mae: 119.9220 - mse: 51774.8398\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 50149.3663 - mae: 120.1787 - mse: 50149.3633\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 49088.6076 - mae: 121.8176 - mse: 49088.6055\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 119us/step - loss: 48463.3740 - mae: 123.8167 - mse: 48463.3789\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 48040.7561 - mae: 125.4816 - mse: 48040.7617\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 47789.5246 - mae: 126.8783 - mse: 47789.5273\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 47566.5077 - mae: 127.3380 - mse: 47566.5078\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 107us/step - loss: 47381.2152 - mae: 127.6825 - mse: 47381.2188\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 134us/step - loss: 47194.6728 - mae: 127.7502 - mse: 47194.6719\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 47048.8771 - mae: 128.2979 - mse: 47048.8750\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 46840.5865 - mae: 128.3379 - mse: 46840.5859\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 46669.7232 - mae: 127.7456 - mse: 46669.7227\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 46502.9038 - mae: 127.3225 - mse: 46502.9023\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 46357.2204 - mae: 127.8726 - mse: 46357.2148\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 75us/step - loss: 46164.4308 - mae: 127.4144 - mse: 46164.4336\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 45991.2893 - mae: 127.0308 - mse: 45991.2930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 45804.5935 - mae: 126.8667 - mse: 45804.5938\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 112us/step - loss: 45632.9591 - mae: 126.8902 - mse: 45632.9609\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 45447.6569 - mae: 126.9571 - mse: 45447.6602\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 87us/step - loss: 45289.6397 - mae: 127.1084 - mse: 45289.6406\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 74us/step - loss: 45094.9302 - mae: 126.8247 - mse: 45094.9219\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 44912.1128 - mae: 125.9709 - mse: 44912.1133\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 87us/step - loss: 44732.9402 - mae: 126.0192 - mse: 44732.9414\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 44534.2868 - mae: 126.0712 - mse: 44534.2852\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 44325.0804 - mae: 125.7893 - mse: 44325.0781\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 44146.2507 - mae: 125.1832 - mse: 44146.2539\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 43973.5207 - mae: 125.2450 - mse: 43973.5195\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 43747.1462 - mae: 124.8157 - mse: 43747.1445\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 43550.8478 - mae: 124.6879 - mse: 43550.8438\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 74us/step - loss: 43339.3767 - mae: 124.6639 - mse: 43339.3750\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 43156.6775 - mae: 124.1301 - mse: 43156.6797\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 42945.2482 - mae: 124.4161 - mse: 42945.2500\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 42724.3012 - mae: 124.0720 - mse: 42724.3008\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 42501.5950 - mae: 123.3702 - mse: 42501.6016\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 83us/step - loss: 42280.4867 - mae: 122.9889 - mse: 42280.4883\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 42073.4615 - mae: 122.8659 - mse: 42073.4570\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 78us/step - loss: 41848.6079 - mae: 122.9219 - mse: 41848.6094\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 80us/step - loss: 41644.0733 - mae: 123.1952 - mse: 41644.0781\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 41383.1555 - mae: 122.8572 - mse: 41383.1602\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 41139.5917 - mae: 122.0818 - mse: 41139.5898\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 40941.3581 - mae: 121.8941 - mse: 40941.3594\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 75us/step - loss: 40681.5011 - mae: 121.4462 - mse: 40681.5039\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 80us/step - loss: 40458.5366 - mae: 121.2065 - mse: 40458.5352\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 76us/step - loss: 40205.4946 - mae: 121.3084 - mse: 40205.4922\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 75us/step - loss: 39945.4798 - mae: 120.4797 - mse: 39945.4844\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 39707.9727 - mae: 119.5764 - mse: 39707.9688\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 39519.7233 - mae: 119.9130 - mse: 39519.7227\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 39200.0504 - mae: 119.9735 - mse: 39200.0547\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 75us/step - loss: 38937.4048 - mae: 118.9021 - mse: 38937.4062\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 81us/step - loss: 38722.7507 - mae: 118.9007 - mse: 38722.7539\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 81us/step - loss: 38436.5794 - mae: 117.9804 - mse: 38436.5781\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 38194.4001 - mae: 118.2512 - mse: 38194.3984\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 37893.1983 - mae: 117.7640 - mse: 37893.1953\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 37623.3465 - mae: 117.0775 - mse: 37623.3438\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 81us/step - loss: 37356.1551 - mae: 116.8241 - mse: 37356.1523\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 37071.4666 - mae: 116.3001 - mse: 37071.4648\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 36803.2751 - mae: 115.4798 - mse: 36803.2773\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 59us/step - loss: 36529.6184 - mae: 115.5516 - mse: 36529.6172\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 36249.5005 - mae: 115.2266 - mse: 36249.5039\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 35962.3054 - mae: 114.5540 - mse: 35962.3086\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 35668.2490 - mae: 114.0760 - mse: 35668.2500\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 102us/step - loss: 35401.7760 - mae: 113.8653 - mse: 35401.7734\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 35094.1779 - mae: 113.6413 - mse: 35094.1797\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 97us/step - loss: 34813.5794 - mae: 112.9469 - mse: 34813.5781\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 34534.1686 - mae: 112.5483 - mse: 34534.1719\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 107us/step - loss: 34251.4011 - mae: 112.4170 - mse: 34251.3984\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 33951.2822 - mae: 111.3578 - mse: 33951.2812\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 33677.6240 - mae: 110.4360 - mse: 33677.6250\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 33384.4979 - mae: 110.4120 - mse: 33384.4961\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 94us/step - loss: 33110.3882 - mae: 110.0808 - mse: 33110.3867\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 32801.4571 - mae: 109.3245 - mse: 32801.4609\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 124us/step - loss: 32549.8298 - mae: 109.4803 - mse: 32549.8262\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 32245.5745 - mae: 109.3951 - mse: 32245.5762\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 31952.1317 - mae: 108.6870 - mse: 31952.1309\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 31683.1915 - mae: 107.8627 - mse: 31683.1934\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 31393.9124 - mae: 107.2912 - mse: 31393.9141\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 31136.3568 - mae: 106.8196 - mse: 31136.3594\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 30870.3854 - mae: 106.3553 - mse: 30870.3828\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 30637.9765 - mae: 106.5948 - mse: 30637.9766\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 30344.5038 - mae: 105.7994 - mse: 30344.5039\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 30078.0173 - mae: 105.4294 - mse: 30078.0176\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 29805.4409 - mae: 104.8546 - mse: 29805.4395\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 83584.4316 - mae: 203.2535 - mse: 83584.4297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 78us/step - loss: 83482.1840 - mae: 202.9945 - mse: 83482.1875\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 86us/step - loss: 83357.6857 - mae: 202.6846 - mse: 83357.6875\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 94us/step - loss: 83181.7129 - mae: 202.2555 - mse: 83181.7188\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 82929.9260 - mae: 201.6180 - mse: 82929.9297\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 82540.2607 - mae: 200.6531 - mse: 82540.2578\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 81951.6526 - mae: 199.2050 - mse: 81951.6562\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 81118.7674 - mae: 197.0938 - mse: 81118.7734\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 109us/step - loss: 79934.9260 - mae: 194.0761 - mse: 79934.9297\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 83us/step - loss: 78336.0742 - mae: 190.1512 - mse: 78336.0703\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 82us/step - loss: 76346.4023 - mae: 185.0857 - mse: 76346.4062\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 73901.5779 - mae: 178.4525 - mse: 73901.5703\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 70961.5913 - mae: 170.8951 - mse: 70961.6016\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 67643.2492 - mae: 162.2888 - mse: 67643.2500\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 64102.2723 - mae: 153.2499 - mse: 64102.2734\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 86us/step - loss: 60290.9859 - mae: 143.9861 - mse: 60290.9883\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 81us/step - loss: 56441.8048 - mae: 135.4794 - mse: 56441.8008\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 87us/step - loss: 52954.3507 - mae: 128.0564 - mse: 52954.3516\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 76us/step - loss: 49825.7964 - mae: 122.5184 - mse: 49825.7969\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 94us/step - loss: 47614.5148 - mae: 120.1482 - mse: 47614.5156\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 45837.9102 - mae: 119.5043 - mse: 45837.9141\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 44780.8324 - mae: 121.1072 - mse: 44780.8281\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 44177.2535 - mae: 123.0483 - mse: 44177.2539\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 43714.4357 - mae: 124.3130 - mse: 43714.4336\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 43466.7484 - mae: 125.2966 - mse: 43466.7461\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 43270.8794 - mae: 125.8709 - mse: 43270.8828\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 84us/step - loss: 43080.0383 - mae: 126.1049 - mse: 43080.0391\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 76us/step - loss: 42897.5286 - mae: 126.5176 - mse: 42897.5312\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 42721.3535 - mae: 126.3372 - mse: 42721.3555\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 87us/step - loss: 42543.4387 - mae: 126.1117 - mse: 42543.4414\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 42386.4639 - mae: 125.8915 - mse: 42386.4648\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 42235.2905 - mae: 126.0647 - mse: 42235.2852\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 42042.2863 - mae: 126.1985 - mse: 42042.2930\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 41885.5737 - mae: 125.6942 - mse: 41885.5703\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 41711.2850 - mae: 125.1821 - mse: 41711.2812\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 41546.4568 - mae: 125.2019 - mse: 41546.4570\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 41383.6338 - mae: 125.2483 - mse: 41383.6328\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 41201.9891 - mae: 124.9127 - mse: 41201.9883\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 86us/step - loss: 41069.0847 - mae: 124.9607 - mse: 41069.0820\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 40872.6258 - mae: 124.6201 - mse: 40872.6250\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 40724.6376 - mae: 123.6736 - mse: 40724.6406\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 40553.2348 - mae: 123.6991 - mse: 40553.2344\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 134us/step - loss: 40374.6658 - mae: 123.6875 - mse: 40374.6680\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 40193.4249 - mae: 123.6849 - mse: 40193.4258\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 100us/step - loss: 40030.3254 - mae: 123.5479 - mse: 40030.3203\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 39848.7240 - mae: 123.3342 - mse: 39848.7227\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 39668.9079 - mae: 122.6901 - mse: 39668.9062\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 39520.3809 - mae: 122.6543 - mse: 39520.3789\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 39346.1503 - mae: 122.5825 - mse: 39346.1484\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 39125.1452 - mae: 122.3803 - mse: 39125.1445\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 38964.3191 - mae: 121.5638 - mse: 38964.3203\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 38773.2441 - mae: 121.4321 - mse: 38773.2383\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 38586.3445 - mae: 121.0076 - mse: 38586.3477\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 38413.8396 - mae: 121.0893 - mse: 38413.8398\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 38235.7107 - mae: 121.0437 - mse: 38235.7109\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 38023.4207 - mae: 120.6906 - mse: 38023.4219\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 37818.1964 - mae: 120.2626 - mse: 37818.1953\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 37628.6766 - mae: 119.6054 - mse: 37628.6758\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 37434.7935 - mae: 119.3999 - mse: 37434.7969\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 37238.9658 - mae: 119.3038 - mse: 37238.9648\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 114us/step - loss: 37037.9304 - mae: 119.1872 - mse: 37037.9336\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 36851.8564 - mae: 119.3017 - mse: 36851.8594\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 36615.4409 - mae: 118.7606 - mse: 36615.4414\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 114us/step - loss: 36422.8982 - mae: 118.1387 - mse: 36422.8984\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 36215.6885 - mae: 117.5779 - mse: 36215.6914\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 36034.3290 - mae: 116.8515 - mse: 36034.3281\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 35839.3283 - mae: 117.3715 - mse: 35839.3281\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 110us/step - loss: 35566.7340 - mae: 117.1784 - mse: 35566.7305\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 35365.7837 - mae: 116.4903 - mse: 35365.7852\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 35140.1255 - mae: 116.1018 - mse: 35140.1250\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 34984.8938 - mae: 116.5307 - mse: 34984.8984\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 34690.0617 - mae: 115.5727 - mse: 34690.0586\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 34481.3514 - mae: 114.7421 - mse: 34481.3516\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 34252.3579 - mae: 114.3160 - mse: 34252.3555\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 34022.9966 - mae: 114.3201 - mse: 34022.9961\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 33792.9136 - mae: 113.9432 - mse: 33792.9102\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 33594.8579 - mae: 113.7432 - mse: 33594.8633\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 33369.5504 - mae: 112.7808 - mse: 33369.5508\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 33145.1079 - mae: 112.6512 - mse: 33145.1094\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 32940.5132 - mae: 113.3882 - mse: 32940.5117\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 114us/step - loss: 32632.6607 - mae: 112.1362 - mse: 32632.6602\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 32403.5292 - mae: 111.1189 - mse: 32403.5293\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 32190.6236 - mae: 110.8667 - mse: 32190.6230\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 109us/step - loss: 31938.3620 - mae: 110.6325 - mse: 31938.3594\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 31726.7499 - mae: 110.3354 - mse: 31726.7500\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 31465.7775 - mae: 109.8161 - mse: 31465.7793\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 31240.2479 - mae: 109.1726 - mse: 31240.2500\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 31001.9493 - mae: 108.6826 - mse: 31001.9473\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 30789.2573 - mae: 108.5377 - mse: 30789.2598\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 30542.1444 - mae: 108.3675 - mse: 30542.1406\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 30296.5293 - mae: 107.4456 - mse: 30296.5293\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 109us/step - loss: 30085.1933 - mae: 106.7278 - mse: 30085.1934\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 29856.3844 - mae: 106.8475 - mse: 29856.3867\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 102us/step - loss: 29618.1885 - mae: 106.8355 - mse: 29618.1875\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 29398.9138 - mae: 106.0865 - mse: 29398.9160\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 29177.0378 - mae: 105.7129 - mse: 29177.0371\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 28937.1992 - mae: 105.4668 - mse: 28937.1973\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 28714.8163 - mae: 104.5812 - mse: 28714.8125\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 83us/step - loss: 28506.2301 - mae: 104.1093 - mse: 28506.2324\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 83us/step - loss: 28323.3754 - mae: 103.3535 - mse: 28323.3770\n",
      "Epoch 1/100\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 84411.5988 - mae: 200.9928 - mse: 84411.5859\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 0s 100us/step - loss: 84240.2335 - mae: 200.5613 - mse: 84240.2266\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 0s 106us/step - loss: 83990.0888 - mae: 199.9339 - mse: 83990.0859\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 0s 110us/step - loss: 83613.6533 - mae: 198.9828 - mse: 83613.6562\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 0s 94us/step - loss: 83044.9752 - mae: 197.5064 - mse: 83044.9844\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 0s 81us/step - loss: 82140.4529 - mae: 195.2379 - mse: 82140.4453\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 0s 65us/step - loss: 80753.2608 - mae: 191.8264 - mse: 80753.2734\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 0s 90us/step - loss: 78806.7986 - mae: 186.8180 - mse: 78806.7969\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 0s 84us/step - loss: 76161.2454 - mae: 179.9488 - mse: 76161.2422\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 0s 88us/step - loss: 72838.1763 - mae: 171.2950 - mse: 72838.1719\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 0s 92us/step - loss: 68811.6472 - mae: 161.1668 - mse: 68811.6484\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 0s 85us/step - loss: 64363.6940 - mae: 150.2482 - mse: 64363.7031\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 0s 100us/step - loss: 59596.8747 - mae: 139.1686 - mse: 59596.8750\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 0s 105us/step - loss: 55264.5349 - mae: 129.5784 - mse: 55264.5352\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 0s 92us/step - loss: 51551.1817 - mae: 122.9676 - mse: 51551.1875\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 0s 84us/step - loss: 48605.6265 - mae: 119.3274 - mse: 48605.6211\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 0s 86us/step - loss: 46961.3100 - mae: 120.1641 - mse: 46961.3125\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 0s 90us/step - loss: 45947.3760 - mae: 122.2065 - mse: 45947.3750\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 0s 101us/step - loss: 45414.4888 - mae: 123.9312 - mse: 45414.4922\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 0s 118us/step - loss: 45100.2221 - mae: 125.3438 - mse: 45100.2227\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 0s 115us/step - loss: 44884.7927 - mae: 125.9670 - mse: 44884.7930\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 0s 122us/step - loss: 44684.8833 - mae: 126.6110 - mse: 44684.8867\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 0s 104us/step - loss: 44500.6983 - mae: 126.8087 - mse: 44500.6992\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 0s 102us/step - loss: 44302.7691 - mae: 126.7286 - mse: 44302.7695\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 0s 109us/step - loss: 44106.6636 - mae: 126.0220 - mse: 44106.6641\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 0s 106us/step - loss: 43969.2271 - mae: 126.2778 - mse: 43969.2266\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 0s 108us/step - loss: 43733.6462 - mae: 125.8500 - mse: 43733.6445\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 0s 117us/step - loss: 43564.9808 - mae: 125.6381 - mse: 43564.9844\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 0s 113us/step - loss: 43363.9703 - mae: 125.4092 - mse: 43363.9688\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 0s 103us/step - loss: 43173.8489 - mae: 124.6818 - mse: 43173.8398\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 0s 99us/step - loss: 42995.2727 - mae: 124.1598 - mse: 42995.2695\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 0s 113us/step - loss: 42896.1813 - mae: 125.4983 - mse: 42896.1719\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 0s 112us/step - loss: 42597.0748 - mae: 125.1368 - mse: 42597.0781\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 0s 104us/step - loss: 42416.1508 - mae: 123.9723 - mse: 42416.1523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "750/750 [==============================] - 0s 106us/step - loss: 42220.2490 - mae: 123.4877 - mse: 42220.2500\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 0s 108us/step - loss: 42012.0096 - mae: 123.5375 - mse: 42012.0117\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 0s 105us/step - loss: 41808.6521 - mae: 123.7586 - mse: 41808.6523\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 0s 107us/step - loss: 41609.1574 - mae: 123.4319 - mse: 41609.1602\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 0s 101us/step - loss: 41394.3899 - mae: 123.1841 - mse: 41394.3867\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 0s 106us/step - loss: 41186.2883 - mae: 122.5807 - mse: 41186.2930\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 0s 88us/step - loss: 40970.1842 - mae: 122.2040 - mse: 40970.1836\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 0s 100us/step - loss: 40759.6897 - mae: 121.9365 - mse: 40759.6914\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 0s 114us/step - loss: 40532.8905 - mae: 121.7379 - mse: 40532.8867\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 0s 121us/step - loss: 40309.9262 - mae: 121.8199 - mse: 40309.9258\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 0s 123us/step - loss: 40070.9439 - mae: 121.5860 - mse: 40070.9414\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 0s 106us/step - loss: 39858.5638 - mae: 121.2292 - mse: 39858.5625\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 0s 104us/step - loss: 39662.2467 - mae: 120.1722 - mse: 39662.2461\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 0s 106us/step - loss: 39403.3057 - mae: 120.4222 - mse: 39403.3047\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 0s 108us/step - loss: 39134.5009 - mae: 119.9282 - mse: 39134.5000\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 0s 102us/step - loss: 38890.1958 - mae: 119.7329 - mse: 38890.1992\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 0s 105us/step - loss: 38645.3089 - mae: 119.5897 - mse: 38645.3164\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 0s 101us/step - loss: 38407.4714 - mae: 118.6721 - mse: 38407.4648\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 0s 115us/step - loss: 38144.6682 - mae: 118.6263 - mse: 38144.6680\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 0s 97us/step - loss: 37877.3459 - mae: 118.0595 - mse: 37877.3438\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 0s 110us/step - loss: 37632.9505 - mae: 118.1457 - mse: 37632.9492\n",
      "Epoch 56/100\n",
      "750/750 [==============================] - 0s 105us/step - loss: 37357.6892 - mae: 117.1655 - mse: 37357.6875\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 0s 112us/step - loss: 37087.8659 - mae: 116.9870 - mse: 37087.8672\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 0s 105us/step - loss: 36799.4672 - mae: 116.4110 - mse: 36799.4648\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 0s 111us/step - loss: 36520.1354 - mae: 115.8449 - mse: 36520.1328\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 0s 112us/step - loss: 36257.8333 - mae: 115.7533 - mse: 36257.8320\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 0s 117us/step - loss: 35964.0373 - mae: 114.7877 - mse: 35964.0391\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 0s 103us/step - loss: 35683.1729 - mae: 114.0824 - mse: 35683.1719\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 0s 101us/step - loss: 35385.9570 - mae: 114.1773 - mse: 35385.9570\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 0s 104us/step - loss: 35107.9501 - mae: 113.8333 - mse: 35107.9453\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 0s 120us/step - loss: 34801.4285 - mae: 113.2797 - mse: 34801.4297\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 0s 72us/step - loss: 34510.4467 - mae: 112.5309 - mse: 34510.4492\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 0s 65us/step - loss: 34227.7355 - mae: 112.4285 - mse: 34227.7344\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 0s 96us/step - loss: 33951.8369 - mae: 112.3171 - mse: 33951.8398\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 0s 107us/step - loss: 33625.6182 - mae: 111.0692 - mse: 33625.6211\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 0s 105us/step - loss: 33343.9671 - mae: 110.0429 - mse: 33343.9688\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 0s 105us/step - loss: 33004.6650 - mae: 110.0429 - mse: 33004.6680\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 0s 108us/step - loss: 32697.7455 - mae: 109.9489 - mse: 32697.7441\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 0s 104us/step - loss: 32406.0592 - mae: 109.2729 - mse: 32406.0586\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 0s 104us/step - loss: 32139.2027 - mae: 109.0001 - mse: 32139.2070\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 0s 104us/step - loss: 31824.1277 - mae: 108.0262 - mse: 31824.1289\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 0s 109us/step - loss: 31512.5434 - mae: 107.4381 - mse: 31512.5410\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 0s 102us/step - loss: 31234.5501 - mae: 107.1031 - mse: 31234.5469\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 0s 106us/step - loss: 30928.9671 - mae: 106.1605 - mse: 30928.9688\n",
      "Epoch 79/100\n",
      "750/750 [==============================] - 0s 115us/step - loss: 30644.7310 - mae: 105.5086 - mse: 30644.7305\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 0s 122us/step - loss: 30362.4770 - mae: 105.2671 - mse: 30362.4746\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 0s 110us/step - loss: 30077.4521 - mae: 105.0587 - mse: 30077.4551\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 0s 118us/step - loss: 29795.3957 - mae: 104.5771 - mse: 29795.3965\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 0s 117us/step - loss: 29521.4222 - mae: 104.0234 - mse: 29521.4238\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 0s 104us/step - loss: 29281.9786 - mae: 102.7176 - mse: 29281.9785\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 0s 94us/step - loss: 28988.1093 - mae: 102.9600 - mse: 28988.1113\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 0s 100us/step - loss: 28723.1835 - mae: 102.9993 - mse: 28723.1836\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 0s 100us/step - loss: 28497.9346 - mae: 102.6854 - mse: 28497.9355\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 0s 106us/step - loss: 28197.9399 - mae: 101.4365 - mse: 28197.9414\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 0s 108us/step - loss: 27989.2571 - mae: 100.6515 - mse: 27989.2578\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 0s 120us/step - loss: 27746.3346 - mae: 100.1425 - mse: 27746.3340\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 0s 106us/step - loss: 27547.8786 - mae: 100.5352 - mse: 27547.8770\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 0s 96us/step - loss: 27280.6094 - mae: 99.8017 - mse: 27280.6055\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 0s 98us/step - loss: 27072.7285 - mae: 99.5710 - mse: 27072.7285\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 0s 89us/step - loss: 26875.8134 - mae: 98.9087 - mse: 26875.8125\n",
      "Epoch 95/100\n",
      "750/750 [==============================] - 0s 106us/step - loss: 26673.6300 - mae: 99.0007 - mse: 26673.6328\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 0s 109us/step - loss: 26470.4818 - mae: 98.1130 - mse: 26470.4805\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 0s 108us/step - loss: 26295.7141 - mae: 97.6881 - mse: 26295.7148\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 0s 107us/step - loss: 26099.9342 - mae: 97.7709 - mse: 26099.9336\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 0s 113us/step - loss: 25925.8474 - mae: 97.7080 - mse: 25925.8457\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 0s 107us/step - loss: 25772.0175 - mae: 97.2211 - mse: 25772.0195\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=22, activation = 'relu', input_dim=22))\n",
    "    model.add(Dense(units=22, activation = 'relu'))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae','mse'])\n",
    "    return model\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "NN_Regressor = KerasRegressor(build_fn=build_model, batch_size=40,epochs=100)    \n",
    "\n",
    "scores = cross_val_score(NN_Regressor, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "NN = NN_Regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the scores for each model run\n",
      "[-28341.99958333 -20514.16307222 -45200.4692771  -24950.09222781\n",
      " -39039.25112159]\n",
      " \n",
      "Mean and variance: 31609.20 (+/- 18287.62)\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 108.65183544799805\n",
      "Root Mean Squared Error: 204.58919486071133\n",
      "Time Taken =  120.703125\n"
     ]
    }
   ],
   "source": [
    "print(\"Below are the scores for each model run\")\n",
    "print(scores)\n",
    "print(\" \")\n",
    "print(\"Mean and variance: %0.2f (+/- %0.2f)\" % (abs(scores.mean()), scores.std() * 2))\n",
    "\n",
    "y_pred= NN_Regressor.predict(X_test_holdout)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 86356.1073 - mae: 204.9122 - mse: 86356.1094\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 86323.5849 - mae: 204.8364 - mse: 86323.5859\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 86297.2849 - mae: 204.7706 - mse: 86297.2812\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 86260.7523 - mae: 204.6793 - mse: 86260.7578\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 86195.3736 - mae: 204.5128 - mse: 86195.3828\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 112us/step - loss: 86083.9477 - mae: 204.2383 - mse: 86083.9531\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 85910.7497 - mae: 203.8105 - mse: 85910.7500\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 85641.3262 - mae: 203.1542 - mse: 85641.3359\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 85239.4695 - mae: 202.1465 - mse: 85239.4688\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 84627.6099 - mae: 200.6388 - mse: 84627.6016\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 83759.1021 - mae: 198.4403 - mse: 83759.1016\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 82503.5430 - mae: 195.3434 - mse: 82503.5469\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 128us/step - loss: 80775.2133 - mae: 190.7982 - mse: 80775.2109\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 100us/step - loss: 78187.1372 - mae: 184.2303 - mse: 78187.1484\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 74623.6823 - mae: 175.1356 - mse: 74623.6797\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 70229.8427 - mae: 163.4248 - mse: 70229.8438\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 64697.8014 - mae: 150.6605 - mse: 64697.8008\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 58841.5648 - mae: 137.2348 - mse: 58841.5664\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 53429.5559 - mae: 125.3262 - mse: 53429.5508\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 112us/step - loss: 49507.8374 - mae: 121.6997 - mse: 49507.8398\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 47336.1594 - mae: 123.9662 - mse: 47336.1602\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 46268.9076 - mae: 127.3961 - mse: 46268.9102\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 45968.0373 - mae: 129.8802 - mse: 45968.0352\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 45673.5113 - mae: 130.4035 - mse: 45673.5117\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 45430.6284 - mae: 129.9408 - mse: 45430.6289\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 45184.0002 - mae: 129.8426 - mse: 45184.0000\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 44953.7783 - mae: 129.5110 - mse: 44953.7812\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 44735.7973 - mae: 129.3773 - mse: 44735.7969\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 44482.3497 - mae: 128.9728 - mse: 44482.3477\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 44277.9102 - mae: 128.7567 - mse: 44277.9141\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 44039.1882 - mae: 127.9893 - mse: 44039.1875\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 43785.3810 - mae: 127.5526 - mse: 43785.3867\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 43520.6609 - mae: 127.2939 - mse: 43520.6641\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 43298.4721 - mae: 127.2606 - mse: 43298.4688\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 43073.0253 - mae: 127.7566 - mse: 43073.0273\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 42813.9620 - mae: 127.2651 - mse: 42813.9648\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 42571.5569 - mae: 126.7760 - mse: 42571.5586\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 42308.8111 - mae: 126.2749 - mse: 42308.8125\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 42048.3512 - mae: 125.7808 - mse: 42048.3516\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 41807.8532 - mae: 125.0866 - mse: 41807.8477\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 41514.9687 - mae: 124.8821 - mse: 41514.9648\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 41249.5367 - mae: 124.9123 - mse: 41249.5391\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 41011.8738 - mae: 124.8332 - mse: 41011.8750\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 40707.9161 - mae: 124.1089 - mse: 40707.9141\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 40415.9635 - mae: 123.0437 - mse: 40415.9609\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 40110.0318 - mae: 123.1093 - mse: 40110.0352\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 39862.9173 - mae: 123.2320 - mse: 39862.9180\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 39539.9165 - mae: 122.4935 - mse: 39539.9180\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 39240.7880 - mae: 121.6322 - mse: 39240.7852\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 38930.8921 - mae: 121.0424 - mse: 38930.8906\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 112us/step - loss: 38619.1452 - mae: 120.9021 - mse: 38619.1445\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 38289.6383 - mae: 119.8450 - mse: 38289.6406\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 37979.9855 - mae: 119.4070 - mse: 37979.9844\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 37652.1479 - mae: 119.2262 - mse: 37652.1484\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 37296.2836 - mae: 118.4273 - mse: 37296.2852\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 36954.4342 - mae: 117.7611 - mse: 36954.4336\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 36609.4489 - mae: 117.2969 - mse: 36609.4492\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 36244.8729 - mae: 116.8301 - mse: 36244.8711\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 35868.9326 - mae: 115.6101 - mse: 35868.9336\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 35514.5276 - mae: 115.0679 - mse: 35514.5312\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 35133.5722 - mae: 114.4962 - mse: 35133.5703\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 34773.6691 - mae: 114.1427 - mse: 34773.6680\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 34414.6744 - mae: 113.5949 - mse: 34414.6719\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 34019.9088 - mae: 112.6555 - mse: 34019.9102\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 33687.8551 - mae: 112.9836 - mse: 33687.8555\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 131us/step - loss: 33256.3753 - mae: 111.1977 - mse: 33256.3750\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 139us/step - loss: 32889.2843 - mae: 109.9963 - mse: 32889.2852\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 112us/step - loss: 32531.3025 - mae: 110.2185 - mse: 32531.3027\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 32135.9141 - mae: 109.8215 - mse: 32135.9160\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 89us/step - loss: 31780.3652 - mae: 109.0644 - mse: 31780.3672\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 94us/step - loss: 31402.6375 - mae: 107.6368 - mse: 31402.6406\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 31011.9435 - mae: 107.0061 - mse: 31011.9395\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 30648.0948 - mae: 106.2948 - mse: 30648.0957\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 30333.5232 - mae: 106.6049 - mse: 30333.5234\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 30013.1711 - mae: 105.1753 - mse: 30013.1660\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 29653.7279 - mae: 104.3251 - mse: 29653.7305\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 29331.7058 - mae: 105.3080 - mse: 29331.7070\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 28982.2975 - mae: 104.5145 - mse: 28982.3008\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 28633.0171 - mae: 102.5530 - mse: 28633.0176\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 28380.8908 - mae: 101.9463 - mse: 28380.8906\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 28075.8911 - mae: 101.3002 - mse: 28075.8926\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 27793.1683 - mae: 100.7860 - mse: 27793.1680\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 27509.0081 - mae: 100.5823 - mse: 27509.0117\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 98us/step - loss: 27292.8230 - mae: 100.7061 - mse: 27292.8223\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 26979.8129 - mae: 100.2796 - mse: 26979.8125\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 26751.6620 - mae: 99.0363 - mse: 26751.6641\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 26513.6609 - mae: 98.0711 - mse: 26513.6602\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 26306.1260 - mae: 98.2455 - mse: 26306.1250\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 26086.9187 - mae: 98.1148 - mse: 26086.9160\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 84us/step - loss: 25903.7307 - mae: 98.0232 - mse: 25903.7285\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 25694.9394 - mae: 97.2041 - mse: 25694.9375\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 82us/step - loss: 25537.2751 - mae: 96.8546 - mse: 25537.2734\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 25339.4975 - mae: 96.8914 - mse: 25339.4980\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 25273.5802 - mae: 96.3572 - mse: 25273.5820\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 25033.9958 - mae: 96.1985 - mse: 25033.9941\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 24922.5608 - mae: 96.8533 - mse: 24922.5645\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 24764.9815 - mae: 95.7421 - mse: 24764.9824\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 24649.4817 - mae: 95.1580 - mse: 24649.4805\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 94us/step - loss: 24492.2885 - mae: 95.2960 - mse: 24492.2871\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 24448.0152 - mae: 95.5716 - mse: 24448.0176\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 88958.0964 - mae: 205.3235 - mse: 88958.1016\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 88792.3789 - mae: 204.9201 - mse: 88792.3750\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 88571.3526 - mae: 204.3790 - mse: 88571.3594\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 88262.2439 - mae: 203.6305 - mse: 88262.2422\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 87818.5945 - mae: 202.4963 - mse: 87818.5938\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 87129.9352 - mae: 200.7982 - mse: 87129.9297\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 86146.7661 - mae: 198.3118 - mse: 86146.7500\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 84694.6503 - mae: 194.7027 - mse: 84694.6484\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 82610.8659 - mae: 189.5583 - mse: 82610.8672\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 87us/step - loss: 79901.0096 - mae: 182.4121 - mse: 79901.0078\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 76322.4732 - mae: 173.3880 - mse: 76322.4766\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 72029.7632 - mae: 162.5455 - mse: 72029.7656\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 67218.2017 - mae: 151.0271 - mse: 67218.2031\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 62202.3565 - mae: 139.4886 - mse: 62202.3516\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 102us/step - loss: 57336.5771 - mae: 129.9672 - mse: 57336.5781\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 53752.4921 - mae: 124.9554 - mse: 53752.4961\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 50973.7839 - mae: 123.8955 - mse: 50973.7852\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 49667.8030 - mae: 125.9290 - mse: 49667.8008\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 49011.9715 - mae: 128.7140 - mse: 49011.9727\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 124us/step - loss: 48732.9737 - mae: 130.2921 - mse: 48732.9727\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 86us/step - loss: 48556.6745 - mae: 131.4562 - mse: 48556.6758\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 48462.9218 - mae: 130.9355 - mse: 48462.9219\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 48202.1508 - mae: 130.8289 - mse: 48202.1484\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 48017.4966 - mae: 130.7997 - mse: 48017.4961\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 47858.6297 - mae: 130.9998 - mse: 47858.6289\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 47756.4728 - mae: 131.5184 - mse: 47756.4727\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 47574.3299 - mae: 130.0859 - mse: 47574.3320\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 47373.7421 - mae: 129.1967 - mse: 47373.7422\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 47196.8751 - mae: 129.3748 - mse: 47196.8750\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 47047.1056 - mae: 130.0006 - mse: 47047.1016\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 46886.0638 - mae: 129.9611 - mse: 46886.0664\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 46717.6549 - mae: 130.0532 - mse: 46717.6484\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 46565.6405 - mae: 129.8543 - mse: 46565.6406\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 93us/step - loss: 46393.9460 - mae: 129.2937 - mse: 46393.9414\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 86us/step - loss: 46236.9781 - mae: 129.0549 - mse: 46236.9805\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 46069.5365 - mae: 128.9280 - mse: 46069.5391\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 45918.7681 - mae: 128.8362 - mse: 45918.7695\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 45762.4768 - mae: 128.6837 - mse: 45762.4727\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 45579.4806 - mae: 128.4513 - mse: 45579.4805\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 45441.7250 - mae: 128.0968 - mse: 45441.7266\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 83us/step - loss: 45255.9232 - mae: 128.0750 - mse: 45255.9219\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 45083.9587 - mae: 128.2421 - mse: 45083.9609\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 119us/step - loss: 44925.8768 - mae: 128.0237 - mse: 44925.8789\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 44771.2274 - mae: 127.2183 - mse: 44771.2227\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 83us/step - loss: 44594.3695 - mae: 127.4125 - mse: 44594.3672\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 44407.8141 - mae: 127.1893 - mse: 44407.8203\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 126us/step - loss: 44221.5921 - mae: 126.8609 - mse: 44221.5977\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 44056.9738 - mae: 127.1124 - mse: 44056.9688\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 127us/step - loss: 43851.2754 - mae: 126.1663 - mse: 43851.2695\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 43690.1882 - mae: 126.4369 - mse: 43690.1914\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 43487.2225 - mae: 125.7095 - mse: 43487.2188\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 43296.2809 - mae: 125.6659 - mse: 43296.2812\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 43089.5714 - mae: 125.7307 - mse: 43089.5742\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 42913.4445 - mae: 124.8416 - mse: 42913.4453\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 42699.7559 - mae: 124.7446 - mse: 42699.7617\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 42506.6837 - mae: 125.0187 - mse: 42506.6836\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 42282.8579 - mae: 124.7082 - mse: 42282.8516\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 42055.3464 - mae: 124.3159 - mse: 42055.3477\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 41861.5641 - mae: 123.5591 - mse: 41861.5703\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 41629.2241 - mae: 123.4494 - mse: 41629.2266\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 114us/step - loss: 41417.1033 - mae: 123.6548 - mse: 41417.1016\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 41178.3868 - mae: 123.2149 - mse: 41178.3828\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 40940.0021 - mae: 122.6808 - mse: 40940.0039\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 40702.2605 - mae: 122.0780 - mse: 40702.2617\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 40507.1540 - mae: 122.1133 - mse: 40507.1562\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 119us/step - loss: 40235.4615 - mae: 121.9874 - mse: 40235.4570\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 39966.7124 - mae: 121.7109 - mse: 39966.7109\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 39724.5591 - mae: 120.4213 - mse: 39724.5586\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 39472.3924 - mae: 120.2237 - mse: 39472.3867\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 39187.3081 - mae: 119.8701 - mse: 39187.3086\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 38930.7165 - mae: 118.8327 - mse: 38930.7148\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 38644.5057 - mae: 118.9451 - mse: 38644.5078\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 38430.6040 - mae: 119.6240 - mse: 38430.6016\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 38078.0247 - mae: 118.8191 - mse: 38078.0234\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 112us/step - loss: 37795.6162 - mae: 117.8435 - mse: 37795.6172\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 122us/step - loss: 37524.7463 - mae: 117.5321 - mse: 37524.7422\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 37193.7892 - mae: 116.3908 - mse: 37193.7891\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 36919.8955 - mae: 115.7743 - mse: 36919.8945\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 36629.0156 - mae: 116.1046 - mse: 36629.0195\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 36318.0651 - mae: 116.5010 - mse: 36318.0703\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 35963.0819 - mae: 115.1553 - mse: 35963.0781\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 35720.7438 - mae: 114.6760 - mse: 35720.7422\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 35362.8930 - mae: 113.9546 - mse: 35362.8945\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 35022.9873 - mae: 113.2951 - mse: 35022.9883\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 34716.1755 - mae: 112.8108 - mse: 34716.1797\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 34372.1007 - mae: 111.9394 - mse: 34372.1016\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 128us/step - loss: 34104.0753 - mae: 112.4861 - mse: 34104.0781\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 33710.1409 - mae: 111.5663 - mse: 33710.1406\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 33373.0275 - mae: 110.8021 - mse: 33373.0273\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 33069.0614 - mae: 109.7291 - mse: 33069.0625\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 32717.5477 - mae: 109.6980 - mse: 32717.5469\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 32438.8223 - mae: 109.0302 - mse: 32438.8203\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 32062.1016 - mae: 108.4471 - mse: 32062.1035\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 126us/step - loss: 31738.0473 - mae: 108.4776 - mse: 31738.0469\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 31463.0077 - mae: 108.3749 - mse: 31463.0059\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 31140.2561 - mae: 107.6119 - mse: 31140.2559\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 131us/step - loss: 30837.1131 - mae: 107.1008 - mse: 30837.1133\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 30549.2447 - mae: 106.1508 - mse: 30549.2441\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 119us/step - loss: 30261.3551 - mae: 105.9856 - mse: 30261.3574\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 118us/step - loss: 30001.5000 - mae: 105.5575 - mse: 30001.5000\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 77962.6747 - mae: 195.2872 - mse: 77962.6797\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 89us/step - loss: 77876.5219 - mae: 195.0615 - mse: 77876.5234\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 99us/step - loss: 77770.6243 - mae: 194.7799 - mse: 77770.6328\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 77631.2676 - mae: 194.4128 - mse: 77631.2656\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 77445.1771 - mae: 193.9141 - mse: 77445.1875\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 77186.5087 - mae: 193.2658 - mse: 77186.5078\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 76863.8456 - mae: 192.3954 - mse: 76863.8438\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 98us/step - loss: 76414.6591 - mae: 191.2536 - mse: 76414.6641\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 75809.6924 - mae: 189.6487 - mse: 75809.6875\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 74968.6286 - mae: 187.3948 - mse: 74968.6328\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 73797.3411 - mae: 184.3546 - mse: 73797.3438\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 72248.3335 - mae: 180.3113 - mse: 72248.3359\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 83us/step - loss: 70281.9480 - mae: 174.9633 - mse: 70281.9531\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 67843.7268 - mae: 168.3705 - mse: 67843.7266\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 98us/step - loss: 64979.6943 - mae: 160.4189 - mse: 64979.6914\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 99us/step - loss: 61757.1870 - mae: 152.0135 - mse: 61757.1914\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 58182.0625 - mae: 142.8783 - mse: 58182.0586\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 109us/step - loss: 54497.3708 - mae: 134.0038 - mse: 54497.3711\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 204us/step - loss: 51002.7105 - mae: 125.1763 - mse: 51002.7109\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 124us/step - loss: 47706.8385 - mae: 118.3505 - mse: 47706.8398\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 45218.5417 - mae: 114.8235 - mse: 45218.5391\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 43495.2270 - mae: 113.8889 - mse: 43495.2266\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 42471.6163 - mae: 115.3864 - mse: 42471.6133\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 128us/step - loss: 41903.1210 - mae: 117.2071 - mse: 41903.1211\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 41622.6260 - mae: 118.9211 - mse: 41622.6250\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 41444.9231 - mae: 119.9538 - mse: 41444.9219\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 41311.2111 - mae: 120.3814 - mse: 41311.2148\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 41184.7340 - mae: 120.8151 - mse: 41184.7383\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 41067.4335 - mae: 120.5253 - mse: 41067.4336\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 119us/step - loss: 40940.3686 - mae: 120.4389 - mse: 40940.3672\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 40821.2984 - mae: 120.6092 - mse: 40821.3008\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 40709.4874 - mae: 120.0109 - mse: 40709.4883\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 40583.6267 - mae: 119.6600 - mse: 40583.6250\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 128us/step - loss: 40471.4079 - mae: 120.0403 - mse: 40471.4062\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 131us/step - loss: 40356.1878 - mae: 120.0162 - mse: 40356.1875\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 40231.5677 - mae: 119.8813 - mse: 40231.5703\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 40131.8493 - mae: 119.2384 - mse: 40131.8516\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 127us/step - loss: 40029.3709 - mae: 119.5589 - mse: 40029.3711\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 39900.4852 - mae: 119.8118 - mse: 39900.4844\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 39808.5893 - mae: 118.8570 - mse: 39808.5898\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 39668.0264 - mae: 118.1028 - mse: 39668.0273\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 39560.9529 - mae: 118.7220 - mse: 39560.9531\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 39435.6109 - mae: 119.0090 - mse: 39435.6094\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 39326.0040 - mae: 119.0774 - mse: 39326.0039\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 39207.6351 - mae: 118.5092 - mse: 39207.6328\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 39119.0182 - mae: 118.5721 - mse: 39119.0156\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 38963.3819 - mae: 118.2945 - mse: 38963.3828\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 38854.3725 - mae: 118.0257 - mse: 38854.3750\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 38728.4489 - mae: 117.7561 - mse: 38728.4453\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 126us/step - loss: 38601.0304 - mae: 117.4377 - mse: 38601.0312\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 38499.4904 - mae: 117.4822 - mse: 38499.4883\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 38371.8152 - mae: 117.0640 - mse: 38371.8164\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 38274.8280 - mae: 117.3319 - mse: 38274.8281\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 128us/step - loss: 38102.5447 - mae: 117.3788 - mse: 38102.5430\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 38017.5546 - mae: 117.0965 - mse: 38017.5586\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 37836.0548 - mae: 116.5803 - mse: 37836.0586\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 37698.2644 - mae: 116.1154 - mse: 37698.2656\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 37531.7358 - mae: 115.6796 - mse: 37531.7383\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 126us/step - loss: 37381.3727 - mae: 116.0075 - mse: 37381.3750\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 37179.4946 - mae: 115.5421 - mse: 37179.4922\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 36982.7166 - mae: 114.9098 - mse: 36982.7148\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 129us/step - loss: 36779.1817 - mae: 114.1502 - mse: 36779.1797\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 36568.9357 - mae: 113.8032 - mse: 36568.9375\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 131us/step - loss: 36369.7937 - mae: 113.4646 - mse: 36369.7930\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 36157.4054 - mae: 113.3625 - mse: 36157.4062\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 121us/step - loss: 35938.4968 - mae: 113.0703 - mse: 35938.5000\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 142us/step - loss: 35716.7137 - mae: 112.5146 - mse: 35716.7109\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 112us/step - loss: 35503.5122 - mae: 112.6555 - mse: 35503.5117\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 35254.3422 - mae: 112.1756 - mse: 35254.3398\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 124us/step - loss: 35034.7629 - mae: 111.7096 - mse: 35034.7656\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 34808.3533 - mae: 111.3667 - mse: 34808.3516\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 34552.6516 - mae: 110.8504 - mse: 34552.6484\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 34318.4408 - mae: 110.9118 - mse: 34318.4453\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 34047.8297 - mae: 110.3195 - mse: 34047.8281\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 126us/step - loss: 33781.4615 - mae: 109.1087 - mse: 33781.4609\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 129us/step - loss: 33528.9945 - mae: 108.6587 - mse: 33528.9922\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 33242.3812 - mae: 108.5459 - mse: 33242.3789\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 109us/step - loss: 32955.4991 - mae: 108.2547 - mse: 32955.4961\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 32685.6615 - mae: 107.8631 - mse: 32685.6602\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 32381.2380 - mae: 106.7318 - mse: 32381.2363\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 126us/step - loss: 32117.3409 - mae: 106.4205 - mse: 32117.3438\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 31768.9778 - mae: 106.5923 - mse: 31768.9766\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 107us/step - loss: 31463.8245 - mae: 105.6335 - mse: 31463.8242\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 31163.6696 - mae: 104.3578 - mse: 31163.6699\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 30904.1798 - mae: 104.6550 - mse: 30904.1836\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 30539.0479 - mae: 104.4675 - mse: 30539.0508\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 30210.9129 - mae: 102.2813 - mse: 30210.9102\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 29866.3281 - mae: 101.5177 - mse: 29866.3301\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 29614.3527 - mae: 102.8219 - mse: 29614.3496\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 29235.4279 - mae: 101.6451 - mse: 29235.4297\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 80us/step - loss: 28911.7524 - mae: 100.7828 - mse: 28911.7559\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 83us/step - loss: 28639.4015 - mae: 100.7770 - mse: 28639.4043\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 28261.8665 - mae: 99.7000 - mse: 28261.8672\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 27931.1562 - mae: 98.7482 - mse: 27931.1543\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 27628.1102 - mae: 98.1751 - mse: 27628.1094\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 27341.3812 - mae: 98.1230 - mse: 27341.3828\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 27000.6202 - mae: 97.0516 - mse: 27000.6172\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 26691.1894 - mae: 96.2480 - mse: 26691.1914\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 26420.7552 - mae: 96.9803 - mse: 26420.7559\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 26126.5021 - mae: 96.2126 - mse: 26126.5039\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 85133.5419 - mae: 196.0797 - mse: 85133.5469\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 85032.1887 - mae: 195.8025 - mse: 85032.1875\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 84879.0990 - mae: 195.3811 - mse: 84879.0938\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 84641.4883 - mae: 194.7502 - mse: 84641.4844\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 84280.8561 - mae: 193.7847 - mse: 84280.8594\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 100us/step - loss: 83698.5815 - mae: 192.2626 - mse: 83698.5781\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 82807.0172 - mae: 189.9043 - mse: 82807.0234\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 81459.1806 - mae: 186.3188 - mse: 81459.1797\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 79470.0096 - mae: 181.2117 - mse: 79470.0156\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 76715.9382 - mae: 173.8942 - mse: 76715.9375\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 73076.5132 - mae: 164.2057 - mse: 73076.5078\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 92us/step - loss: 68512.6602 - mae: 152.8510 - mse: 68512.6641\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 63487.9287 - mae: 140.9684 - mse: 63487.9258\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 58390.4033 - mae: 130.3500 - mse: 58390.4062\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 119us/step - loss: 54116.5967 - mae: 122.8571 - mse: 54116.5977\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 51248.7589 - mae: 121.7748 - mse: 51248.7617\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 49457.4157 - mae: 123.7385 - mse: 49457.4102\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 48771.5934 - mae: 126.5025 - mse: 48771.5977\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 94us/step - loss: 48451.0235 - mae: 128.1542 - mse: 48451.0273\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 48227.5263 - mae: 129.4192 - mse: 48227.5273\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 48006.5975 - mae: 129.5829 - mse: 48006.5938\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 86us/step - loss: 47774.9844 - mae: 129.0945 - mse: 47774.9883\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 47555.2579 - mae: 128.8268 - mse: 47555.2617\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 81us/step - loss: 47346.6154 - mae: 128.8849 - mse: 47346.6094\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 47114.2027 - mae: 128.1017 - mse: 47114.2031\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 46886.8512 - mae: 127.6867 - mse: 46886.8516\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 98us/step - loss: 46674.5475 - mae: 127.8214 - mse: 46674.5430\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 46456.9482 - mae: 127.3385 - mse: 46456.9492\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 92us/step - loss: 46283.6575 - mae: 128.1416 - mse: 46283.6523\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 46006.7785 - mae: 127.4631 - mse: 46006.7852\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 45838.6146 - mae: 128.0042 - mse: 45838.6172\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 45520.6948 - mae: 127.1457 - mse: 45520.6914\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 109us/step - loss: 45294.0059 - mae: 126.1099 - mse: 45294.0117\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 102us/step - loss: 45062.8224 - mae: 126.0192 - mse: 45062.8242\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 92us/step - loss: 44884.7356 - mae: 126.8592 - mse: 44884.7383\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 87us/step - loss: 44571.4048 - mae: 126.3523 - mse: 44571.4023\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 114us/step - loss: 44291.3494 - mae: 125.2505 - mse: 44291.3477\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 44016.5123 - mae: 125.0322 - mse: 44016.5117\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 43770.6522 - mae: 125.2141 - mse: 43770.6484\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 43494.0576 - mae: 124.7622 - mse: 43494.0586\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 43204.9149 - mae: 124.5033 - mse: 43204.9180\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 42922.2232 - mae: 124.4015 - mse: 42922.2227\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 42649.0818 - mae: 124.3342 - mse: 42649.0781\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 42309.5786 - mae: 123.2556 - mse: 42309.5781\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 110us/step - loss: 42059.4553 - mae: 123.7081 - mse: 42059.4570\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 41690.5991 - mae: 123.0953 - mse: 41690.5977\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 41390.3835 - mae: 122.2788 - mse: 41390.3867\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 41041.2894 - mae: 122.6194 - mse: 41041.2930\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 40735.9254 - mae: 121.7454 - mse: 40735.9219\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 40433.7647 - mae: 122.1017 - mse: 40433.7656\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 40001.6476 - mae: 121.4105 - mse: 40001.6484\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 131us/step - loss: 39664.8253 - mae: 120.8693 - mse: 39664.8281\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 39288.8851 - mae: 119.9813 - mse: 39288.8867\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 38892.1182 - mae: 119.5946 - mse: 38892.1172\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 84us/step - loss: 38528.8338 - mae: 119.7470 - mse: 38528.8359\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 38141.0337 - mae: 118.2686 - mse: 38141.0352\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 86us/step - loss: 37736.0008 - mae: 117.9565 - mse: 37736.0000\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 37353.4959 - mae: 117.9019 - mse: 37353.4961\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 126us/step - loss: 36891.6245 - mae: 117.3630 - mse: 36891.6250\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 127us/step - loss: 36463.5591 - mae: 116.4760 - mse: 36463.5586\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 36133.4694 - mae: 116.1140 - mse: 36133.4648\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 35616.3769 - mae: 114.8370 - mse: 35616.3750\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 35220.1266 - mae: 113.9971 - mse: 35220.1250\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 114us/step - loss: 34753.9392 - mae: 113.6372 - mse: 34753.9414\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 81us/step - loss: 34335.2275 - mae: 112.6608 - mse: 34335.2305\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 100us/step - loss: 33935.8214 - mae: 112.7186 - mse: 33935.8164\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 33459.0551 - mae: 112.3711 - mse: 33459.0586\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 33093.4103 - mae: 109.8189 - mse: 33093.4062\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 32562.5087 - mae: 108.8982 - mse: 32562.5098\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 32270.6341 - mae: 110.1802 - mse: 32270.6328\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 31693.0886 - mae: 109.4750 - mse: 31693.0859\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 31280.2637 - mae: 107.0771 - mse: 31280.2676\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 30846.9891 - mae: 106.3667 - mse: 30846.9902\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 75us/step - loss: 30426.2100 - mae: 106.0176 - mse: 30426.2129\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 30036.3095 - mae: 105.8583 - mse: 30036.3105\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 29614.2659 - mae: 104.8455 - mse: 29614.2676\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 81us/step - loss: 29266.9827 - mae: 104.3866 - mse: 29266.9824\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 104us/step - loss: 28851.9589 - mae: 103.3048 - mse: 28851.9609\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 95us/step - loss: 28470.4930 - mae: 102.3705 - mse: 28470.4941\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 87us/step - loss: 28116.9327 - mae: 101.8905 - mse: 28116.9336\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 27807.3911 - mae: 101.5743 - mse: 27807.3906\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 131us/step - loss: 27431.5681 - mae: 100.5598 - mse: 27431.5664\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 27181.6217 - mae: 100.7296 - mse: 27181.6230\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 26896.0800 - mae: 99.8777 - mse: 26896.0801\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 78us/step - loss: 26585.8273 - mae: 99.8089 - mse: 26585.8262\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 26315.1183 - mae: 99.2438 - mse: 26315.1191\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 26074.0779 - mae: 99.0079 - mse: 26074.0762\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 25792.0340 - mae: 98.4527 - mse: 25792.0332\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 92us/step - loss: 25569.1381 - mae: 97.9640 - mse: 25569.1387\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 25358.1836 - mae: 97.3354 - mse: 25358.1797\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 25126.3295 - mae: 97.4737 - mse: 25126.3301\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 89us/step - loss: 24950.5981 - mae: 97.4457 - mse: 24950.5957\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 24761.6895 - mae: 97.3636 - mse: 24761.6875\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 24591.0185 - mae: 96.2408 - mse: 24591.0176\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 24412.3315 - mae: 96.1310 - mse: 24412.3340\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 24214.3820 - mae: 96.0876 - mse: 24214.3809\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 24134.1812 - mae: 96.0795 - mse: 24134.1836\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 23907.9187 - mae: 95.1906 - mse: 23907.9199\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 23780.9031 - mae: 94.8273 - mse: 23780.9043\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 75us/step - loss: 23635.1897 - mae: 94.9152 - mse: 23635.1914\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 83525.4167 - mae: 203.1087 - mse: 83525.4141\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 83448.7408 - mae: 202.9219 - mse: 83448.7422\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 89us/step - loss: 83332.2885 - mae: 202.6349 - mse: 83332.2891\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 83166.6508 - mae: 202.2181 - mse: 83166.6562\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 82923.3391 - mae: 201.6104 - mse: 82923.3281\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 82552.7328 - mae: 200.6882 - mse: 82552.7266\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 138us/step - loss: 81957.3596 - mae: 199.2587 - mse: 81957.3516\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 80990.7190 - mae: 196.9447 - mse: 80990.7188\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 112us/step - loss: 79528.4057 - mae: 193.3548 - mse: 79528.3906\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 77469.9935 - mae: 188.0924 - mse: 77470.0000\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 74529.9367 - mae: 180.9407 - mse: 74529.9453\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 70928.4499 - mae: 171.1432 - mse: 70928.4453\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 100us/step - loss: 66442.2210 - mae: 159.6524 - mse: 66442.2188\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 61397.5566 - mae: 147.6954 - mse: 61397.5547\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 56228.3396 - mae: 135.7501 - mse: 56228.3398\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 51429.5025 - mae: 125.2337 - mse: 51429.5078\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 47923.9771 - mae: 119.9228 - mse: 47923.9805\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 45381.9900 - mae: 120.0506 - mse: 45381.9922\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 43997.3493 - mae: 122.2817 - mse: 43997.3477\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 43429.1324 - mae: 124.8212 - mse: 43429.1367\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 113us/step - loss: 43178.3374 - mae: 126.7758 - mse: 43178.3359\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 92us/step - loss: 42985.1589 - mae: 127.7944 - mse: 42985.1602\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 42792.7460 - mae: 127.9566 - mse: 42792.7422\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 42594.3255 - mae: 127.4864 - mse: 42594.3281\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 42424.1396 - mae: 127.0917 - mse: 42424.1445\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 42248.7410 - mae: 127.1623 - mse: 42248.7383\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 42046.1508 - mae: 126.6264 - mse: 42046.1523\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 41882.1247 - mae: 125.8883 - mse: 41882.1250\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 41703.7594 - mae: 126.1494 - mse: 41703.7617\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 76us/step - loss: 41526.9815 - mae: 126.5200 - mse: 41526.9844\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 41343.9667 - mae: 125.9616 - mse: 41343.9648\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 75us/step - loss: 41162.4170 - mae: 125.6334 - mse: 41162.4219\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 76us/step - loss: 40973.8609 - mae: 125.4777 - mse: 40973.8672\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 123us/step - loss: 40787.2705 - mae: 125.1985 - mse: 40787.2734\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 126us/step - loss: 40627.3074 - mae: 125.3879 - mse: 40627.3086\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 40429.2524 - mae: 124.8075 - mse: 40429.2617\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 40234.7916 - mae: 124.4249 - mse: 40234.7930\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 78us/step - loss: 40030.6103 - mae: 124.0583 - mse: 40030.6055\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 89us/step - loss: 39813.7989 - mae: 124.2655 - mse: 39813.8008\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 91us/step - loss: 39604.9883 - mae: 124.0735 - mse: 39604.9883\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 101us/step - loss: 39386.2345 - mae: 123.2837 - mse: 39386.2344\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 39127.9337 - mae: 123.0415 - mse: 39127.9336\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 38869.1266 - mae: 122.9953 - mse: 38869.1250\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 38629.2523 - mae: 122.6691 - mse: 38629.2539\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 38364.9555 - mae: 122.6951 - mse: 38364.9570\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 81us/step - loss: 38084.3418 - mae: 122.0002 - mse: 38084.3398\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 117us/step - loss: 37808.1780 - mae: 121.7402 - mse: 37808.1719\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 37524.2278 - mae: 121.4125 - mse: 37524.2266\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 56us/step - loss: 37201.9219 - mae: 120.7758 - mse: 37201.9219\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 83us/step - loss: 36904.4173 - mae: 120.1713 - mse: 36904.4219\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 81us/step - loss: 36597.3225 - mae: 119.6222 - mse: 36597.3242\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 36285.2041 - mae: 119.2120 - mse: 36285.2070\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 127us/step - loss: 35964.1743 - mae: 118.1356 - mse: 35964.1719\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 116us/step - loss: 35646.1816 - mae: 118.4178 - mse: 35646.1836\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 35287.2680 - mae: 117.6180 - mse: 35287.2695\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 34957.2916 - mae: 116.9158 - mse: 34957.2930\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 137us/step - loss: 34633.8309 - mae: 116.4264 - mse: 34633.8281\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 96us/step - loss: 34265.8370 - mae: 115.7934 - mse: 34265.8359\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 128us/step - loss: 33945.1403 - mae: 116.1066 - mse: 33945.1445\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 100us/step - loss: 33567.2387 - mae: 114.8454 - mse: 33567.2383\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 80us/step - loss: 33226.7345 - mae: 113.3776 - mse: 33226.7344\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 32889.0217 - mae: 113.6954 - mse: 32889.0195\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 32501.9857 - mae: 113.6269 - mse: 32501.9863\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 82us/step - loss: 32093.9110 - mae: 112.2889 - mse: 32093.9141\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 80us/step - loss: 31729.0274 - mae: 111.1555 - mse: 31729.0234\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 31346.4577 - mae: 110.7097 - mse: 31346.4570\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 80us/step - loss: 30989.2750 - mae: 110.2937 - mse: 30989.2734\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 108us/step - loss: 30591.4564 - mae: 109.7550 - mse: 30591.4570\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 30205.1090 - mae: 109.2184 - mse: 30205.1094\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 121us/step - loss: 29884.3911 - mae: 107.0861 - mse: 29884.3906\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 103us/step - loss: 29470.2366 - mae: 106.3554 - mse: 29470.2363\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 112us/step - loss: 29101.9363 - mae: 106.9313 - mse: 29101.9336\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 28725.5866 - mae: 106.2684 - mse: 28725.5859\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 28370.2200 - mae: 105.4698 - mse: 28370.2207\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 92us/step - loss: 28007.6306 - mae: 104.5158 - mse: 28007.6309\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 111us/step - loss: 27692.5713 - mae: 103.6937 - mse: 27692.5703\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 118us/step - loss: 27301.9790 - mae: 103.0235 - mse: 27301.9805\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 126us/step - loss: 27000.9922 - mae: 101.7371 - mse: 27000.9922\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 26620.6691 - mae: 101.4243 - mse: 26620.6719\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 26320.6533 - mae: 100.9487 - mse: 26320.6543\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 86us/step - loss: 26044.4511 - mae: 100.6432 - mse: 26044.4512\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 120us/step - loss: 25700.8382 - mae: 100.2650 - mse: 25700.8359\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 93us/step - loss: 25435.0692 - mae: 99.6245 - mse: 25435.0684\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 25104.8137 - mae: 98.6897 - mse: 25104.8125\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 125us/step - loss: 24899.2579 - mae: 97.2239 - mse: 24899.2598\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 106us/step - loss: 24609.7913 - mae: 97.4668 - mse: 24609.7910\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 24345.3965 - mae: 97.5596 - mse: 24345.3945\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 100us/step - loss: 24116.6271 - mae: 96.8662 - mse: 24116.6250\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 86us/step - loss: 23889.4928 - mae: 95.9856 - mse: 23889.4941\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 23663.3690 - mae: 95.7212 - mse: 23663.3711\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 81us/step - loss: 23497.6593 - mae: 95.6551 - mse: 23497.6602\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 88us/step - loss: 23293.2156 - mae: 95.3465 - mse: 23293.2148\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 115us/step - loss: 23088.2326 - mae: 95.1046 - mse: 23088.2344\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 22934.5768 - mae: 94.5509 - mse: 22934.5762\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 105us/step - loss: 22771.8992 - mae: 94.5718 - mse: 22771.9004\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 86us/step - loss: 22621.1048 - mae: 94.4061 - mse: 22621.1055\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 90us/step - loss: 22493.3605 - mae: 93.7426 - mse: 22493.3594\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 86us/step - loss: 22340.4848 - mae: 93.6532 - mse: 22340.4863\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 64us/step - loss: 22231.6158 - mae: 93.1440 - mse: 22231.6152\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 98us/step - loss: 22048.8799 - mae: 92.9671 - mse: 22048.8789\n",
      "Epoch 1/100\n",
      "750/750 [==============================] - 1s 1ms/step - loss: 84633.0117 - mae: 201.5694 - mse: 84633.0078\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 0s 79us/step - loss: 84435.5807 - mae: 201.0741 - mse: 84435.5859\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 0s 126us/step - loss: 84264.4752 - mae: 200.6333 - mse: 84264.4766\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 0s 101us/step - loss: 84027.9951 - mae: 200.0372 - mse: 84027.9922\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 0s 106us/step - loss: 83618.5291 - mae: 198.9932 - mse: 83618.5312\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 0s 105us/step - loss: 82885.3839 - mae: 197.1017 - mse: 82885.3828\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 0s 102us/step - loss: 81612.9920 - mae: 193.8628 - mse: 81612.9922\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 0s 96us/step - loss: 79597.6960 - mae: 188.8144 - mse: 79597.7031\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 0s 96us/step - loss: 76670.4759 - mae: 180.9336 - mse: 76670.4688\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 0s 141us/step - loss: 72484.8018 - mae: 170.2721 - mse: 72484.7969\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 0s 104us/step - loss: 67289.9388 - mae: 156.8352 - mse: 67289.9375\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 0s 117us/step - loss: 61330.5944 - mae: 142.3421 - mse: 61330.5977\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 0s 108us/step - loss: 55413.2317 - mae: 129.4060 - mse: 55413.2305\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 0s 96us/step - loss: 50419.0616 - mae: 120.8142 - mse: 50419.0664\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 0s 97us/step - loss: 47467.7943 - mae: 120.7246 - mse: 47467.7930\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 0s 100us/step - loss: 45943.9352 - mae: 123.3996 - mse: 45943.9375\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 0s 110us/step - loss: 45529.0064 - mae: 126.6606 - mse: 45529.0039\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 0s 110us/step - loss: 45261.0494 - mae: 127.8615 - mse: 45261.0508\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 0s 88us/step - loss: 45046.5249 - mae: 127.8543 - mse: 45046.5234\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 0s 89us/step - loss: 44869.1058 - mae: 127.8386 - mse: 44869.1133\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 0s 101us/step - loss: 44675.4659 - mae: 127.7100 - mse: 44675.4648\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 0s 100us/step - loss: 44512.9286 - mae: 127.1233 - mse: 44512.9258\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 0s 88us/step - loss: 44318.5165 - mae: 127.4891 - mse: 44318.5234\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 0s 113us/step - loss: 44134.8351 - mae: 127.2646 - mse: 44134.8359\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 0s 92us/step - loss: 43954.9582 - mae: 126.6651 - mse: 43954.9531\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 0s 98us/step - loss: 43777.0578 - mae: 126.6148 - mse: 43777.0586\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 0s 115us/step - loss: 43588.4312 - mae: 126.7464 - mse: 43588.4258\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 0s 104us/step - loss: 43434.3654 - mae: 127.0569 - mse: 43434.3672\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 0s 126us/step - loss: 43223.3911 - mae: 125.7950 - mse: 43223.3906\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 0s 113us/step - loss: 43064.2582 - mae: 126.1902 - mse: 43064.2578\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 0s 118us/step - loss: 42847.2158 - mae: 125.3073 - mse: 42847.2148\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 0s 120us/step - loss: 42609.6134 - mae: 124.5802 - mse: 42609.6133\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 0s 116us/step - loss: 42322.6019 - mae: 124.3417 - mse: 42322.6016\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 130us/step - loss: 42064.9995 - mae: 124.0557 - mse: 42065.0000\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 0s 128us/step - loss: 41823.5826 - mae: 124.2617 - mse: 41823.5820\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 0s 104us/step - loss: 41549.0570 - mae: 123.3421 - mse: 41549.0508\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 0s 101us/step - loss: 41278.7684 - mae: 123.7529 - mse: 41278.7695\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 0s 93us/step - loss: 40951.2201 - mae: 122.5716 - mse: 40951.2227\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 0s 100us/step - loss: 40646.5522 - mae: 121.6004 - mse: 40646.5508\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 0s 117us/step - loss: 40322.0241 - mae: 121.5864 - mse: 40322.0273\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 0s 108us/step - loss: 39995.2533 - mae: 121.3368 - mse: 39995.2539\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 0s 117us/step - loss: 39701.8140 - mae: 120.1534 - mse: 39701.8125\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 0s 114us/step - loss: 39391.8887 - mae: 121.1965 - mse: 39391.8867\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 0s 122us/step - loss: 39027.9282 - mae: 121.2073 - mse: 39027.9297\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 0s 104us/step - loss: 38621.1921 - mae: 119.6630 - mse: 38621.1875\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 0s 97us/step - loss: 38256.5343 - mae: 118.1844 - mse: 38256.5391\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 0s 93us/step - loss: 37865.2152 - mae: 117.9567 - mse: 37865.2148\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 0s 94us/step - loss: 37480.2254 - mae: 117.9381 - mse: 37480.2305\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 0s 90us/step - loss: 37085.0586 - mae: 116.4873 - mse: 37085.0625\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 0s 80us/step - loss: 36701.1359 - mae: 116.7554 - mse: 36701.1367\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 0s 104us/step - loss: 36230.9241 - mae: 115.4729 - mse: 36230.9258\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 0s 109us/step - loss: 35841.0987 - mae: 114.8306 - mse: 35841.0977\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 0s 105us/step - loss: 35383.9199 - mae: 114.4019 - mse: 35383.9180\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 0s 125us/step - loss: 34926.3019 - mae: 113.0311 - mse: 34926.2969\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 0s 88us/step - loss: 34454.2141 - mae: 112.0478 - mse: 34454.2188\n",
      "Epoch 56/100\n",
      "750/750 [==============================] - 0s 97us/step - loss: 34060.8643 - mae: 112.5349 - mse: 34060.8672\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 0s 108us/step - loss: 33539.7512 - mae: 110.7361 - mse: 33539.7500\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 0s 133us/step - loss: 33049.0405 - mae: 109.6552 - mse: 33049.0391\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 0s 112us/step - loss: 32588.2949 - mae: 109.6783 - mse: 32588.2969\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 0s 113us/step - loss: 32075.2513 - mae: 108.3444 - mse: 32075.2539\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 0s 109us/step - loss: 31626.1015 - mae: 107.8622 - mse: 31626.1016\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 0s 110us/step - loss: 31155.1696 - mae: 107.1192 - mse: 31155.1699\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 0s 86us/step - loss: 30681.3911 - mae: 106.6020 - mse: 30681.3887\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 0s 93us/step - loss: 30204.6134 - mae: 105.4089 - mse: 30204.6152\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 0s 119us/step - loss: 29759.9039 - mae: 103.7287 - mse: 29759.9062\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 0s 107us/step - loss: 29416.2375 - mae: 104.7312 - mse: 29416.2344\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 0s 69us/step - loss: 28868.4255 - mae: 103.2913 - mse: 28868.4238\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 0s 100us/step - loss: 28564.3845 - mae: 103.0802 - mse: 28564.3848\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 0s 85us/step - loss: 28139.6261 - mae: 101.0219 - mse: 28139.6270\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 0s 97us/step - loss: 27736.7238 - mae: 101.5096 - mse: 27736.7246\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 0s 96us/step - loss: 27415.9178 - mae: 101.3210 - mse: 27415.9180\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 0s 101us/step - loss: 27104.1069 - mae: 99.3480 - mse: 27104.1074\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 0s 130us/step - loss: 26769.5306 - mae: 100.2073 - mse: 26769.5312\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 0s 93us/step - loss: 26528.5661 - mae: 99.6824 - mse: 26528.5625\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 0s 75us/step - loss: 26208.3447 - mae: 98.9854 - mse: 26208.3438\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 0s 117us/step - loss: 25985.4673 - mae: 99.0827 - mse: 25985.4648\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 0s 81us/step - loss: 25770.4692 - mae: 97.7587 - mse: 25770.4688\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 0s 92us/step - loss: 25597.6869 - mae: 98.7102 - mse: 25597.6836\n",
      "Epoch 79/100\n",
      "750/750 [==============================] - 0s 102us/step - loss: 25366.5370 - mae: 97.7136 - mse: 25366.5391\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 0s 82us/step - loss: 25218.6132 - mae: 98.1889 - mse: 25218.6133\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 0s 80us/step - loss: 25018.9625 - mae: 97.5346 - mse: 25018.9629\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 0s 102us/step - loss: 24879.4145 - mae: 96.8725 - mse: 24879.4141\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 0s 88us/step - loss: 24755.6465 - mae: 96.8303 - mse: 24755.6445\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 0s 101us/step - loss: 24636.1277 - mae: 96.8523 - mse: 24636.1309\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 0s 110us/step - loss: 24531.8093 - mae: 96.5030 - mse: 24531.8105\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 0s 89us/step - loss: 24393.6241 - mae: 96.4201 - mse: 24393.6230\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 0s 108us/step - loss: 24392.6739 - mae: 96.9098 - mse: 24392.6719\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 0s 122us/step - loss: 24308.0341 - mae: 95.8970 - mse: 24308.0352\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 0s 81us/step - loss: 24136.4042 - mae: 96.1487 - mse: 24136.4062\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 0s 70us/step - loss: 24097.2410 - mae: 96.7814 - mse: 24097.2383\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 0s 83us/step - loss: 23991.5830 - mae: 95.9713 - mse: 23991.5820\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 0s 86us/step - loss: 23951.8807 - mae: 95.4871 - mse: 23951.8809\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 0s 100us/step - loss: 24041.1410 - mae: 97.3897 - mse: 24041.1406\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 0s 98us/step - loss: 23819.0670 - mae: 95.5352 - mse: 23819.0664\n",
      "Epoch 95/100\n",
      "750/750 [==============================] - 0s 97us/step - loss: 23801.3247 - mae: 95.2916 - mse: 23801.3262\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 0s 100us/step - loss: 23670.8283 - mae: 95.6270 - mse: 23670.8262\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 0s 91us/step - loss: 23627.5849 - mae: 95.4754 - mse: 23627.5859\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 0s 118us/step - loss: 23590.0161 - mae: 94.8641 - mse: 23590.0137\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 0s 130us/step - loss: 23501.7035 - mae: 95.0760 - mse: 23501.7012\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 0s 107us/step - loss: 23452.6696 - mae: 95.0961 - mse: 23452.6660\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=11, activation = 'relu', input_dim=22))\n",
    "    model.add(Dense(units=11, activation = 'relu'))\n",
    "    model.add(Dense(units=11, activation = 'relu'))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae','mse'])\n",
    "    return model\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "NN_Regressor = KerasRegressor(build_fn=build_model, batch_size=40,epochs=100)    \n",
    "\n",
    "scores = cross_val_score(NN_Regressor, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "NN = NN_Regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the scores for each model run\n",
      "[-22029.25380159 -18509.39726945 -42781.02495654 -25714.56728207\n",
      " -32828.6549837 ]\n",
      " \n",
      "Mean and variance: 28372.58 (+/- 17252.13)\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 110.56946370689393\n",
      "Root Mean Squared Error: 196.82085029686246\n",
      "Time Taken =  134.640625\n"
     ]
    }
   ],
   "source": [
    "print(\"Below are the scores for each model run\")\n",
    "print(scores)\n",
    "print(\" \")\n",
    "print(\"Mean and variance: %0.2f (+/- %0.2f)\" % (abs(scores.mean()), scores.std() * 2))\n",
    "\n",
    "y_pred= NN_Regressor.predict(X_test_holdout)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_purchase = df[df['Purchase'] == 1]\n",
    "\n",
    "# Selecting required columns\n",
    "X_df = df_purchase.iloc[:,1:23]\n",
    "y_df = df_purchase.iloc[:,24:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating the Train and Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test_holdout, y_train, y_test_holdout = train_test_split(X_df, y_df, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train_scaled)\n",
    "\n",
    "x_test_scaled = scaler.fit_transform(X_test_holdout)\n",
    "X_test_holdout = pd.DataFrame(x_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the mean squared errors for each model run\n",
      "[-19812.07066791 -12602.97017752 -34733.42026459 -25786.96103861\n",
      " -28542.89446855]\n",
      " \n",
      "Mean score: 24295.66 \n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 110.57948435806942\n",
      "Root Mean Squared Error: 191.2238772941838\n",
      "r2: 0.41548093167861555\n",
      " \n",
      "Time Taken =  0.140625\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "# create linear regression object \n",
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "# cross validation \n",
    "scores = cross_val_score(lr, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "print(\"Below are the mean squared errors for each model run\")\n",
    "print(scores)\n",
    "print(\" \")\n",
    "print(\"Mean score: %0.2f \" % (abs(scores.mean())))\n",
    "\n",
    "# Model fit on training data and predicting on testing data\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test_holdout)\n",
    "\n",
    "# Model performance on testing data\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "# print('Explained Variance:',metrics.explained_variance_score(y_test_holdout, y_pred))\n",
    "print('r2:',metrics.r2_score(y_test_holdout, y_pred))\n",
    "\n",
    "print(\" \")\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score achieved across all parameters:  23951.402393936794\n",
      " \n",
      "Best parameters\n",
      "{'alpha': 0.5000000000000001}\n",
      " \n",
      "Best estimator\n",
      "Lasso(alpha=0.5000000000000001, copy_X=True, fit_intercept=True,\n",
      "   max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "   random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 109.7550939894061\n",
      "Root Mean Squared Error: 190.59275614275074\n",
      "r2: 0.419332893937013\n",
      "Time Taken =  0.9375\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "lasso = linear_model.Lasso()\n",
    "\n",
    "#Hyper Parameter tuning\n",
    "param_set ={'alpha': list(np.arange(0.1,2,0.2))}\n",
    "grid_lasso = GridSearchCV(lasso, param_grid = param_set, cv=5, scoring='neg_mean_squared_error', verbose = 0)\n",
    "grid_lasso.fit(X_train,y_train)\n",
    "\n",
    "# examine the best model\n",
    "print(\"Best score achieved across all parameters: \", abs(grid_lasso.best_score_))\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(\" \")\n",
    "print(\"Best parameters\")\n",
    "print (grid_lasso.best_params_)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Best estimator\")\n",
    "print (grid_lasso.best_estimator_)\n",
    "\n",
    "# predicting on test data\n",
    "lasso = grid_lasso.best_estimator_\n",
    "lasso.fit(X_train,y_train)\n",
    "y_pred = lasso.predict(X_test_holdout)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "print('r2:',metrics.r2_score(y_test_holdout, y_pred))\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score achieved across all parameters:  24249.094866401145\n",
      " \n",
      "Best parameters\n",
      "{'alpha': 0.30000000000000004}\n",
      " \n",
      "Best estimator\n",
      "Ridge(alpha=0.30000000000000004, copy_X=True, fit_intercept=True,\n",
      "   max_iter=None, normalize=False, random_state=None, solver='auto',\n",
      "   tol=0.001)\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 110.13709948664578\n",
      "Root Mean Squared Error: 191.4901826660552\n",
      "r2: 0.4138517527354626\n",
      "Time Taken =  1.390625\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "ridge = linear_model.Ridge()\n",
    "\n",
    "#Hyper Parameter tuning\n",
    "param_set ={'alpha': list(np.arange(0.1,2,0.2))}\n",
    "grid_ridge = GridSearchCV(ridge, param_grid = param_set, cv=5, scoring='neg_mean_squared_error', verbose = 0)\n",
    "grid_ridge.fit(X_train,y_train)\n",
    "\n",
    "# examine the best model\n",
    "print(\"Best score achieved across all parameters: \", abs(grid_ridge.best_score_))\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(\" \")\n",
    "print(\"Best parameters\")\n",
    "print (grid_ridge.best_params_)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Best estimator\")\n",
    "print (grid_ridge.best_estimator_)\n",
    "\n",
    "# predicting on test data\n",
    "ridge = grid_ridge.best_estimator_\n",
    "ridge.fit(X_train,y_train)\n",
    "y_pred = ridge.predict(X_test_holdout)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "print('r2:',metrics.r2_score(y_test_holdout, y_pred))\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score achieved across all parameters:  37913.72046451443\n",
      " \n",
      "Best parameters\n",
      "{'n_neighbors': 25, 'weights': 'distance'}\n",
      " \n",
      "Best estimator\n",
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=None, n_neighbors=25, p=2,\n",
      "          weights='distance')\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 123.70465389883117\n",
      "Root Mean Squared Error: 240.02773522513584\n",
      "r2: 0.07904735705996002\n",
      "Time Taken =  6.9375\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "knn = neighbors.KNeighborsRegressor()\n",
    "\n",
    "#Hyper Parameter tuning\n",
    "param_set ={'n_neighbors': list(range(1,30)), 'weights': [\"uniform\", \"distance\"]}\n",
    "grid_knn = GridSearchCV(knn, param_grid = param_set, cv=5, scoring='neg_mean_squared_error', verbose = 0)\n",
    "grid_knn.fit(X_train,y_train)\n",
    "\n",
    "# examine the best model\n",
    "print(\"Best score achieved across all parameters: \", abs(grid_knn.best_score_))\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(\" \")\n",
    "print(\"Best parameters\")\n",
    "print (grid_knn.best_params_)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Best estimator\")\n",
    "print (grid_knn.best_estimator_)\n",
    "\n",
    "# predicting on test data\n",
    "knn = grid_knn.best_estimator_\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test_holdout)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "print('r2:',metrics.r2_score(y_test_holdout, y_pred))\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score achieved across all parameters:  22323.240263277614\n",
      " \n",
      "Best parameters\n",
      "{'max_depth': 3, 'min_samples_split': 8}\n",
      " \n",
      "Best estimator\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=3, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=8, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best')\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 111.67511949161054\n",
      "Root Mean Squared Error: 204.45116269214938\n",
      "r2: 0.33181978305652526\n",
      "Time Taken =  15.515625\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "DTree = tree.DecisionTreeRegressor()\n",
    "\n",
    "#Hyper parameter tuning\n",
    "param_set ={'max_depth': range(1,20), 'min_samples_split' : range(2,30)}\n",
    "grid_DTree = GridSearchCV(DTree, param_grid = param_set, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_DTree.fit(X_train,y_train)\n",
    "\n",
    "# examine the best model\n",
    "print(\"Best score achieved across all parameters: \", abs(grid_DTree.best_score_))\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(\" \")\n",
    "print(\"Best parameters\")\n",
    "print (grid_DTree.best_params_)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Best estimator\")\n",
    "print (grid_DTree.best_estimator_)\n",
    "\n",
    "# predicting on test data\n",
    "DTree = grid_DTree.best_estimator_\n",
    "DTree.fit(X_train,y_train)\n",
    "y_pred = DTree.predict(X_test_holdout)\n",
    "\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "print('r2:',metrics.r2_score(y_test_holdout, y_pred))\n",
    "\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score achieved across all parameters:  27815.104847457817\n",
      " \n",
      "Best parameters\n",
      "{'C': 100, 'epsilon': 0.05, 'kernel': 'linear'}\n",
      " \n",
      "Best estimator\n",
      "SVR(C=100, cache_size=200, coef0=0.0, degree=3, epsilon=0.05,\n",
      "  gamma='auto_deprecated', kernel='linear', max_iter=-1, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 108.22570555700518\n",
      "Root Mean Squared Error: 210.49456562157204\n",
      "r2: 0.32204375565882715\n",
      "Time Taken =  12.484375\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "SVR = svm.SVR()\n",
    "# Hyper parameter tuning using GridSearch\n",
    "param_set = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1,2,10,100,1000], 'epsilon':[0.05,0.1,0.2,0.3,0.5]},\n",
    "                    {'kernel': ['linear'], 'C': [1,2,5,10,100], 'epsilon':[0.05,0.1,0.2,0.3,0.5]}]\n",
    "grid_SVR = GridSearchCV(SVR, param_grid = param_set, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_SVR.fit(X_train,y_train)\n",
    "\n",
    "# examine the best model\n",
    "print(\"Best score achieved across all parameters: \", abs(grid_SVR.best_score_))\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(\" \")\n",
    "print(\"Best parameters\")\n",
    "print (grid_SVR.best_params_)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Best estimator\")\n",
    "print (grid_SVR.best_estimator_)\n",
    "\n",
    "# predicting on test data\n",
    "SVR = grid_SVR.best_estimator_\n",
    "SVR.fit(X_train,y_train)\n",
    "y_pred = SVR.predict(X_test_holdout)\n",
    "\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "print('r2:',metrics.explained_variance_score(y_test_holdout, y_pred))\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble : Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score achieved across all parameters:  22323.240263277577\n",
      " \n",
      "Best parameters\n",
      "{'bootstrap': False, 'max_depth': 3, 'max_features': 'auto', 'min_samples_split': 5, 'n_estimators': 500, 'n_jobs': -1}\n",
      " \n",
      "Best estimator\n",
      "RandomForestRegressor(bootstrap=False, criterion='mse', max_depth=3,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=5,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 111.6751194916104\n",
      "Root Mean Squared Error: 204.4511626921494\n",
      "r2: 0.33913672503684633\n",
      " \n",
      "Time Taken =  168.734375\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "RF = ensemble.RandomForestRegressor()\n",
    "\n",
    "# Hyper parameter tuning using GridSearch\n",
    "param_set ={'max_depth': [3,10,20],\n",
    "            'min_samples_split' :[4,5,10],\n",
    "            'n_estimators': [100,250,500],\n",
    "            'bootstrap':[True, False] ,\n",
    "            'max_features':['auto','sqrt'],\n",
    "            'n_jobs':[-1]\n",
    "           }\n",
    "grid_RF = GridSearchCV(RF, param_grid = param_set, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_RF.fit(X_train,y_train)\n",
    "\n",
    "# examine the best model\n",
    "print(\"Best score achieved across all parameters: \", abs(grid_RF.best_score_))\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(\" \")\n",
    "print(\"Best parameters\")\n",
    "print (grid_RF.best_params_)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Best estimator\")\n",
    "print (grid_RF.best_estimator_)\n",
    "\n",
    "# predicting on test data\n",
    "RF = grid_RF.best_estimator_\n",
    "RF.fit(X_train,y_train)\n",
    "y_pred = RF.predict(X_test_holdout)\n",
    "\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "print('r2:',metrics.explained_variance_score(y_test_holdout, y_pred))\n",
    "print(\" \")\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble : XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:15:01] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:01] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:01] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:01] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:01] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:02] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:02] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:02] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:02] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:02] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:02] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:02] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:02] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:02] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:02] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:03] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:03] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:03] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:03] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:03] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:03] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:03] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:03] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:04] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:04] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:04] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:04] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:04] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:04] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:04] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:04] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:04] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:04] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:04] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:04] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:04] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:04] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:05] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:05] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:05] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:05] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:05] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:05] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:05] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:06] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:06] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:06] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:06] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:06] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:06] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:15:06] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Best score achieved across all parameters:  26294.674411178054\n",
      " \n",
      "Best parameters\n",
      "{'colsample_bytree': 0.927269921736378, 'gamma': 1.3479999463585524, 'learning_rate': 0.09853009882881976, 'max_depth': 33, 'n_estimators': 19, 'n_jobs': -1, 'subsample': 0.7826237202008084}\n",
      " \n",
      "Best estimator\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bynode=1, colsample_bytree=0.927269921736378,\n",
      "       gamma=1.3479999463585524, importance_type='gain',\n",
      "       learning_rate=0.09853009882881976, max_delta_step=0, max_depth=33,\n",
      "       min_child_weight=1, missing=None, n_estimators=19, n_jobs=-1,\n",
      "       nthread=None, nthreads=-1, objective='reg:linear', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=None, subsample=0.7826237202008084, verbosity=1)\n",
      "[16:15:06] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken =  28.765625\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "XGB = xgboost.XGBRegressor(nthreads=-1)\n",
    "\n",
    "a = stat.beta(10, 1)\n",
    "\n",
    "# Hyper parameter tuning using GridSearch\n",
    "param_set ={\"n_estimators\": stat.randint(3, 40),\n",
    "            \"max_depth\": stat.randint(3, 40),\n",
    "            \"learning_rate\": stat.uniform(0.05, 0.4),\n",
    "            \"colsample_bytree\": a,\n",
    "            \"subsample\": a,\n",
    "            \"gamma\": stat.uniform(0, 10),\n",
    "            'n_jobs':[-1]\n",
    "           }\n",
    "\n",
    "grid_XGB = RandomizedSearchCV(XGB, param_set, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_XGB.fit(X_train,y_train)\n",
    "\n",
    "# examine the best model\n",
    "print(\"Best score achieved across all parameters: \", abs(grid_XGB.best_score_))\n",
    "\n",
    "# Dictionary containing the parameters used to generate that score\n",
    "print(\" \")\n",
    "print(\"Best parameters\")\n",
    "print (grid_XGB.best_params_)\n",
    "\n",
    "print(\" \")\n",
    "print(\"Best estimator\")\n",
    "print (grid_XGB.best_estimator_)\n",
    "\n",
    "# predicting on test data\n",
    "XGB = grid_XGB.best_estimator_\n",
    "XGB.fit(X_train,y_train)\n",
    "y_pred = XGB.predict(X_test_holdout)\n",
    "\n",
    "# print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "# print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "# print('r2:',metrics.explained_variance_score(y_test_holdout, y_pred))\n",
    "# print(\" \")\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:15:18] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 106.66388892211916\n",
      "Root Mean Squared Error: 195.5159751248307\n",
      "r2: 0.4343583052403158\n"
     ]
    }
   ],
   "source": [
    "# predicting on test data\n",
    "XGB = grid_XGB.best_estimator_\n",
    "XGB.fit(X_train,y_train)\n",
    "y_pred = XGB.predict(X_test_holdout)\n",
    "\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "print('r2:',metrics.explained_variance_score(y_test_holdout, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shallow Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 352us/step - loss: 86312.7380 - mae: 204.8103 - mse: 86312.7422\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 27us/step - loss: 86165.4724 - mae: 204.4349 - mse: 86165.4766\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 86009.6742 - mae: 204.0499 - mse: 86009.6641\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 85837.3874 - mae: 203.6078 - mse: 85837.3828\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 85626.3576 - mae: 203.0801 - mse: 85626.3672\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 85367.0156 - mae: 202.4263 - mse: 85367.0234\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 85047.8618 - mae: 201.6194 - mse: 85047.8672\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 84658.6012 - mae: 200.6379 - mse: 84658.6016\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 84194.3585 - mae: 199.4784 - mse: 84194.3594\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 83672.3113 - mae: 198.1618 - mse: 83672.3047\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 83095.8526 - mae: 196.6865 - mse: 83095.8516\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 30us/step - loss: 82463.8938 - mae: 195.0886 - mse: 82463.8906\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 81791.8826 - mae: 193.3760 - mse: 81791.8828\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 81045.9902 - mae: 191.5777 - mse: 81045.9922\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 80277.8438 - mae: 189.6452 - mse: 80277.8438\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 79476.3612 - mae: 187.5373 - mse: 79476.3594\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 78616.1469 - mae: 185.3316 - mse: 78616.1562\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 77713.2768 - mae: 182.9938 - mse: 77713.2812\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 76807.5331 - mae: 180.5260 - mse: 76807.5312\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 75819.2527 - mae: 178.0483 - mse: 75819.2500\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 74855.3203 - mae: 175.4891 - mse: 74855.3203\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 73855.2108 - mae: 172.8771 - mse: 73855.2109\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 72813.6362 - mae: 170.2732 - mse: 72813.6406\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 71769.0458 - mae: 167.7169 - mse: 71769.0391\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 70734.4391 - mae: 165.0879 - mse: 70734.4297\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 69680.9208 - mae: 162.3978 - mse: 69680.9141\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 68568.0250 - mae: 159.8684 - mse: 68568.0234\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 67532.7253 - mae: 157.3928 - mse: 67532.7266\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 66470.4643 - mae: 154.8120 - mse: 66470.4609\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 65422.7105 - mae: 152.2766 - mse: 65422.7070\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 64372.2651 - mae: 149.8790 - mse: 64372.2617\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 63338.5553 - mae: 147.3913 - mse: 63338.5547\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 62329.2516 - mae: 145.0444 - mse: 62329.2539\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 61343.1923 - mae: 142.6328 - mse: 61343.1914\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 60355.8400 - mae: 140.4510 - mse: 60355.8398\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 59395.8100 - mae: 138.3653 - mse: 59395.8086\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 58482.8207 - mae: 136.3309 - mse: 58482.8203\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 57581.5801 - mae: 134.3598 - mse: 57581.5781\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 56733.2770 - mae: 132.4884 - mse: 56733.2812\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 55922.3480 - mae: 130.8613 - mse: 55922.3516\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 55105.4128 - mae: 129.2939 - mse: 55105.4141\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 54418.1172 - mae: 127.8130 - mse: 54418.1133\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 53721.3577 - mae: 126.5956 - mse: 53721.3555\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 53036.5209 - mae: 125.4753 - mse: 53036.5156\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 52424.1570 - mae: 124.5580 - mse: 52424.1602\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 51859.4398 - mae: 123.7648 - mse: 51859.4414\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 51303.6395 - mae: 123.1326 - mse: 51303.6406\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 50814.5596 - mae: 122.6339 - mse: 50814.5586\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 50332.5747 - mae: 122.2874 - mse: 50332.5781\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 49948.6477 - mae: 122.0869 - mse: 49948.6523\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 49510.7865 - mae: 121.8914 - mse: 49510.7852\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 49162.4349 - mae: 121.8941 - mse: 49162.4375\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 48840.3435 - mae: 121.9172 - mse: 48840.3516\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 48514.4139 - mae: 121.9987 - mse: 48514.4180\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 48244.1856 - mae: 122.2104 - mse: 48244.1875\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 47998.5799 - mae: 122.4165 - mse: 47998.5742\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 47755.9085 - mae: 122.6595 - mse: 47755.9102\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 47563.2641 - mae: 122.9535 - mse: 47563.2734\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 47347.7626 - mae: 123.2020 - mse: 47347.7617\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 47172.3975 - mae: 123.5450 - mse: 47172.3984\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 47014.3042 - mae: 123.8423 - mse: 47014.3008\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 46871.1942 - mae: 124.2629 - mse: 46871.1953\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 46720.4776 - mae: 124.5292 - mse: 46720.4766\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - ETA: 0s - loss: 83264.3281 - mae: 162.5570 - mse: 83264.328 - 0s 52us/step - loss: 46599.5477 - mae: 124.7466 - mse: 46599.5508\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 46494.0835 - mae: 125.0185 - mse: 46494.0820\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 46387.0389 - mae: 125.2708 - mse: 46387.0391\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 52us/step - loss: 46298.2104 - mae: 125.5671 - mse: 46298.2148\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 46191.1419 - mae: 125.7873 - mse: 46191.1406\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 46112.9514 - mae: 125.9605 - mse: 46112.9531\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 46044.9527 - mae: 126.1826 - mse: 46044.9492\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 45962.5404 - mae: 126.4732 - mse: 45962.5391\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 45895.0038 - mae: 126.6742 - mse: 45895.0039\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 45824.3249 - mae: 126.7887 - mse: 45824.3242\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 45763.4503 - mae: 126.9817 - mse: 45763.4492\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 45696.4320 - mae: 127.1689 - mse: 45696.4336\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 45637.5271 - mae: 127.2947 - mse: 45637.5273\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 45577.4534 - mae: 127.3833 - mse: 45577.4531\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 45521.3400 - mae: 127.5057 - mse: 45521.3398\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 45464.7779 - mae: 127.6048 - mse: 45464.7773\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 45408.8094 - mae: 127.5532 - mse: 45408.8086\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 45352.2361 - mae: 127.5307 - mse: 45352.2383\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 45301.6724 - mae: 127.6903 - mse: 45301.6758\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 45244.3210 - mae: 127.7830 - mse: 45244.3203\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 45190.5647 - mae: 127.8724 - mse: 45190.5664\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 45133.8980 - mae: 127.8681 - mse: 45133.8984\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 45083.3027 - mae: 127.7733 - mse: 45083.3047\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 45023.0592 - mae: 127.7473 - mse: 45023.0547\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 44969.3227 - mae: 127.7843 - mse: 44969.3281\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 44915.2884 - mae: 127.8249 - mse: 44915.2852\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 44856.4081 - mae: 127.7817 - mse: 44856.4062\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 44806.3240 - mae: 127.7619 - mse: 44806.3203\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 44748.4101 - mae: 127.7468 - mse: 44748.4102\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 44695.5335 - mae: 127.5965 - mse: 44695.5352\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 44641.9352 - mae: 127.5539 - mse: 44641.9375\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 44589.5359 - mae: 127.6866 - mse: 44589.5352\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 44521.4052 - mae: 127.5343 - mse: 44521.4062\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 44473.6709 - mae: 127.3759 - mse: 44473.6719\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 44414.5005 - mae: 127.3030 - mse: 44414.5078\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 44357.5644 - mae: 127.2850 - mse: 44357.5586\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 44300.9339 - mae: 127.1956 - mse: 44300.9297\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 350us/step - loss: 89044.2706 - mae: 205.5486 - mse: 89044.2734\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 88852.6237 - mae: 205.0685 - mse: 88852.6250\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 88649.0779 - mae: 204.5744 - mse: 88649.0859\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 88432.3138 - mae: 204.0336 - mse: 88432.3203\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 88187.7835 - mae: 203.4285 - mse: 88187.7891\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 87911.9263 - mae: 202.7263 - mse: 87911.9297\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 87582.1943 - mae: 201.9191 - mse: 87582.1953\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 87212.4854 - mae: 200.9870 - mse: 87212.4766\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 86787.4091 - mae: 199.9197 - mse: 86787.3984\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 86302.9596 - mae: 198.7338 - mse: 86302.9609\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 85766.0310 - mae: 197.4059 - mse: 85766.0312\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 85170.4219 - mae: 195.9530 - mse: 85170.4297\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 84517.4108 - mae: 194.3755 - mse: 84517.4141\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 83820.7846 - mae: 192.6336 - mse: 83820.7891\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 83084.1794 - mae: 190.7353 - mse: 83084.1797\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 82269.3736 - mae: 188.7764 - mse: 82269.3750\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 81468.0044 - mae: 186.6767 - mse: 81468.0078\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 80584.7314 - mae: 184.4700 - mse: 80584.7266\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 79716.8729 - mae: 182.1273 - mse: 79716.8750\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 78762.0659 - mae: 179.7313 - mse: 78762.0703\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 77817.5840 - mae: 177.2924 - mse: 77817.5859\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 76837.2318 - mae: 174.7079 - mse: 76837.2344\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 75817.7928 - mae: 172.1588 - mse: 75817.7969\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 74799.2040 - mae: 169.6063 - mse: 74799.2031\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 73774.2410 - mae: 167.0167 - mse: 73774.2422\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 72717.3520 - mae: 164.4335 - mse: 72717.3516\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 71669.2954 - mae: 161.8746 - mse: 71669.2969\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 70628.9818 - mae: 159.4065 - mse: 70628.9844\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 69611.2380 - mae: 156.9915 - mse: 69611.2422\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 68554.4010 - mae: 154.4426 - mse: 68554.3984\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 67559.9160 - mae: 152.0469 - mse: 67559.9219\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - ETA: 0s - loss: 63368.8984 - mae: 143.3377 - mse: 63368.898 - 0s 57us/step - loss: 66529.9738 - mae: 149.6771 - mse: 66529.9766\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 55us/step - loss: 65544.7279 - mae: 147.3941 - mse: 65544.7344\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 64581.5570 - mae: 145.2493 - mse: 64581.5586\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 63630.1773 - mae: 143.0657 - mse: 63630.1719\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 62714.2728 - mae: 141.0291 - mse: 62714.2812\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 61830.6302 - mae: 139.0674 - mse: 61830.6250\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 60915.9315 - mae: 137.1989 - mse: 60915.9336\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 60114.0504 - mae: 135.4655 - mse: 60114.0547\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 59287.5517 - mae: 133.7348 - mse: 59287.5469\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 58517.4405 - mae: 132.1764 - mse: 58517.4414\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 57781.3824 - mae: 130.6663 - mse: 57781.3867\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 57078.3500 - mae: 129.3197 - mse: 57078.3516\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 56391.0068 - mae: 128.0805 - mse: 56391.0078\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 55756.1652 - mae: 127.0299 - mse: 55756.1641\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 55154.3276 - mae: 126.1471 - mse: 55154.3242\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 54581.6303 - mae: 125.2941 - mse: 54581.6289\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 54037.4875 - mae: 124.6090 - mse: 54037.4844\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 53538.7434 - mae: 123.9818 - mse: 53538.7461\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 53073.7312 - mae: 123.5961 - mse: 53073.7305\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 52634.0138 - mae: 123.1503 - mse: 52634.0117\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 52208.7010 - mae: 122.9612 - mse: 52208.6992\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 51848.0856 - mae: 122.7052 - mse: 51848.0820\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 51491.3341 - mae: 122.5980 - mse: 51491.3359\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 51179.2514 - mae: 122.6598 - mse: 51179.2539\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 50856.5650 - mae: 122.6158 - mse: 50856.5664\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 50621.4386 - mae: 122.7587 - mse: 50621.4375\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 50340.9381 - mae: 122.9399 - mse: 50340.9414\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 50117.4778 - mae: 123.1062 - mse: 50117.4844\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 49893.0404 - mae: 123.2717 - mse: 49893.0391\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 49726.2192 - mae: 123.5199 - mse: 49726.2227\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 49538.0768 - mae: 123.7966 - mse: 49538.0781\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 49363.2370 - mae: 123.9681 - mse: 49363.2383\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 49219.4166 - mae: 124.2217 - mse: 49219.4141\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 49088.2735 - mae: 124.4826 - mse: 49088.2734\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 48967.7010 - mae: 124.7839 - mse: 48967.7070\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 48850.6502 - mae: 125.0316 - mse: 48850.6523\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 48732.6504 - mae: 125.2368 - mse: 48732.6523\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 48645.7944 - mae: 125.4731 - mse: 48645.7930\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 48544.4313 - mae: 125.6936 - mse: 48544.4336\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 48468.0541 - mae: 125.9626 - mse: 48468.0547\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 48376.6104 - mae: 126.1961 - mse: 48376.6133\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 48306.1631 - mae: 126.4183 - mse: 48306.1641\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 48232.4145 - mae: 126.6449 - mse: 48232.4141\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 48164.7990 - mae: 126.8336 - mse: 48164.8008\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 48102.5331 - mae: 127.0660 - mse: 48102.5352\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 48038.4443 - mae: 127.2434 - mse: 48038.4414\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 47979.4777 - mae: 127.4075 - mse: 47979.4766\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 47911.1535 - mae: 127.4923 - mse: 47911.1562\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 47857.6548 - mae: 127.5273 - mse: 47857.6523\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 47804.4104 - mae: 127.6336 - mse: 47804.4062\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 47750.9654 - mae: 127.7613 - mse: 47750.9648\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 47694.1255 - mae: 127.8666 - mse: 47694.1250\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 47640.5702 - mae: 127.9724 - mse: 47640.5703\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 47602.2497 - mae: 128.1578 - mse: 47602.2500\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 47537.1043 - mae: 128.1964 - mse: 47537.1055\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 47491.2524 - mae: 128.2164 - mse: 47491.2539\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 47436.4554 - mae: 128.2341 - mse: 47436.4570\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 47387.2345 - mae: 128.2519 - mse: 47387.2344\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 47344.9907 - mae: 128.3702 - mse: 47345.0000\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 47282.5458 - mae: 128.3591 - mse: 47282.5469\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 47237.9026 - mae: 128.2653 - mse: 47237.9023\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 47186.1555 - mae: 128.3477 - mse: 47186.1523\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 47128.1143 - mae: 128.3730 - mse: 47128.1172\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 47078.8609 - mae: 128.3976 - mse: 47078.8633\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 47017.7499 - mae: 128.3231 - mse: 47017.7500\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 46971.0706 - mae: 128.1859 - mse: 46971.0703\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 46932.7180 - mae: 128.2685 - mse: 46932.7148\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 46870.5309 - mae: 128.3038 - mse: 46870.5352\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 57us/step - loss: 46815.4653 - mae: 128.1585 - mse: 46815.4648\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 346us/step - loss: 77882.1023 - mae: 195.0798 - mse: 77882.1016\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 77741.0499 - mae: 194.7161 - mse: 77741.0547\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 77595.8069 - mae: 194.3299 - mse: 77595.8047\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 77424.4982 - mae: 193.8947 - mse: 77424.4922\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 77220.6443 - mae: 193.3582 - mse: 77220.6484\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 76967.0259 - mae: 192.6930 - mse: 76967.0234\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 76656.2034 - mae: 191.8996 - mse: 76656.2031\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 76295.2457 - mae: 190.9435 - mse: 76295.2500\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 75873.9411 - mae: 189.8407 - mse: 75873.9453\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 75392.6909 - mae: 188.6125 - mse: 75392.6953\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 74882.4637 - mae: 187.2686 - mse: 74882.4688\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 41us/step - loss: 74312.2100 - mae: 185.8089 - mse: 74312.2109\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 73714.9815 - mae: 184.2283 - mse: 73714.9844\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 73072.3904 - mae: 182.5431 - mse: 73072.3906\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 72384.4708 - mae: 180.7286 - mse: 72384.4688\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 31us/step - loss: 71645.5659 - mae: 178.8172 - mse: 71645.5703\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 70895.2121 - mae: 176.7729 - mse: 70895.2109\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 70111.1227 - mae: 174.5735 - mse: 70111.1250\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 69274.7250 - mae: 172.3345 - mse: 69274.7266\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 68420.4960 - mae: 170.0465 - mse: 68420.4922\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 67556.1102 - mae: 167.6681 - mse: 67556.1172\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 66682.3116 - mae: 165.1752 - mse: 66682.3047\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 65779.0606 - mae: 162.6822 - mse: 65779.0703\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 41us/step - loss: 64827.1184 - mae: 160.2907 - mse: 64827.1211\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 63928.1564 - mae: 157.8421 - mse: 63928.1602\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 63002.8430 - mae: 155.3767 - mse: 63002.8477\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 62056.6637 - mae: 152.9129 - mse: 62056.6680\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 61152.9868 - mae: 150.5665 - mse: 61152.9805\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 60200.9931 - mae: 148.1716 - mse: 60200.9922\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 59283.3540 - mae: 145.8968 - mse: 59283.3516\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 58392.3565 - mae: 143.6005 - mse: 58392.3516\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 57493.1909 - mae: 141.3244 - mse: 57493.1875\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 56592.7026 - mae: 139.1818 - mse: 56592.6992\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 55754.3589 - mae: 137.0305 - mse: 55754.3516\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 54888.8079 - mae: 134.9320 - mse: 54888.8125\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 54060.3271 - mae: 132.8139 - mse: 54060.3281\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 53221.6954 - mae: 130.8024 - mse: 53221.6914\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 52412.5827 - mae: 128.8627 - mse: 52412.5781\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 51649.9991 - mae: 127.0322 - mse: 51650.0000\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 50898.9590 - mae: 125.2786 - mse: 50898.9609\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 50198.4299 - mae: 123.5233 - mse: 50198.4297\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 49519.1055 - mae: 121.9940 - mse: 49519.1133\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 48858.9005 - mae: 120.4908 - mse: 48858.8984\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 48228.9827 - mae: 119.0651 - mse: 48228.9883\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 47633.2900 - mae: 118.0281 - mse: 47633.2891\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 47063.0546 - mae: 116.9216 - mse: 47063.0547\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 46535.2590 - mae: 116.0730 - mse: 46535.2617\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 46046.5079 - mae: 115.3370 - mse: 46046.5039\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 45571.3497 - mae: 114.6646 - mse: 45571.3516\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 45130.2225 - mae: 114.1656 - mse: 45130.2227\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 44732.8195 - mae: 113.7954 - mse: 44732.8242\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 44364.1443 - mae: 113.4877 - mse: 44364.1406\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 44022.5930 - mae: 113.2980 - mse: 44022.5977\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 43711.0456 - mae: 113.1588 - mse: 43711.0430\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 43420.0191 - mae: 113.0505 - mse: 43420.0156\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 43157.2611 - mae: 113.0196 - mse: 43157.2617\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 42924.0542 - mae: 113.1522 - mse: 42924.0508\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 42698.5395 - mae: 113.2590 - mse: 42698.5430\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 42500.5995 - mae: 113.4028 - mse: 42500.6055\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 42330.5939 - mae: 113.6488 - mse: 42330.5938\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 42168.4074 - mae: 113.9247 - mse: 42168.4062\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 42007.0354 - mae: 114.2183 - mse: 42007.0391\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 41867.1548 - mae: 114.4523 - mse: 41867.1562\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 41753.6031 - mae: 114.7076 - mse: 41753.6016\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 41639.1075 - mae: 115.0295 - mse: 41639.1055\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 41529.3389 - mae: 115.3070 - mse: 41529.3398\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 48us/step - loss: 41434.8449 - mae: 115.6004 - mse: 41434.8477\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 41341.0868 - mae: 115.8100 - mse: 41341.0859\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 41266.3604 - mae: 116.0602 - mse: 41266.3594\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 41189.1833 - mae: 116.2850 - mse: 41189.1836\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 41111.7324 - mae: 116.4637 - mse: 41111.7305\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 41048.4618 - mae: 116.5839 - mse: 41048.4609\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 40989.6834 - mae: 116.7810 - mse: 40989.6875\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 40928.1400 - mae: 116.9583 - mse: 40928.1406\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 40870.2307 - mae: 117.1335 - mse: 40870.2305\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 40814.1122 - mae: 117.2888 - mse: 40814.1133\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 40773.6066 - mae: 117.4831 - mse: 40773.6055\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 40714.8786 - mae: 117.6809 - mse: 40714.8750\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 40661.4283 - mae: 117.7349 - mse: 40661.4336\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 40614.5494 - mae: 117.8007 - mse: 40614.5469\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 40566.7068 - mae: 117.8440 - mse: 40566.7070\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 40520.4478 - mae: 117.9217 - mse: 40520.4492\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 40474.7589 - mae: 117.9865 - mse: 40474.7617\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 40427.1893 - mae: 118.0479 - mse: 40427.1875\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 40382.4809 - mae: 118.1128 - mse: 40382.4805\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 40338.5741 - mae: 118.1998 - mse: 40338.5703\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 40288.4401 - mae: 118.2067 - mse: 40288.4414\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 40244.4520 - mae: 118.1503 - mse: 40244.4531\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 40200.0917 - mae: 118.2134 - mse: 40200.0859\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 40147.8796 - mae: 118.1851 - mse: 40147.8789\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 40105.3021 - mae: 118.2252 - mse: 40105.3008\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 40051.5887 - mae: 118.2028 - mse: 40051.5859\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 40001.6421 - mae: 118.1045 - mse: 40001.6406\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 39956.2802 - mae: 118.0936 - mse: 39956.2812\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 39905.7452 - mae: 117.9945 - mse: 39905.7422\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 39850.9969 - mae: 117.8810 - mse: 39850.9961\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 39805.0303 - mae: 117.8750 - mse: 39805.0312\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 39751.9505 - mae: 117.8851 - mse: 39751.9414\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 39697.9131 - mae: 117.8621 - mse: 39697.9141\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 39643.7737 - mae: 117.7136 - mse: 39643.7695\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 348us/step - loss: 85249.4617 - mae: 196.3655 - mse: 85249.4453\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 85063.4901 - mae: 195.9076 - mse: 85063.4922\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 84871.3169 - mae: 195.4139 - mse: 84871.3203\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 84654.8573 - mae: 194.8474 - mse: 84654.8594\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 84392.5604 - mae: 194.1918 - mse: 84392.5625\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 84098.0734 - mae: 193.4043 - mse: 84098.0703\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 83737.2746 - mae: 192.4810 - mse: 83737.2734\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 83325.1667 - mae: 191.4106 - mse: 83325.1641\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 82858.7419 - mae: 190.1895 - mse: 82858.7500\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 82332.3408 - mae: 188.8548 - mse: 82332.3359\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 81777.5100 - mae: 187.4013 - mse: 81777.5078\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 81166.5753 - mae: 185.8344 - mse: 81166.5703\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 80505.7632 - mae: 184.1908 - mse: 80505.7578\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 79828.3000 - mae: 182.4242 - mse: 79828.2969\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 79098.5733 - mae: 180.5299 - mse: 79098.5703\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 78341.0577 - mae: 178.5175 - mse: 78341.0547\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 77551.9944 - mae: 176.4249 - mse: 77551.9922\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 76727.6178 - mae: 174.1932 - mse: 76727.6172\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 75859.0009 - mae: 171.9099 - mse: 75859.0000\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 74991.2211 - mae: 169.5441 - mse: 74991.2188\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 74079.3083 - mae: 167.1979 - mse: 74079.3125\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 73156.2327 - mae: 164.7656 - mse: 73156.2344\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 72203.2561 - mae: 162.4156 - mse: 72203.2500\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 71268.6271 - mae: 160.0536 - mse: 71268.6172\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 70290.2355 - mae: 157.6302 - mse: 70290.2422\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 69338.8811 - mae: 155.1946 - mse: 69338.8828\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 68332.0299 - mae: 152.8631 - mse: 68332.0312\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 67360.6271 - mae: 150.4901 - mse: 67360.6328\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 66382.7967 - mae: 148.2509 - mse: 66382.7969\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 65399.0414 - mae: 146.0173 - mse: 65399.0391\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 64425.5967 - mae: 143.8358 - mse: 64425.5938\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 63537.9848 - mae: 141.6914 - mse: 63537.9805\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 62568.2978 - mae: 139.5679 - mse: 62568.3086\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 38us/step - loss: 61677.2746 - mae: 137.6780 - mse: 61677.2734\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 60800.8695 - mae: 135.8054 - mse: 60800.8672\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 59977.2275 - mae: 133.9401 - mse: 59977.2266\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 59138.0783 - mae: 132.1365 - mse: 59138.0781\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 58343.1003 - mae: 130.4042 - mse: 58343.1016\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 57586.4919 - mae: 128.8010 - mse: 57586.4922\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 56873.4746 - mae: 127.3652 - mse: 56873.4805\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 56152.9504 - mae: 125.9077 - mse: 56152.9453\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 55528.8909 - mae: 124.7730 - mse: 55528.8945\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 54885.5639 - mae: 123.6833 - mse: 54885.5586\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 54313.2046 - mae: 122.8217 - mse: 54313.1992\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 53753.8428 - mae: 121.9605 - mse: 53753.8477\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 53234.2303 - mae: 121.3053 - mse: 53234.2344\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 52735.6640 - mae: 120.7076 - mse: 52735.6680\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 52310.4053 - mae: 120.4287 - mse: 52310.4023\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 51880.3999 - mae: 120.0509 - mse: 51880.3984\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 51494.0419 - mae: 119.9004 - mse: 51494.0391\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 51142.9046 - mae: 119.8570 - mse: 51142.9062\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 50789.3184 - mae: 119.7936 - mse: 50789.3203\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 50489.2092 - mae: 119.8445 - mse: 50489.2070\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 50215.5245 - mae: 119.9790 - mse: 50215.5195\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 49943.2102 - mae: 120.1561 - mse: 49943.2148\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 49711.9901 - mae: 120.2896 - mse: 49711.9922\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 49504.9255 - mae: 120.6040 - mse: 49504.9219\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 49292.3069 - mae: 120.8927 - mse: 49292.3086\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 49104.7135 - mae: 121.1464 - mse: 49104.7148\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 48958.7033 - mae: 121.5670 - mse: 48958.6992\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 48786.2310 - mae: 121.8455 - mse: 48786.2305\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 48653.6525 - mae: 122.1693 - mse: 48653.6484\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 48523.3735 - mae: 122.5195 - mse: 48523.3750\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 48408.3992 - mae: 122.8402 - mse: 48408.3984\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 48289.6223 - mae: 123.1091 - mse: 48289.6211\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 48196.5521 - mae: 123.4169 - mse: 48196.5547\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 48097.4148 - mae: 123.7225 - mse: 48097.4141\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 48008.6794 - mae: 124.0107 - mse: 48008.6797\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 47930.9259 - mae: 124.2609 - mse: 47930.9219\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 47848.1730 - mae: 124.5151 - mse: 47848.1719\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 47778.6729 - mae: 124.7739 - mse: 47778.6719\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 47702.4112 - mae: 124.9346 - mse: 47702.4062\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 47642.4348 - mae: 125.1284 - mse: 47642.4414\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 47570.2734 - mae: 125.2599 - mse: 47570.2695\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 47510.7148 - mae: 125.4047 - mse: 47510.7148\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 47449.6439 - mae: 125.5179 - mse: 47449.6484\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 47390.4710 - mae: 125.5992 - mse: 47390.4688\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 47336.7378 - mae: 125.7435 - mse: 47336.7344\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 47279.2177 - mae: 125.8812 - mse: 47279.2148\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 47224.1939 - mae: 126.0524 - mse: 47224.1914\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 47170.4895 - mae: 126.2118 - mse: 47170.4883\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 47109.7145 - mae: 126.1888 - mse: 47109.7148\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 47059.0286 - mae: 126.2169 - mse: 47059.0273\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 47010.2634 - mae: 126.2688 - mse: 47010.2617\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 46960.9063 - mae: 126.3875 - mse: 46960.9023\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 46898.7971 - mae: 126.4012 - mse: 46898.7930\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 46855.7136 - mae: 126.4734 - mse: 46855.7188\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 46799.0307 - mae: 126.4210 - mse: 46799.0312\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 46747.4751 - mae: 126.4233 - mse: 46747.4727\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 46697.8440 - mae: 126.3890 - mse: 46697.8438\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 46639.2671 - mae: 126.4005 - mse: 46639.2695\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 46597.7365 - mae: 126.4789 - mse: 46597.7383\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 46541.3336 - mae: 126.4876 - mse: 46541.3320\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 46486.8632 - mae: 126.5090 - mse: 46486.8594\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 46432.2281 - mae: 126.4407 - mse: 46432.2266\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 46379.0773 - mae: 126.4117 - mse: 46379.0781\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 46326.7667 - mae: 126.4247 - mse: 46326.7656\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 46267.2538 - mae: 126.3251 - mse: 46267.2578\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 46218.9050 - mae: 126.2398 - mse: 46218.9023\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 46161.0953 - mae: 126.1671 - mse: 46161.0938\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 346us/step - loss: 83626.2284 - mae: 203.3477 - mse: 83626.2344\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 83493.4461 - mae: 203.0127 - mse: 83493.4453\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 83337.1099 - mae: 202.6398 - mse: 83337.1172\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 83141.0104 - mae: 202.1602 - mse: 83141.0078\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 82885.3076 - mae: 201.5272 - mse: 82885.3125\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 82557.2367 - mae: 200.6931 - mse: 82557.2266\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 82145.2366 - mae: 199.6808 - mse: 82145.2422\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 81674.1573 - mae: 198.4741 - mse: 81674.1562\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 28us/step - loss: 81122.9565 - mae: 197.1385 - mse: 81122.9609\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 80529.0467 - mae: 195.6145 - mse: 80529.0469\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 79859.9182 - mae: 193.9715 - mse: 79859.9219\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 79149.9018 - mae: 192.1736 - mse: 79149.9062\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 78377.1750 - mae: 190.2259 - mse: 78377.1719\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 77548.9432 - mae: 188.1416 - mse: 77548.9453\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 76666.8615 - mae: 185.9056 - mse: 76666.8672\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 75745.6565 - mae: 183.5191 - mse: 75745.6562\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 74780.7294 - mae: 180.9536 - mse: 74780.7344\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 73773.4395 - mae: 178.2874 - mse: 73773.4375\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 72719.9155 - mae: 175.5692 - mse: 72719.9141\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 71672.1023 - mae: 172.7394 - mse: 71672.1094\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 70588.5711 - mae: 169.9519 - mse: 70588.5703\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 69475.5391 - mae: 167.1430 - mse: 69475.5469\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 68375.2845 - mae: 164.2574 - mse: 68375.2891\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 67259.3069 - mae: 161.3870 - mse: 67259.3047\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 66120.8749 - mae: 158.5350 - mse: 66120.8828\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 65018.7178 - mae: 155.7773 - mse: 65018.7188\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 63882.9678 - mae: 153.1163 - mse: 63882.9727\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 62802.3120 - mae: 150.5890 - mse: 62802.3086\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 61715.4457 - mae: 148.0134 - mse: 61715.4453\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 60632.8628 - mae: 145.4809 - mse: 60632.8594\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 59613.1225 - mae: 143.0419 - mse: 59613.1250\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 58572.4900 - mae: 140.6601 - mse: 58572.4922\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 57589.3798 - mae: 138.3880 - mse: 57589.3789\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 56628.3148 - mae: 136.2665 - mse: 56628.3203\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 55686.5892 - mae: 134.1879 - mse: 55686.5859\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 54797.9921 - mae: 132.2021 - mse: 54797.9922\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 53948.7500 - mae: 130.3325 - mse: 53948.7500\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 53110.1045 - mae: 128.5101 - mse: 53110.1016\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 52353.9021 - mae: 127.0458 - mse: 52353.8984\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 51621.4702 - mae: 125.6770 - mse: 51621.4727\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 50930.1720 - mae: 124.2846 - mse: 50930.1719\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 50252.6979 - mae: 123.3423 - mse: 50252.6992\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 49639.0584 - mae: 122.3907 - mse: 49639.0586\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 49074.3165 - mae: 121.5509 - mse: 49074.3203\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 48549.2419 - mae: 120.8962 - mse: 48549.2461\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 48042.5713 - mae: 120.3680 - mse: 48042.5742\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 47578.3883 - mae: 120.0231 - mse: 47578.3906\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 47145.1387 - mae: 119.6864 - mse: 47145.1367\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 46765.1048 - mae: 119.4912 - mse: 46765.1055\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 46419.4725 - mae: 119.4398 - mse: 46419.4727\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 46083.3837 - mae: 119.3846 - mse: 46083.3828\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 45764.0357 - mae: 119.5130 - mse: 45764.0352\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 45523.5216 - mae: 119.6989 - mse: 45523.5234\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 45248.4159 - mae: 119.8044 - mse: 45248.4180\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 45021.1862 - mae: 120.0076 - mse: 45021.1875\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 44826.5328 - mae: 120.2994 - mse: 44826.5312\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 44623.0669 - mae: 120.4927 - mse: 44623.0703\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 44454.1693 - mae: 120.7679 - mse: 44454.1680\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 44313.9217 - mae: 121.1234 - mse: 44313.9219\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 44158.1591 - mae: 121.4048 - mse: 44158.1562\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 44044.1121 - mae: 121.7370 - mse: 44044.1172\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 43921.5949 - mae: 122.0430 - mse: 43921.5898\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 43804.7853 - mae: 122.2670 - mse: 43804.7852\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 43700.2206 - mae: 122.4264 - mse: 43700.2227\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 43615.8735 - mae: 122.6351 - mse: 43615.8750\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 41us/step - loss: 43524.1683 - mae: 122.8990 - mse: 43524.1719\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 43449.8313 - mae: 123.1939 - mse: 43449.8320\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 47us/step - loss: 43366.7755 - mae: 123.4778 - mse: 43366.7734\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 43287.5680 - mae: 123.6775 - mse: 43287.5703\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 43222.5524 - mae: 123.8406 - mse: 43222.5508\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 43159.4695 - mae: 124.0529 - mse: 43159.4727\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 43096.1289 - mae: 124.2905 - mse: 43096.1250\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 43026.9067 - mae: 124.3951 - mse: 43026.9062\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 42972.7618 - mae: 124.5320 - mse: 42972.7656\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 42911.2975 - mae: 124.6683 - mse: 42911.3008\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 42854.4503 - mae: 124.7202 - mse: 42854.4531\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 42799.0223 - mae: 124.8402 - mse: 42799.0234\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 42741.1636 - mae: 124.8667 - mse: 42741.1641\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 42688.1416 - mae: 124.9679 - mse: 42688.1406\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 42637.5670 - mae: 124.9657 - mse: 42637.5664\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 42582.7617 - mae: 124.9513 - mse: 42582.7617\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 42530.3359 - mae: 125.0023 - mse: 42530.3359\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 42473.2704 - mae: 125.0595 - mse: 42473.2695\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 42422.4346 - mae: 125.0407 - mse: 42422.4375\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 42373.8152 - mae: 125.0579 - mse: 42373.8164\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 42316.0105 - mae: 125.1421 - mse: 42316.0117\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 42261.5275 - mae: 125.1506 - mse: 42261.5273\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 42209.8370 - mae: 125.1206 - mse: 42209.8320\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 42157.6162 - mae: 125.0876 - mse: 42157.6211\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 42103.9337 - mae: 125.0610 - mse: 42103.9336\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 42048.8299 - mae: 125.0333 - mse: 42048.8281\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 41996.1644 - mae: 125.0366 - mse: 41996.1602\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 41944.4755 - mae: 125.0461 - mse: 41944.4727\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 41884.3700 - mae: 124.9142 - mse: 41884.3711\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 41836.5869 - mae: 124.9255 - mse: 41836.5859\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 41776.1665 - mae: 124.8288 - mse: 41776.1680\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 41725.7581 - mae: 124.7962 - mse: 41725.7578\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 41670.7013 - mae: 124.7912 - mse: 41670.6992\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 41611.3729 - mae: 124.7248 - mse: 41611.3711\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 41555.1747 - mae: 124.6078 - mse: 41555.1719\n",
      "Epoch 1/100\n",
      "750/750 [==============================] - 0s 319us/step - loss: 84569.6034 - mae: 201.4084 - mse: 84569.6016\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 0s 40us/step - loss: 84377.1376 - mae: 200.9474 - mse: 84377.1328\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 84175.0370 - mae: 200.4425 - mse: 84175.0391\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 83935.9546 - mae: 199.8386 - mse: 83935.9609\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 0s 37us/step - loss: 83638.7646 - mae: 199.0829 - mse: 83638.7656\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 83267.9501 - mae: 198.1208 - mse: 83267.9531\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 82802.0612 - mae: 196.9912 - mse: 82802.0625\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 82288.7704 - mae: 195.6732 - mse: 82288.7734\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 0s 40us/step - loss: 81703.1090 - mae: 194.1795 - mse: 81703.1094\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 0s 43us/step - loss: 81060.7365 - mae: 192.5623 - mse: 81060.7344\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 0s 41us/step - loss: 80357.9681 - mae: 190.7896 - mse: 80357.9609\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 0s 39us/step - loss: 79611.3975 - mae: 188.9018 - mse: 79611.4062\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 0s 43us/step - loss: 78797.0383 - mae: 186.8559 - mse: 78797.0469\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 0s 40us/step - loss: 77959.2251 - mae: 184.6545 - mse: 77959.2188\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 77041.1220 - mae: 182.3250 - mse: 77041.1172\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 0s 43us/step - loss: 76119.1219 - mae: 179.7870 - mse: 76119.1172\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 0s 43us/step - loss: 75089.2561 - mae: 177.1633 - mse: 75089.2500\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 74051.4281 - mae: 174.4420 - mse: 74051.4219\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 0s 41us/step - loss: 72971.8331 - mae: 171.5377 - mse: 72971.8203\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 71855.9677 - mae: 168.6103 - mse: 71855.9609\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 0s 60us/step - loss: 70705.2986 - mae: 165.7171 - mse: 70705.2969\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 0s 60us/step - loss: 69562.2839 - mae: 162.8006 - mse: 69562.2812\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 0s 55us/step - loss: 68413.6362 - mae: 159.8952 - mse: 68413.6406\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 0s 60us/step - loss: 67234.0551 - mae: 156.9847 - mse: 67234.0547\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 0s 61us/step - loss: 66097.3258 - mae: 154.1510 - mse: 66097.3359\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 0s 64us/step - loss: 64927.8479 - mae: 151.4531 - mse: 64927.8438\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 0s 64us/step - loss: 63815.3082 - mae: 148.7646 - mse: 63815.3086\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 62690.7240 - mae: 146.0762 - mse: 62690.7266\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 61602.2052 - mae: 143.5819 - mse: 61602.1992\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 60534.5498 - mae: 141.0384 - mse: 60534.5508\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 0s 57us/step - loss: 59518.5435 - mae: 138.6251 - mse: 59518.5547\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 58487.7203 - mae: 136.4495 - mse: 58487.7227\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 0s 56us/step - loss: 57552.7974 - mae: 134.2540 - mse: 57552.8008\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 56607.4420 - mae: 132.2605 - mse: 56607.4414\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 51us/step - loss: 55737.7762 - mae: 130.2397 - mse: 55737.7695\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 54871.2917 - mae: 128.4312 - mse: 54871.2891\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 0s 46us/step - loss: 54072.2356 - mae: 126.8180 - mse: 54072.2344\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 53308.5484 - mae: 125.3219 - mse: 53308.5430\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 52590.2095 - mae: 123.9994 - mse: 52590.2031\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 0s 41us/step - loss: 51880.5719 - mae: 122.8800 - mse: 51880.5742\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 0s 41us/step - loss: 51236.2767 - mae: 121.9479 - mse: 51236.2773\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 50666.9930 - mae: 121.2012 - mse: 50666.9922\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 0s 43us/step - loss: 50073.1871 - mae: 120.5186 - mse: 50073.1836\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 0s 37us/step - loss: 49552.0724 - mae: 119.9743 - mse: 49552.0742\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 0s 39us/step - loss: 49102.3757 - mae: 119.7183 - mse: 49102.3789\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 0s 37us/step - loss: 48649.6027 - mae: 119.4699 - mse: 48649.6055\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 48244.1337 - mae: 119.3069 - mse: 48244.1328\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 0s 33us/step - loss: 47895.3548 - mae: 119.3366 - mse: 47895.3594\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 47566.2322 - mae: 119.3957 - mse: 47566.2344\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 0s 38us/step - loss: 47289.1359 - mae: 119.6847 - mse: 47289.1289\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 0s 40us/step - loss: 47012.0169 - mae: 119.8873 - mse: 47012.0156\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 0s 41us/step - loss: 46784.0569 - mae: 120.1894 - mse: 46784.0547\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 46563.4379 - mae: 120.4540 - mse: 46563.4414\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 46385.3282 - mae: 120.8443 - mse: 46385.3281\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 46198.6520 - mae: 121.1207 - mse: 46198.6523\n",
      "Epoch 56/100\n",
      "750/750 [==============================] - 0s 41us/step - loss: 46048.3184 - mae: 121.4735 - mse: 46048.3164\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 0s 39us/step - loss: 45902.5658 - mae: 121.7813 - mse: 45902.5586\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 0s 37us/step - loss: 45773.4368 - mae: 122.0727 - mse: 45773.4336\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 45656.4668 - mae: 122.3950 - mse: 45656.4648\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 0s 43us/step - loss: 45573.0471 - mae: 122.7757 - mse: 45573.0469\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 0s 41us/step - loss: 45455.3084 - mae: 123.0411 - mse: 45455.3008\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 45355.9145 - mae: 123.2155 - mse: 45355.9141\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 0s 37us/step - loss: 45278.8015 - mae: 123.3995 - mse: 45278.8008\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 45194.2670 - mae: 123.5686 - mse: 45194.2656\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 0s 43us/step - loss: 45118.0277 - mae: 123.7853 - mse: 45118.0273\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 0s 41us/step - loss: 45042.4078 - mae: 123.9489 - mse: 45042.4102\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 44971.6464 - mae: 124.0651 - mse: 44971.6484\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 0s 37us/step - loss: 44905.1216 - mae: 124.2334 - mse: 44905.1211\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 0s 43us/step - loss: 44835.3520 - mae: 124.4100 - mse: 44835.3477\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 0s 37us/step - loss: 44768.5289 - mae: 124.4394 - mse: 44768.5234\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 44703.1117 - mae: 124.5009 - mse: 44703.1055\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 0s 37us/step - loss: 44642.9535 - mae: 124.6777 - mse: 44642.9531\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 44574.8254 - mae: 124.6739 - mse: 44574.8242\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 0s 36us/step - loss: 44514.6386 - mae: 124.7002 - mse: 44514.6367\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 44449.2468 - mae: 124.7446 - mse: 44449.2500\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 44387.2372 - mae: 124.7933 - mse: 44387.2344\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 0s 37us/step - loss: 44326.6054 - mae: 124.8732 - mse: 44326.6094\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 44260.1806 - mae: 124.8706 - mse: 44260.1836\n",
      "Epoch 79/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 44209.8139 - mae: 124.9695 - mse: 44209.8125\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 0s 46us/step - loss: 44133.3252 - mae: 124.9832 - mse: 44133.3242\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 0s 40us/step - loss: 44065.0008 - mae: 124.8874 - mse: 44065.0039\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 44001.0763 - mae: 124.8026 - mse: 44001.0781\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 43934.0724 - mae: 124.7954 - mse: 43934.0703\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 43871.4170 - mae: 124.6672 - mse: 43871.4180\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 0s 38us/step - loss: 43802.5956 - mae: 124.5817 - mse: 43802.5938\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 43738.2884 - mae: 124.6530 - mse: 43738.2891\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 0s 56us/step - loss: 43669.2776 - mae: 124.4831 - mse: 43669.2773\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 0s 59us/step - loss: 43603.6389 - mae: 124.4692 - mse: 43603.6445\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 0s 63us/step - loss: 43527.4667 - mae: 124.4060 - mse: 43527.4688\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 0s 56us/step - loss: 43465.4035 - mae: 124.3971 - mse: 43465.4062\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 0s 66us/step - loss: 43391.4265 - mae: 124.2098 - mse: 43391.4297\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 43328.4372 - mae: 124.1522 - mse: 43328.4414\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 0s 59us/step - loss: 43252.6762 - mae: 123.9682 - mse: 43252.6758\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 43182.7506 - mae: 123.8160 - mse: 43182.7539\n",
      "Epoch 95/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 43116.6702 - mae: 123.7963 - mse: 43116.6680\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 43043.2609 - mae: 123.6638 - mse: 43043.2617\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 42974.8988 - mae: 123.6329 - mse: 42974.8945\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 42901.0291 - mae: 123.5325 - mse: 42901.0273\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 42833.5014 - mae: 123.4315 - mse: 42833.5000\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 0s 56us/step - loss: 42758.4912 - mae: 123.3508 - mse: 42758.4922\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=44, activation = 'relu', input_dim=22))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae','mse'])\n",
    "    return model\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "NN_Regressor = KerasRegressor(build_fn=build_model, batch_size=40,epochs=100)    \n",
    "\n",
    "scores = cross_val_score(NN_Regressor, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "NN = NN_Regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the scores for each model run\n",
      "[-41536.45578229 -32429.48374361 -61222.4536624  -34660.3325281\n",
      " -51258.86725425]\n",
      " \n",
      "Mean and variance: 44221.52 (+/- 21470.61)\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 140.87187237426758\n",
      "Root Mean Squared Error: 61803.214139767064\n",
      "Time Taken =  46.578125\n"
     ]
    }
   ],
   "source": [
    "print(\"Below are the scores for each model run\")\n",
    "print(scores)\n",
    "print(\" \")\n",
    "print(\"Mean and variance: %0.2f (+/- %0.2f)\" % (abs(scores.mean()), scores.std() * 2))\n",
    "\n",
    "y_pred= NN_Regressor.predict(X_test_holdout)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))\n",
    "\n",
    "print('Time Taken = ', time.process_time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Medium depth Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 494us/step - loss: 86143.8211 - mae: 204.3756 - mse: 86143.8125\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 85948.7122 - mae: 203.9089 - mse: 85948.7188\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 85689.6510 - mae: 203.2637 - mse: 85689.6484\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 85306.2901 - mae: 202.3071 - mse: 85306.2891\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 84740.8529 - mae: 200.8789 - mse: 84740.8594\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 83899.0501 - mae: 198.7878 - mse: 83899.0625\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 82714.2490 - mae: 195.8471 - mse: 82714.2422\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 81112.7479 - mae: 191.7996 - mse: 81112.7422\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 79026.9042 - mae: 186.4798 - mse: 79026.9062\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 76371.7831 - mae: 179.7034 - mse: 76371.7891\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 73224.6635 - mae: 171.5473 - mse: 73224.6562\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 69648.1020 - mae: 162.5107 - mse: 69648.1016\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 65745.0324 - mae: 153.2152 - mse: 65745.0234\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 61588.3349 - mae: 143.8647 - mse: 61588.3398\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 57857.3085 - mae: 135.4357 - mse: 57857.3086\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 54334.1934 - mae: 128.5466 - mse: 54334.1914\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 51427.2315 - mae: 123.5647 - mse: 51427.2383\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 49196.6876 - mae: 122.0568 - mse: 49196.6914\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 47687.8070 - mae: 122.6906 - mse: 47687.8086\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 46912.8241 - mae: 124.6069 - mse: 46912.8281\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 46315.3633 - mae: 126.3657 - mse: 46315.3633\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 45993.1301 - mae: 127.5808 - mse: 45993.1289\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 45774.9382 - mae: 128.3540 - mse: 45774.9414\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 45579.4602 - mae: 128.6988 - mse: 45579.4531\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 45418.3118 - mae: 129.1822 - mse: 45418.3125\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 45235.7601 - mae: 129.2589 - mse: 45235.7617\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 45052.3923 - mae: 129.0026 - mse: 45052.3945\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 44892.3158 - mae: 128.6169 - mse: 44892.3125\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 44739.4105 - mae: 128.7745 - mse: 44739.4141\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 44563.4344 - mae: 128.6707 - mse: 44563.4336\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 44405.6279 - mae: 127.8930 - mse: 44405.6250\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 44230.1480 - mae: 127.1911 - mse: 44230.1484\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 44064.8002 - mae: 127.6465 - mse: 44064.8047\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 32us/step - loss: 43902.0132 - mae: 128.2578 - mse: 43902.0117\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 43689.4824 - mae: 127.8391 - mse: 43689.4844\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 43526.8764 - mae: 127.0961 - mse: 43526.8750\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 43351.9717 - mae: 126.6027 - mse: 43351.9727\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 43236.7684 - mae: 126.8461 - mse: 43236.7656\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 43006.1585 - mae: 126.5689 - mse: 43006.1562\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 42826.8119 - mae: 125.9526 - mse: 42826.8086\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 42646.2086 - mae: 125.7862 - mse: 42646.2148\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 42477.3865 - mae: 125.7775 - mse: 42477.3867\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 42281.9122 - mae: 125.1736 - mse: 42281.9180\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 42108.0637 - mae: 124.6185 - mse: 42108.0664\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 41918.6859 - mae: 124.5230 - mse: 41918.6875\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 41734.4829 - mae: 124.6594 - mse: 41734.4844\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 41577.0607 - mae: 124.1801 - mse: 41577.0625\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 41356.6983 - mae: 123.9842 - mse: 41356.6992\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 41186.7548 - mae: 124.0346 - mse: 41186.7578\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 40987.8039 - mae: 123.8765 - mse: 40987.8008\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 40790.0131 - mae: 123.4938 - mse: 40790.0117\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 40599.1559 - mae: 122.8631 - mse: 40599.1562\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 40389.9426 - mae: 122.4821 - mse: 40389.9453\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 40189.8350 - mae: 122.4437 - mse: 40189.8359\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 39986.2937 - mae: 122.2432 - mse: 39986.2969\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 39781.0114 - mae: 122.0435 - mse: 39781.0117\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 39570.0878 - mae: 121.6613 - mse: 39570.0938\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 75us/step - loss: 39365.9435 - mae: 121.1907 - mse: 39365.9453\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 39200.8885 - mae: 120.3097 - mse: 39200.8867\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 38932.4958 - mae: 120.0074 - mse: 38932.4883\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 38727.6841 - mae: 120.0658 - mse: 38727.6836\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 38516.7977 - mae: 120.0239 - mse: 38516.7969\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 38285.1528 - mae: 119.4227 - mse: 38285.1523\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 38095.7257 - mae: 119.4720 - mse: 38095.7305\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 37856.6181 - mae: 118.8279 - mse: 37856.6172\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 37614.5755 - mae: 118.2761 - mse: 37614.5742\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 76us/step - loss: 37404.2547 - mae: 117.9386 - mse: 37404.2539\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 75us/step - loss: 37154.1696 - mae: 117.3677 - mse: 37154.1719\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 75us/step - loss: 36943.7979 - mae: 117.2353 - mse: 36943.8008\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 36721.5549 - mae: 116.6792 - mse: 36721.5586\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 36470.2919 - mae: 116.3344 - mse: 36470.2930\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 36224.2459 - mae: 116.0610 - mse: 36224.2461\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 35990.4499 - mae: 115.4903 - mse: 35990.4492\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 35746.9488 - mae: 115.0453 - mse: 35746.9453\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 35520.6155 - mae: 115.1467 - mse: 35520.6172\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 35271.9180 - mae: 114.5695 - mse: 35271.9219\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 76us/step - loss: 35023.5853 - mae: 113.6106 - mse: 35023.5859\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 78us/step - loss: 34774.6684 - mae: 112.7392 - mse: 34774.6680\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 75us/step - loss: 34520.8550 - mae: 112.8210 - mse: 34520.8555\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 86us/step - loss: 34285.1750 - mae: 112.8870 - mse: 34285.1719\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 76us/step - loss: 34030.9955 - mae: 112.5570 - mse: 34030.9922\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 80us/step - loss: 33785.9681 - mae: 111.6305 - mse: 33785.9648\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 75us/step - loss: 33537.5319 - mae: 111.0294 - mse: 33537.5312\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 33289.4080 - mae: 110.9370 - mse: 33289.4102\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 33050.6856 - mae: 110.7618 - mse: 33050.6875\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 32807.0300 - mae: 110.2717 - mse: 32807.0312\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 32556.8979 - mae: 109.5331 - mse: 32556.9043\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 32316.3126 - mae: 108.4971 - mse: 32316.3125\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 32083.1814 - mae: 108.2971 - mse: 32083.1836\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 31829.6028 - mae: 107.7647 - mse: 31829.5996\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 31629.5991 - mae: 107.9380 - mse: 31629.5996\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 31375.8925 - mae: 107.3547 - mse: 31375.8906\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 31132.4466 - mae: 106.8076 - mse: 31132.4473\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 30926.1514 - mae: 106.8083 - mse: 30926.1543\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 30672.9332 - mae: 105.7578 - mse: 30672.9297\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 41us/step - loss: 30470.2669 - mae: 105.0872 - mse: 30470.2676\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 30238.7402 - mae: 104.6839 - mse: 30238.7441\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 29999.1183 - mae: 104.6514 - mse: 29999.1191\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 29816.1954 - mae: 104.6416 - mse: 29816.1934\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 29593.9352 - mae: 104.0835 - mse: 29593.9375\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 481us/step - loss: 89008.3766 - mae: 205.4390 - mse: 89008.3828\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 88825.6997 - mae: 204.9791 - mse: 88825.7031\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 88634.6409 - mae: 204.4937 - mse: 88634.6484\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 88394.6784 - mae: 203.9007 - mse: 88394.6719\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 88071.3344 - mae: 203.0959 - mse: 88071.3438\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 87611.9315 - mae: 201.9376 - mse: 87611.9297\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 86924.3440 - mae: 200.2551 - mse: 86924.3438\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 85994.8962 - mae: 197.9046 - mse: 85994.8906\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 84721.9932 - mae: 194.7840 - mse: 84721.9844\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 83126.2865 - mae: 190.7219 - mse: 83126.2812\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 81086.7264 - mae: 185.5796 - mse: 81086.7266\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 78684.5365 - mae: 179.3356 - mse: 78684.5391\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 75831.8732 - mae: 172.1812 - mse: 75831.8672\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 72670.7389 - mae: 164.2831 - mse: 72670.7500\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 69317.3806 - mae: 156.3307 - mse: 69317.3750\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 65901.9844 - mae: 148.1241 - mse: 65901.9844\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 62504.6546 - mae: 140.6125 - mse: 62504.6523\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 59342.1750 - mae: 133.8903 - mse: 59342.1719\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 56545.6245 - mae: 128.4173 - mse: 56545.6250\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 54167.9839 - mae: 125.2511 - mse: 54167.9883\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 52381.8186 - mae: 123.6632 - mse: 52381.8242\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 51097.3115 - mae: 123.7845 - mse: 51097.3086\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 50066.2885 - mae: 124.5252 - mse: 50066.2930\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 49538.1713 - mae: 125.7092 - mse: 49538.1719\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 49082.7685 - mae: 126.9858 - mse: 49082.7695\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 48893.9436 - mae: 128.3411 - mse: 48893.9453\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 48633.1296 - mae: 129.1093 - mse: 48633.1250\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 56us/step - loss: 48473.2615 - mae: 129.4716 - mse: 48473.2617\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 48336.7117 - mae: 129.6153 - mse: 48336.7109\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 48196.0239 - mae: 129.9280 - mse: 48196.0234\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 48052.2863 - mae: 130.1783 - mse: 48052.2891\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 47925.5715 - mae: 130.3470 - mse: 47925.5742\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 47781.4998 - mae: 130.1432 - mse: 47781.5000\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 47628.5815 - mae: 130.0669 - mse: 47628.5820\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 53us/step - loss: 47489.9531 - mae: 130.1230 - mse: 47489.9531\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 47338.8472 - mae: 129.9330 - mse: 47338.8516\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 47190.5262 - mae: 129.6803 - mse: 47190.5273\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 47066.5880 - mae: 129.8642 - mse: 47066.5820\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 46909.7028 - mae: 129.8322 - mse: 46909.7031\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 46759.1749 - mae: 129.6566 - mse: 46759.1758\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 46622.0120 - mae: 129.1065 - mse: 46622.0117\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 46474.1432 - mae: 129.0249 - mse: 46474.1484\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 46319.7364 - mae: 128.7820 - mse: 46319.7344\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 46170.5897 - mae: 128.6558 - mse: 46170.5898\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 46048.4504 - mae: 128.8700 - mse: 46048.4492\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 45875.3984 - mae: 128.7304 - mse: 45875.4023\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 45726.1161 - mae: 128.2615 - mse: 45726.1133\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 45588.4592 - mae: 128.1790 - mse: 45588.4609\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 45444.8111 - mae: 127.6458 - mse: 45444.8125\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 45283.2143 - mae: 127.6582 - mse: 45283.2148\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 45137.3385 - mae: 127.7962 - mse: 45137.3398\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 45003.7844 - mae: 127.4854 - mse: 45003.7812\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 44814.1394 - mae: 127.5245 - mse: 44814.1406\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 44678.8876 - mae: 127.3219 - mse: 44678.8945\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 44511.2221 - mae: 126.7913 - mse: 44511.2188\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 44361.2055 - mae: 126.6431 - mse: 44361.2031\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 44209.8290 - mae: 126.4575 - mse: 44209.8281\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 44069.9521 - mae: 126.5177 - mse: 44069.9453\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 43902.5993 - mae: 126.6429 - mse: 43902.6016\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 43736.7688 - mae: 126.0074 - mse: 43736.7734\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 43578.1544 - mae: 125.7190 - mse: 43578.1562\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 43416.7971 - mae: 125.7752 - mse: 43416.8008\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 43255.1249 - mae: 125.6213 - mse: 43255.1250\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 41us/step - loss: 43097.1880 - mae: 124.8741 - mse: 43097.1875\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 42923.1189 - mae: 124.8183 - mse: 42923.1211\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 42793.6346 - mae: 124.3302 - mse: 42793.6367\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 114us/step - loss: 42599.3510 - mae: 124.3388 - mse: 42599.3516\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 42430.6255 - mae: 124.4246 - mse: 42430.6289\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 42261.2233 - mae: 124.2439 - mse: 42261.2266\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 42090.1049 - mae: 124.1495 - mse: 42090.1055\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 41926.5935 - mae: 124.0750 - mse: 41926.5898\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 41731.9629 - mae: 123.4085 - mse: 41731.9648\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 41577.8107 - mae: 122.6720 - mse: 41577.8086\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 41408.7490 - mae: 122.3799 - mse: 41408.7461\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 41227.5906 - mae: 122.6989 - mse: 41227.5938\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 41032.3486 - mae: 122.1895 - mse: 41032.3516\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 40861.9509 - mae: 122.0630 - mse: 40861.9492\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 40685.6232 - mae: 121.4878 - mse: 40685.6211\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 40501.0395 - mae: 121.1718 - mse: 40501.0391\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 40298.7008 - mae: 120.9122 - mse: 40298.6992\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 40125.0506 - mae: 120.8702 - mse: 40125.0508\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 39934.4766 - mae: 120.7666 - mse: 39934.4766\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 39755.5493 - mae: 120.5716 - mse: 39755.5469\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 39548.1741 - mae: 120.0168 - mse: 39548.1758\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 39358.8490 - mae: 119.6438 - mse: 39358.8438\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 39178.2474 - mae: 119.0992 - mse: 39178.2461\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 38971.8198 - mae: 118.8137 - mse: 38971.8203\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 38796.9833 - mae: 118.8739 - mse: 38796.9844\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 38580.8496 - mae: 118.6321 - mse: 38580.8516\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 38373.2911 - mae: 118.1380 - mse: 38373.2891\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 38188.3496 - mae: 117.8765 - mse: 38188.3516\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 37983.5223 - mae: 117.3585 - mse: 37983.5234\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 37826.7076 - mae: 117.4241 - mse: 37826.7109\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 37579.8053 - mae: 116.6757 - mse: 37579.8047\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 37369.7300 - mae: 116.0758 - mse: 37369.7266\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 37233.1443 - mae: 116.3029 - mse: 37233.1484\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 36951.0539 - mae: 115.8938 - mse: 36951.0508\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 36762.1026 - mae: 115.5552 - mse: 36762.1016\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 36555.7794 - mae: 115.0258 - mse: 36555.7812\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 36344.8896 - mae: 114.4589 - mse: 36344.8906\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 522us/step - loss: 78142.1426 - mae: 195.7382 - mse: 78142.1328\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 40us/step - loss: 78045.8362 - mae: 195.4926 - mse: 78045.8438\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 77947.4551 - mae: 195.2354 - mse: 77947.4531\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 77810.6182 - mae: 194.8733 - mse: 77810.6172\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 77595.8172 - mae: 194.3161 - mse: 77595.8125\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 41us/step - loss: 77273.0161 - mae: 193.4781 - mse: 77273.0156\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 33us/step - loss: 76807.1052 - mae: 192.2657 - mse: 76807.1094\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 76155.9984 - mae: 190.5510 - mse: 76156.0000\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 75266.5823 - mae: 188.2416 - mse: 75266.5859\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 74079.9070 - mae: 185.1183 - mse: 74079.9141\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 72496.1839 - mae: 180.8490 - mse: 72496.1875\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 70407.6740 - mae: 175.3661 - mse: 70407.6719\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 49us/step - loss: 67921.2806 - mae: 168.5491 - mse: 67921.2812\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 65028.5417 - mae: 160.5128 - mse: 65028.5352\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 61769.6605 - mae: 151.7920 - mse: 61769.6680\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 58151.6148 - mae: 143.1665 - mse: 58151.6133\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 54722.1315 - mae: 134.3113 - mse: 54722.1328\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 51273.0636 - mae: 125.8644 - mse: 51273.0625\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 48321.5788 - mae: 119.3449 - mse: 48321.5781\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 45815.1911 - mae: 114.9125 - mse: 45815.1875\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 44112.0475 - mae: 113.6870 - mse: 44112.0469\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 42835.2896 - mae: 114.0781 - mse: 42835.2969\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 42063.2478 - mae: 115.2950 - mse: 42063.2461\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 41691.9105 - mae: 117.0990 - mse: 41691.9141\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 41379.9744 - mae: 118.3441 - mse: 41379.9727\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 41209.6493 - mae: 118.9762 - mse: 41209.6484\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 41050.6241 - mae: 119.4533 - mse: 41050.6250\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 40939.8081 - mae: 119.9871 - mse: 40939.8086\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 40785.0355 - mae: 120.0134 - mse: 40785.0352\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 40681.8729 - mae: 119.5000 - mse: 40681.8750\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 40552.8321 - mae: 119.4644 - mse: 40552.8359\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 40442.6627 - mae: 119.8262 - mse: 40442.6680\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 40288.4639 - mae: 119.9754 - mse: 40288.4648\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 40169.3717 - mae: 119.5202 - mse: 40169.3750\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 40054.5953 - mae: 119.5540 - mse: 40054.5938\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 39917.8503 - mae: 119.1719 - mse: 39917.8477\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 39791.4530 - mae: 118.6296 - mse: 39791.4492\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 56us/step - loss: 39671.4368 - mae: 118.4176 - mse: 39671.4375\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 39571.1225 - mae: 118.5231 - mse: 39571.1172\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 39419.0532 - mae: 118.3684 - mse: 39419.0547\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 39300.1113 - mae: 118.0245 - mse: 39300.1055\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 39179.5002 - mae: 118.0204 - mse: 39179.5039\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 39060.3189 - mae: 117.7236 - mse: 39060.3203\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 38922.9489 - mae: 117.5277 - mse: 38922.9453\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 38787.5647 - mae: 117.5970 - mse: 38787.5664\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 38662.6120 - mae: 117.2937 - mse: 38662.6133\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 38520.1146 - mae: 117.1313 - mse: 38520.1172\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 38395.3501 - mae: 116.9366 - mse: 38395.3477\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 38266.1656 - mae: 116.9378 - mse: 38266.1680\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 38134.8139 - mae: 116.5704 - mse: 38134.8125\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 37990.1935 - mae: 116.0000 - mse: 37990.1914\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 37846.9738 - mae: 115.9459 - mse: 37846.9766\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 37702.9463 - mae: 116.1613 - mse: 37702.9414\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 37593.2440 - mae: 116.4889 - mse: 37593.2383\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 37417.1499 - mae: 115.9917 - mse: 37417.1484\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 37276.4854 - mae: 115.8140 - mse: 37276.4883\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 37121.8447 - mae: 115.0980 - mse: 37121.8438\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 37019.3770 - mae: 114.2173 - mse: 37019.3750\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 36814.9776 - mae: 114.0228 - mse: 36814.9766\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 36698.5445 - mae: 114.8016 - mse: 36698.5391\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 36506.5639 - mae: 114.5627 - mse: 36506.5586\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 36375.6778 - mae: 114.6496 - mse: 36375.6758\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 36181.9755 - mae: 113.9973 - mse: 36181.9727\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 36034.7917 - mae: 113.2066 - mse: 36034.7891\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 35863.5069 - mae: 113.0516 - mse: 35863.5117\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 35684.3186 - mae: 112.9801 - mse: 35684.3164\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 35507.7459 - mae: 112.4960 - mse: 35507.7461\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 35336.5748 - mae: 112.1380 - mse: 35336.5742\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 45us/step - loss: 35192.9460 - mae: 112.5298 - mse: 35192.9453\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 34961.8218 - mae: 111.8146 - mse: 34961.8242\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 34782.0775 - mae: 111.3778 - mse: 34782.0781\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 34596.9713 - mae: 110.9233 - mse: 34596.9688\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 34446.9883 - mae: 111.4315 - mse: 34446.9883\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 34204.4410 - mae: 110.5158 - mse: 34204.4414\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 34008.6684 - mae: 110.0513 - mse: 34008.6680\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 33805.9959 - mae: 109.6599 - mse: 33805.9961\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 33616.7911 - mae: 109.7901 - mse: 33616.7852\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 33410.4900 - mae: 109.5700 - mse: 33410.4883\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 33190.2719 - mae: 108.5979 - mse: 33190.2734\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 32975.4995 - mae: 107.9146 - mse: 32975.5000\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 32763.8617 - mae: 107.7377 - mse: 32763.8633\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 32535.0197 - mae: 107.5453 - mse: 32535.0234\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 32330.9486 - mae: 107.5608 - mse: 32330.9492\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 32100.3944 - mae: 107.2323 - mse: 32100.3926\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 31864.7863 - mae: 106.2480 - mse: 31864.7871\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 31633.7288 - mae: 106.1187 - mse: 31633.7266\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 31405.4624 - mae: 105.9810 - mse: 31405.4609\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 31217.3112 - mae: 104.8398 - mse: 31217.3125\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 30930.7121 - mae: 104.5205 - mse: 30930.7109\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 30740.7659 - mae: 104.9524 - mse: 30740.7676\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 30494.7527 - mae: 105.0130 - mse: 30494.7500\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 30192.6406 - mae: 104.1927 - mse: 30192.6406\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 29956.1150 - mae: 102.9874 - mse: 29956.1133\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 29743.3037 - mae: 102.1212 - mse: 29743.3027\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 29536.2022 - mae: 102.3599 - mse: 29536.2031\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 29243.1726 - mae: 102.0160 - mse: 29243.1699\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 29034.4189 - mae: 101.5558 - mse: 29034.4199\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 28756.2575 - mae: 101.2362 - mse: 28756.2539\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 28530.6844 - mae: 100.3346 - mse: 28530.6875\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 28299.5975 - mae: 100.0226 - mse: 28299.5996\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 486us/step - loss: 85279.3117 - mae: 196.4528 - mse: 85279.3125\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 85161.8628 - mae: 196.1577 - mse: 85161.8594\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 85023.2055 - mae: 195.8089 - mse: 85023.2031\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 84830.3073 - mae: 195.3257 - mse: 84830.3047\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 84540.9044 - mae: 194.5834 - mse: 84540.9219\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 84078.5667 - mae: 193.3958 - mse: 84078.5703\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 83370.5546 - mae: 191.5548 - mse: 83370.5547\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 82338.3745 - mae: 188.8405 - mse: 82338.3672\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 80837.2805 - mae: 185.1183 - mse: 80837.2812\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 78965.6538 - mae: 180.1037 - mse: 78965.6562\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 76459.3665 - mae: 173.8200 - mse: 76459.3672\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 73652.8065 - mae: 166.2308 - mse: 73652.8047\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 70339.1378 - mae: 157.9347 - mse: 70339.1328\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 66901.3605 - mae: 149.4438 - mse: 66901.3672\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 63147.7895 - mae: 140.9908 - mse: 63147.7852\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 59618.2892 - mae: 132.9872 - mse: 59618.2930\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 56403.1660 - mae: 126.6636 - mse: 56403.1719\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 53515.5817 - mae: 121.7297 - mse: 53515.5742\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 51465.4518 - mae: 120.0337 - mse: 51465.4531\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 49825.1719 - mae: 120.0535 - mse: 49825.1719\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 48776.9559 - mae: 121.8595 - mse: 48776.9570\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 48269.2458 - mae: 124.0256 - mse: 48269.2461\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 47833.2469 - mae: 125.6760 - mse: 47833.2422\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 47597.9893 - mae: 126.7251 - mse: 47597.9922\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 47402.6984 - mae: 127.5259 - mse: 47402.6992\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 47214.2844 - mae: 127.6045 - mse: 47214.2852\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 47046.9562 - mae: 127.8350 - mse: 47046.9531\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 46877.6301 - mae: 127.8858 - mse: 46877.6289\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 46715.4003 - mae: 128.0296 - mse: 46715.3984\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 46541.1057 - mae: 127.9169 - mse: 46541.1055\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 46377.6058 - mae: 127.8496 - mse: 46377.6133\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 46202.5910 - mae: 127.6787 - mse: 46202.5898\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 46037.7616 - mae: 127.1548 - mse: 46037.7617\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 45875.7408 - mae: 127.0384 - mse: 45875.7383\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 45700.3798 - mae: 127.0499 - mse: 45700.3828\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 45us/step - loss: 45516.1577 - mae: 126.9154 - mse: 45516.1602\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 45365.3351 - mae: 126.9512 - mse: 45365.3320\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 45203.0597 - mae: 127.2283 - mse: 45203.0586\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 45064.9803 - mae: 125.9307 - mse: 45064.9844\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 44845.0131 - mae: 125.9252 - mse: 44845.0117\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 44663.3652 - mae: 126.1346 - mse: 44663.3594\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 44475.1734 - mae: 125.8249 - mse: 44475.1719\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 44308.1121 - mae: 125.6665 - mse: 44308.1133\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 44119.7531 - mae: 125.9815 - mse: 44119.7539\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 43933.4025 - mae: 125.2040 - mse: 43933.4062\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 56us/step - loss: 43741.0630 - mae: 124.6742 - mse: 43741.0625\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 43586.5613 - mae: 125.2177 - mse: 43586.5625\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 43394.9359 - mae: 124.6064 - mse: 43394.9375\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 43197.9468 - mae: 124.5704 - mse: 43197.9453\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 42993.3369 - mae: 124.3788 - mse: 42993.3281\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 42800.0316 - mae: 123.9124 - mse: 42800.0273\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 42608.9941 - mae: 123.6117 - mse: 42608.9922\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 42412.5948 - mae: 123.6492 - mse: 42412.5977\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 42213.5188 - mae: 123.8083 - mse: 42213.5195\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 42011.4315 - mae: 123.9338 - mse: 42011.4336\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 41792.7635 - mae: 123.5713 - mse: 41792.7617\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 41599.6197 - mae: 123.0898 - mse: 41599.6211\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 41356.0551 - mae: 122.5632 - mse: 41356.0586\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 41164.7674 - mae: 121.9339 - mse: 41164.7656\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 40959.3290 - mae: 121.8917 - mse: 40959.3281\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 40751.0283 - mae: 121.9901 - mse: 40751.0273\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 40499.5643 - mae: 121.5384 - mse: 40499.5625\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 40288.0352 - mae: 121.1821 - mse: 40288.0352\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 40080.1640 - mae: 120.8750 - mse: 40080.1641\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 39860.2263 - mae: 120.8028 - mse: 39860.2266\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 39614.9572 - mae: 119.8659 - mse: 39614.9570\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 39364.0833 - mae: 119.1831 - mse: 39364.0820\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 39145.6545 - mae: 119.3973 - mse: 39145.6523\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 38890.4107 - mae: 119.0488 - mse: 38890.4102\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 38665.7995 - mae: 119.2462 - mse: 38665.8008\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 41us/step - loss: 38418.0993 - mae: 118.7044 - mse: 38418.1016\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 38197.6564 - mae: 118.5669 - mse: 38197.6523\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 37946.2065 - mae: 118.9030 - mse: 37946.2109\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 37690.2393 - mae: 118.6088 - mse: 37690.2383\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 37409.0880 - mae: 116.7420 - mse: 37409.0859\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 37148.9674 - mae: 116.1323 - mse: 37148.9688\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 36864.1938 - mae: 116.0057 - mse: 36864.1914\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 36628.0625 - mae: 115.3974 - mse: 36628.0664\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 36353.8727 - mae: 115.5384 - mse: 36353.8711\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 36095.8272 - mae: 115.1874 - mse: 36095.8242\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 35828.3105 - mae: 115.1797 - mse: 35828.3125\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 35537.1156 - mae: 114.4861 - mse: 35537.1172\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 35276.1787 - mae: 114.1563 - mse: 35276.1797\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 34991.6204 - mae: 113.3491 - mse: 34991.6211\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 34707.4152 - mae: 112.8893 - mse: 34707.4180\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 34440.7820 - mae: 112.6538 - mse: 34440.7812\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 34169.6360 - mae: 111.9161 - mse: 34169.6367\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 33910.0774 - mae: 112.2275 - mse: 33910.0742\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 33601.1633 - mae: 111.6029 - mse: 33601.1641\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 33334.7225 - mae: 110.6394 - mse: 33334.7227\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 33108.7164 - mae: 110.5448 - mse: 33108.7148\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 32766.3654 - mae: 110.6890 - mse: 32766.3633\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 32512.6913 - mae: 109.5450 - mse: 32512.6875\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 32227.2016 - mae: 108.8562 - mse: 32227.1992\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 31958.5552 - mae: 108.7884 - mse: 31958.5566\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 31686.2805 - mae: 108.2318 - mse: 31686.2773\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 31394.1368 - mae: 107.3665 - mse: 31394.1328\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 31148.0132 - mae: 106.7467 - mse: 31148.0137\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 30903.2385 - mae: 107.0541 - mse: 30903.2363\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 30631.7053 - mae: 107.2697 - mse: 30631.7070\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 472us/step - loss: 83459.3214 - mae: 202.9593 - mse: 83459.3125\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 83275.5243 - mae: 202.4885 - mse: 83275.5234\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 48us/step - loss: 83023.2352 - mae: 201.8495 - mse: 83023.2344\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 82636.6695 - mae: 200.8602 - mse: 82636.6641\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 81975.9018 - mae: 199.2447 - mse: 81975.8984\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 80990.9490 - mae: 196.6975 - mse: 80990.9453\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 79544.5318 - mae: 192.9431 - mse: 79544.5312\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 77465.8378 - mae: 187.8088 - mse: 77465.8359\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 74892.2264 - mae: 180.8766 - mse: 74892.2344\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 71723.0979 - mae: 172.4132 - mse: 71723.1094\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 68054.5674 - mae: 163.0745 - mse: 68054.5625\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 64102.4440 - mae: 153.1848 - mse: 64102.4453\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 59878.1152 - mae: 143.4694 - mse: 59878.1211\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 55906.5307 - mae: 134.1918 - mse: 55906.5312\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 52272.7043 - mae: 126.8451 - mse: 52272.6992\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 49222.9942 - mae: 122.0556 - mse: 49222.9961\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 47173.4923 - mae: 120.5533 - mse: 47173.4883\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 49us/step - loss: 45739.7193 - mae: 121.2319 - mse: 45739.7148\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 44880.9588 - mae: 122.8867 - mse: 44880.9570\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 44428.4887 - mae: 124.6958 - mse: 44428.4883\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 44134.6507 - mae: 126.0588 - mse: 44134.6484\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 44018.8249 - mae: 127.4872 - mse: 44018.8242\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 43759.0130 - mae: 127.5547 - mse: 43759.0156\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 43588.9474 - mae: 127.3554 - mse: 43588.9453\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 43438.6111 - mae: 127.4692 - mse: 43438.6094\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 43274.4440 - mae: 127.0236 - mse: 43274.4414\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 77us/step - loss: 43110.7930 - mae: 126.6986 - mse: 43110.7930\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 42971.6658 - mae: 127.2557 - mse: 42971.6719\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 42783.5449 - mae: 126.8367 - mse: 42783.5469\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 42633.2498 - mae: 126.2703 - mse: 42633.2500\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 42486.1781 - mae: 126.4173 - mse: 42486.1797\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 42309.7130 - mae: 126.2495 - mse: 42309.7148\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 42175.8249 - mae: 125.9685 - mse: 42175.8281\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 42002.6010 - mae: 125.8431 - mse: 42002.6016\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 78us/step - loss: 41848.1608 - mae: 125.6998 - mse: 41848.1641\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 41689.1118 - mae: 125.7605 - mse: 41689.1133\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 41531.5227 - mae: 125.6714 - mse: 41531.5273\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 41366.8191 - mae: 125.5042 - mse: 41366.8203\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 41199.6633 - mae: 125.2296 - mse: 41199.6641\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 75us/step - loss: 41050.1207 - mae: 125.2347 - mse: 41050.1211\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 40879.3529 - mae: 125.0313 - mse: 40879.3516\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 40717.0347 - mae: 124.2806 - mse: 40717.0352\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 72us/step - loss: 40579.5770 - mae: 124.0825 - mse: 40579.5742\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 81us/step - loss: 40384.1031 - mae: 124.0610 - mse: 40384.0977\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 40218.6484 - mae: 123.6468 - mse: 40218.6484\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 40048.4553 - mae: 123.1710 - mse: 40048.4531\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 39902.3232 - mae: 123.3405 - mse: 39902.3242\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 39701.6738 - mae: 123.5024 - mse: 39701.6719\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 39518.9979 - mae: 123.0468 - mse: 39518.9961\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 39332.7417 - mae: 122.9143 - mse: 39332.7422\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 39165.1806 - mae: 122.2071 - mse: 39165.1797\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 38946.5122 - mae: 121.9093 - mse: 38946.5117\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 38763.2630 - mae: 122.4718 - mse: 38763.2617\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 38555.4352 - mae: 121.9211 - mse: 38555.4375\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 38348.4914 - mae: 121.4516 - mse: 38348.4883\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 38148.3307 - mae: 121.4899 - mse: 38148.3281\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 37927.2396 - mae: 121.0357 - mse: 37927.2383\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 37728.3868 - mae: 120.1880 - mse: 37728.3867\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 37530.6661 - mae: 120.4007 - mse: 37530.6680\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 37282.1839 - mae: 120.0440 - mse: 37282.1875\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 76us/step - loss: 37062.7236 - mae: 119.5933 - mse: 37062.7227\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 76us/step - loss: 36859.1256 - mae: 119.5668 - mse: 36859.1250\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 36608.5823 - mae: 118.9208 - mse: 36608.5820\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 75us/step - loss: 36389.8594 - mae: 118.2905 - mse: 36389.8594\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 36147.0294 - mae: 117.9498 - mse: 36147.0273\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 35903.2172 - mae: 117.7494 - mse: 35903.2148\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 76us/step - loss: 35656.3336 - mae: 117.4779 - mse: 35656.3281\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 35413.2628 - mae: 117.3523 - mse: 35413.2617\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 73us/step - loss: 35155.2661 - mae: 116.9068 - mse: 35155.2656\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 80us/step - loss: 34933.7995 - mae: 115.9504 - mse: 34933.8008\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 75us/step - loss: 34657.8537 - mae: 115.6816 - mse: 34657.8516\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 34416.2812 - mae: 115.1309 - mse: 34416.2852\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 34136.3715 - mae: 114.5787 - mse: 34136.3750\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 33895.6116 - mae: 114.7178 - mse: 33895.6133\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 33618.6079 - mae: 114.3808 - mse: 33618.6094\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 33378.4820 - mae: 114.0771 - mse: 33378.4844\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 33068.5338 - mae: 113.3402 - mse: 33068.5352\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 32800.2570 - mae: 112.5084 - mse: 32800.2617\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 32537.1225 - mae: 112.0157 - mse: 32537.1230\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 32258.0799 - mae: 111.1241 - mse: 32258.0801\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 31985.1861 - mae: 110.7168 - mse: 31985.1875\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 31718.9749 - mae: 110.3259 - mse: 31718.9727\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 31426.1401 - mae: 109.8445 - mse: 31426.1406\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 31171.5173 - mae: 108.8769 - mse: 31171.5176\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 56us/step - loss: 30956.0558 - mae: 109.2175 - mse: 30956.0527\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 30610.6779 - mae: 108.7643 - mse: 30610.6797\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 30363.4063 - mae: 107.4416 - mse: 30363.4062\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 30082.9143 - mae: 107.1200 - mse: 30082.9160\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 29807.5395 - mae: 107.0211 - mse: 29807.5391\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 29518.8284 - mae: 106.1543 - mse: 29518.8262\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 29254.9511 - mae: 105.5569 - mse: 29254.9492\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 29053.8428 - mae: 104.5352 - mse: 29053.8398\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 28793.4614 - mae: 104.7684 - mse: 28793.4609\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 28498.5605 - mae: 104.6148 - mse: 28498.5605\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 28240.5243 - mae: 103.9334 - mse: 28240.5234\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 49us/step - loss: 27978.6557 - mae: 103.1297 - mse: 27978.6543\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 27753.0900 - mae: 102.8357 - mse: 27753.0918\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 27556.8648 - mae: 102.6437 - mse: 27556.8672\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 27274.6229 - mae: 102.3495 - mse: 27274.6211\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 27079.2520 - mae: 101.3041 - mse: 27079.2539\n",
      "Epoch 1/100\n",
      "750/750 [==============================] - 0s 566us/step - loss: 84297.2634 - mae: 200.7183 - mse: 84297.2656\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 84094.3295 - mae: 200.1971 - mse: 84094.3281\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 0s 56us/step - loss: 83802.3364 - mae: 199.4432 - mse: 83802.3359\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 83320.3955 - mae: 198.2140 - mse: 83320.3984\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 82510.7199 - mae: 196.1900 - mse: 82510.7188\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 81268.4070 - mae: 192.9435 - mse: 81268.4062\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 79458.0259 - mae: 188.3886 - mse: 79458.0234\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 0s 39us/step - loss: 77055.5135 - mae: 182.0988 - mse: 77055.5156\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 0s 41us/step - loss: 73880.3442 - mae: 173.7133 - mse: 73880.3438\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 0s 50us/step - loss: 70053.5310 - mae: 163.9206 - mse: 70053.5312\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 65754.3772 - mae: 152.9933 - mse: 65754.3672\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 0s 55us/step - loss: 61193.5441 - mae: 142.5181 - mse: 61193.5430\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 56803.2015 - mae: 132.8004 - mse: 56803.1992\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 52935.7593 - mae: 124.7406 - mse: 52935.7617\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 0s 56us/step - loss: 50092.7029 - mae: 120.5720 - mse: 50092.7109\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 0s 56us/step - loss: 48037.2888 - mae: 119.8970 - mse: 48037.2891\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 46686.5094 - mae: 120.9705 - mse: 46686.5117\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 45990.1695 - mae: 122.9633 - mse: 45990.1641\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 45560.9096 - mae: 124.5043 - mse: 45560.9102\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 0s 61us/step - loss: 45318.5661 - mae: 125.9597 - mse: 45318.5664\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 0s 55us/step - loss: 45103.6527 - mae: 126.9182 - mse: 45103.6523\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 0s 57us/step - loss: 44902.1133 - mae: 127.0486 - mse: 44902.1133\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 0s 54us/step - loss: 44705.1170 - mae: 126.6966 - mse: 44705.1211\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 0s 56us/step - loss: 44513.9366 - mae: 126.4236 - mse: 44513.9375\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 0s 59us/step - loss: 44323.7985 - mae: 126.7069 - mse: 44323.7930\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 44125.3101 - mae: 126.0196 - mse: 44125.3125\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 0s 56us/step - loss: 43948.3166 - mae: 125.8495 - mse: 43948.3125\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 0s 57us/step - loss: 43734.1189 - mae: 125.8565 - mse: 43734.1172\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 43535.4973 - mae: 125.5771 - mse: 43535.4961\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 0s 57us/step - loss: 43339.3732 - mae: 124.8940 - mse: 43339.3750\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 0s 61us/step - loss: 43155.3521 - mae: 125.1672 - mse: 43155.3516\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 42943.0135 - mae: 124.6452 - mse: 42943.0117\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 42732.9356 - mae: 124.2897 - mse: 42732.9375\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 42534.1944 - mae: 124.2262 - mse: 42534.1992\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 42328.9166 - mae: 124.1954 - mse: 42328.9219\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 0s 59us/step - loss: 42118.7717 - mae: 123.5825 - mse: 42118.7695\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 64us/step - loss: 41901.7731 - mae: 123.5435 - mse: 41901.7734\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 0s 66us/step - loss: 41697.2096 - mae: 123.3323 - mse: 41697.2148\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 0s 59us/step - loss: 41472.5952 - mae: 122.9707 - mse: 41472.5938\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 0s 66us/step - loss: 41269.3595 - mae: 123.0672 - mse: 41269.3594\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 41051.9808 - mae: 122.3055 - mse: 41051.9805\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 0s 62us/step - loss: 40822.1702 - mae: 122.0865 - mse: 40822.1680\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 40604.1698 - mae: 122.1302 - mse: 40604.1719\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 0s 60us/step - loss: 40380.9407 - mae: 121.3874 - mse: 40380.9375\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 0s 68us/step - loss: 40152.7536 - mae: 121.3662 - mse: 40152.7578\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 0s 67us/step - loss: 39906.8924 - mae: 120.7793 - mse: 39906.8945\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 0s 66us/step - loss: 39667.6571 - mae: 120.5004 - mse: 39667.6602\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 0s 61us/step - loss: 39448.2601 - mae: 120.8571 - mse: 39448.2578\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 0s 64us/step - loss: 39194.0764 - mae: 120.0283 - mse: 39194.0781\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 0s 65us/step - loss: 38954.9979 - mae: 119.7683 - mse: 38954.9961\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 0s 57us/step - loss: 38706.8461 - mae: 119.5611 - mse: 38706.8477\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 38469.4766 - mae: 118.3794 - mse: 38469.4766\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 0s 56us/step - loss: 38209.1393 - mae: 118.5391 - mse: 38209.1406\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 0s 57us/step - loss: 37934.6077 - mae: 118.2972 - mse: 37934.6055\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 37692.1021 - mae: 118.2739 - mse: 37692.1016\n",
      "Epoch 56/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 37453.6483 - mae: 117.0060 - mse: 37453.6523\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 37231.8775 - mae: 117.5792 - mse: 37231.8750\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 0s 60us/step - loss: 36896.9617 - mae: 116.4003 - mse: 36896.9609\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 0s 56us/step - loss: 36612.3413 - mae: 115.1976 - mse: 36612.3398\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 36348.2842 - mae: 115.5554 - mse: 36348.2812\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 36054.6338 - mae: 115.6644 - mse: 36054.6367\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 35781.0640 - mae: 114.8155 - mse: 35781.0625\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 35475.7658 - mae: 114.1543 - mse: 35475.7695\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 0s 50us/step - loss: 35219.4178 - mae: 113.6100 - mse: 35219.4180\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 34915.8970 - mae: 112.9036 - mse: 34915.8945\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 34628.1526 - mae: 112.8601 - mse: 34628.1562\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 34335.7714 - mae: 112.8952 - mse: 34335.7695\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 34029.6326 - mae: 111.4067 - mse: 34029.6289\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 0s 43us/step - loss: 33718.8136 - mae: 111.1607 - mse: 33718.8164\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 33415.4501 - mae: 110.5700 - mse: 33415.4570\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 33134.7543 - mae: 110.4874 - mse: 33134.7578\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 32779.9229 - mae: 109.1447 - mse: 32779.9219\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 32464.7632 - mae: 108.4248 - mse: 32464.7656\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 32145.1288 - mae: 108.2929 - mse: 32145.1250\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 31840.8418 - mae: 107.8879 - mse: 31840.8398\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 31579.6493 - mae: 107.9771 - mse: 31579.6504\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 0s 57us/step - loss: 31229.0708 - mae: 107.4268 - mse: 31229.0684\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 30941.0508 - mae: 105.9833 - mse: 30941.0508\n",
      "Epoch 79/100\n",
      "750/750 [==============================] - 0s 46us/step - loss: 30628.5182 - mae: 105.3455 - mse: 30628.5176\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 30347.9444 - mae: 105.5709 - mse: 30347.9414\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 30050.5142 - mae: 104.5385 - mse: 30050.5156\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 29742.9048 - mae: 104.2312 - mse: 29742.9043\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 29470.2664 - mae: 104.0312 - mse: 29470.2676\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 0s 56us/step - loss: 29214.2452 - mae: 102.7996 - mse: 29214.2402\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 28940.0176 - mae: 102.3211 - mse: 28940.0156\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 28674.2560 - mae: 102.6562 - mse: 28674.2559\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 28403.3467 - mae: 101.8417 - mse: 28403.3438\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 0s 57us/step - loss: 28197.0338 - mae: 101.5304 - mse: 28197.0312\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 27908.8692 - mae: 100.9555 - mse: 27908.8633\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 0s 56us/step - loss: 27697.0487 - mae: 99.9632 - mse: 27697.0488\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 27494.3718 - mae: 100.3176 - mse: 27494.3730\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 27233.7953 - mae: 99.9815 - mse: 27233.7949\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 27032.1635 - mae: 99.1892 - mse: 27032.1621\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 0s 41us/step - loss: 26813.3955 - mae: 99.1151 - mse: 26813.3945\n",
      "Epoch 95/100\n",
      "750/750 [==============================] - 0s 54us/step - loss: 26614.3479 - mae: 98.3963 - mse: 26614.3457\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 26442.4336 - mae: 97.5686 - mse: 26442.4355\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 0s 43us/step - loss: 26269.0852 - mae: 98.1886 - mse: 26269.0859\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 26064.2850 - mae: 97.8814 - mse: 26064.2852\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 25895.9328 - mae: 97.6941 - mse: 25895.9316\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 25750.8214 - mae: 96.8525 - mse: 25750.8223\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=22, activation = 'relu', input_dim=22))\n",
    "    model.add(Dense(units=22, activation = 'relu'))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae','mse'])\n",
    "    return model\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "NN_Regressor = KerasRegressor(build_fn=build_model, batch_size=40,epochs=100)    \n",
    "\n",
    "scores = cross_val_score(NN_Regressor, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "NN = NN_Regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the scores for each model run\n",
      "[-28565.39957291 -24083.02752101 -45652.81687063 -25565.40087296\n",
      " -37855.60690973]\n",
      " \n",
      "Mean and variance: 32344.45 (+/- 16394.47)\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 108.11128180541992\n",
      "Root Mean Squared Error: 41808.255924489065\n"
     ]
    }
   ],
   "source": [
    "print(\"Below are the scores for each model run\")\n",
    "print(scores)\n",
    "print(\" \")\n",
    "print(\"Mean and variance: %0.2f (+/- %0.2f)\" % (abs(scores.mean()), scores.std() * 2))\n",
    "\n",
    "y_pred= NN_Regressor.predict(X_test_holdout)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 660us/step - loss: 86327.0083 - mae: 204.8447 - mse: 86327.0078\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 86293.7312 - mae: 204.7630 - mse: 86293.7344\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 86251.3379 - mae: 204.6585 - mse: 86251.3438\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 86186.6818 - mae: 204.4871 - mse: 86186.6797\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 86063.7396 - mae: 204.1797 - mse: 86063.7344\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 85857.3141 - mae: 203.6518 - mse: 85857.3203\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 85516.0625 - mae: 202.7661 - mse: 85516.0703\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 84925.8935 - mae: 201.2662 - mse: 84925.8828\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 83985.8195 - mae: 198.8576 - mse: 83985.8203\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 82538.2178 - mae: 195.2403 - mse: 82538.2188\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 80557.2081 - mae: 190.1813 - mse: 80557.2031\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 77776.0967 - mae: 183.0558 - mse: 77776.0938\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 56us/step - loss: 74246.2706 - mae: 173.9648 - mse: 74246.2734\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 69922.3587 - mae: 163.2793 - mse: 69922.3594\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 65025.0443 - mae: 151.3926 - mse: 65025.0391\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 59780.7172 - mae: 139.4281 - mse: 59780.7188\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 54854.9384 - mae: 128.3464 - mse: 54854.9336\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 50852.7602 - mae: 122.8025 - mse: 50852.7617\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 48225.0167 - mae: 122.0183 - mse: 48225.0156\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 46970.4197 - mae: 125.3406 - mse: 46970.4180\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 46342.2551 - mae: 127.8865 - mse: 46342.2578\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 46089.7738 - mae: 129.4208 - mse: 46089.7734\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 45896.6482 - mae: 129.9582 - mse: 45896.6484\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 45684.9070 - mae: 129.9708 - mse: 45684.9062\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 45539.0907 - mae: 130.1964 - mse: 45539.0859\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 45307.4493 - mae: 129.4939 - mse: 45307.4492\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 45134.2105 - mae: 129.1742 - mse: 45134.2070\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 44954.0438 - mae: 128.5269 - mse: 44954.0469\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 44772.8749 - mae: 128.5074 - mse: 44772.8750\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 44579.8095 - mae: 128.6622 - mse: 44579.8086\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 85us/step - loss: 44407.1078 - mae: 128.5693 - mse: 44407.1094\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 44225.6548 - mae: 128.0493 - mse: 44225.6562\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 44048.3733 - mae: 128.0804 - mse: 44048.3750\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 43867.1582 - mae: 127.4579 - mse: 43867.1602\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 43684.8440 - mae: 127.4281 - mse: 43684.8438\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 43501.1949 - mae: 127.3559 - mse: 43501.1953\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 43358.4372 - mae: 127.4679 - mse: 43358.4414\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 43139.8581 - mae: 127.1632 - mse: 43139.8555\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 42936.0253 - mae: 126.5592 - mse: 42936.0273\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 42768.4663 - mae: 125.7451 - mse: 42768.4648\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 56us/step - loss: 42581.1359 - mae: 125.6806 - mse: 42581.1328\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 42405.8997 - mae: 126.2063 - mse: 42405.8984\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 42176.3896 - mae: 125.7526 - mse: 42176.3906\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 41991.4277 - mae: 125.0076 - mse: 41991.4297\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 41790.1704 - mae: 124.7875 - mse: 41790.1719\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 41572.7199 - mae: 124.7473 - mse: 41572.7148\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 41377.8314 - mae: 124.5065 - mse: 41377.8320\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 56us/step - loss: 41181.1077 - mae: 124.2847 - mse: 41181.1055\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 40972.3820 - mae: 124.4324 - mse: 40972.3789\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 40736.3790 - mae: 123.7242 - mse: 40736.3828\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 40519.2431 - mae: 123.2757 - mse: 40519.2422\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 40284.8263 - mae: 122.9746 - mse: 40284.8281\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 40055.8493 - mae: 122.2430 - mse: 40055.8516\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 39859.3681 - mae: 122.6423 - mse: 39859.3711\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 39587.9513 - mae: 122.0576 - mse: 39587.9492\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 39363.1975 - mae: 121.7261 - mse: 39363.1953\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 76us/step - loss: 39109.7878 - mae: 121.5347 - mse: 39109.7852\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 38861.5701 - mae: 120.3121 - mse: 38861.5664\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 38590.3965 - mae: 119.9684 - mse: 38590.3945\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 38350.3097 - mae: 120.2160 - mse: 38350.3086\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 38048.4785 - mae: 119.4070 - mse: 38048.4766\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 37782.3293 - mae: 118.9302 - mse: 37782.3281\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 37533.1225 - mae: 119.1725 - mse: 37533.1250\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 37213.4018 - mae: 118.0785 - mse: 37213.4023\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 36955.6549 - mae: 116.9812 - mse: 36955.6523\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 36642.5411 - mae: 116.5792 - mse: 36642.5391\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 36362.2513 - mae: 116.3658 - mse: 36362.2500\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 52us/step - loss: 36053.6670 - mae: 116.7716 - mse: 36053.6680\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 35781.2469 - mae: 116.3723 - mse: 35781.2461\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 35441.9320 - mae: 115.1830 - mse: 35441.9336\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 35150.8938 - mae: 114.6777 - mse: 35150.8906\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 34898.0190 - mae: 114.9180 - mse: 34898.0195\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 41us/step - loss: 34503.0789 - mae: 113.5288 - mse: 34503.0781\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 34196.9363 - mae: 112.4602 - mse: 34196.9336\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 33937.8187 - mae: 112.8537 - mse: 33937.8203\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 33533.1131 - mae: 112.2758 - mse: 33533.1133\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 33214.4081 - mae: 111.3767 - mse: 33214.4102\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 32921.5751 - mae: 110.2120 - mse: 32921.5781\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 32560.1318 - mae: 109.9826 - mse: 32560.1328\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 32252.1266 - mae: 109.8037 - mse: 32252.1270\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 31941.9691 - mae: 108.8324 - mse: 31941.9668\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 31600.2323 - mae: 108.5715 - mse: 31600.2363\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 31355.3349 - mae: 108.9983 - mse: 31355.3340\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 30941.6419 - mae: 107.5983 - mse: 30941.6406\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 30654.1861 - mae: 106.9873 - mse: 30654.1875\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 30331.5779 - mae: 106.1941 - mse: 30331.5762\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 30035.0829 - mae: 105.5376 - mse: 30035.0801\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 29747.1061 - mae: 104.8935 - mse: 29747.1035\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 29476.6356 - mae: 105.2733 - mse: 29476.6367\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 29199.2350 - mae: 104.2060 - mse: 29199.2324\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 28903.5751 - mae: 103.6035 - mse: 28903.5742\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 28655.5047 - mae: 103.7649 - mse: 28655.5059\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 28351.6911 - mae: 102.8351 - mse: 28351.6895\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 28130.3778 - mae: 102.4080 - mse: 28130.3809\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 41us/step - loss: 27912.1140 - mae: 101.6190 - mse: 27912.1133\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 27667.7463 - mae: 102.0205 - mse: 27667.7441\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 27407.0080 - mae: 101.2872 - mse: 27407.0078\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 27212.6208 - mae: 100.8408 - mse: 27212.6191\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 27006.6076 - mae: 99.9972 - mse: 27006.6074\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 26804.5305 - mae: 99.8858 - mse: 26804.5332\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 586us/step - loss: 88902.9156 - mae: 205.2163 - mse: 88902.9219\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 88742.2930 - mae: 204.8477 - mse: 88742.2969\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 88524.3750 - mae: 204.3235 - mse: 88524.3828\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 88209.3531 - mae: 203.5609 - mse: 88209.3594\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 87758.5932 - mae: 202.4618 - mse: 87758.5938\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 87098.8094 - mae: 200.9331 - mse: 87098.8047\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 86239.4352 - mae: 198.7407 - mse: 86239.4375\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 84998.9990 - mae: 195.7308 - mse: 84999.0078\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 83330.0888 - mae: 191.7795 - mse: 83330.0859\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 81279.5625 - mae: 186.4090 - mse: 81279.5703\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 78570.8715 - mae: 179.6233 - mse: 78570.8672\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 75372.5737 - mae: 171.5668 - mse: 75372.5703\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 71620.7904 - mae: 162.1967 - mse: 71620.7969\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 67462.2057 - mae: 152.5989 - mse: 67462.2031\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 63203.4514 - mae: 142.6320 - mse: 63203.4531\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 58996.2098 - mae: 133.2144 - mse: 58996.2070\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 55434.7520 - mae: 126.4705 - mse: 55434.7500\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 52467.6268 - mae: 123.0994 - mse: 52467.6328\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 50365.7599 - mae: 123.0902 - mse: 50365.7539\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 49176.4041 - mae: 124.2463 - mse: 49176.4062\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 48625.6225 - mae: 126.7754 - mse: 48625.6250\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 48257.5698 - mae: 128.8623 - mse: 48257.5703\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 48047.5440 - mae: 129.9800 - mse: 48047.5430\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 47851.4633 - mae: 129.9176 - mse: 47851.4648\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 47687.8755 - mae: 129.6727 - mse: 47687.8750\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 47597.9011 - mae: 130.4845 - mse: 47597.9023\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 47380.6086 - mae: 130.0938 - mse: 47380.6016\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 47226.1035 - mae: 129.8173 - mse: 47226.1016\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 41us/step - loss: 47078.4643 - mae: 129.8028 - mse: 47078.4648\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 46933.6965 - mae: 129.9825 - mse: 46933.6914\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 46770.0186 - mae: 129.5399 - mse: 46770.0156\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 46618.1108 - mae: 129.2671 - mse: 46618.1094\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 46483.7041 - mae: 129.6334 - mse: 46483.6992\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 46318.9595 - mae: 129.1473 - mse: 46318.9570\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 50us/step - loss: 46175.6137 - mae: 128.6805 - mse: 46175.6133\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 46013.6649 - mae: 128.5733 - mse: 46013.6680\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 45855.7292 - mae: 128.4243 - mse: 45855.7266\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 45707.1106 - mae: 128.5693 - mse: 45707.1055\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 45553.1648 - mae: 128.4764 - mse: 45553.1680\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 45400.4520 - mae: 128.3483 - mse: 45400.4609\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 45244.8683 - mae: 128.5941 - mse: 45244.8672\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 45093.0848 - mae: 128.0452 - mse: 45093.0859\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 44921.1549 - mae: 127.8497 - mse: 44921.1523\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 44773.6687 - mae: 127.7554 - mse: 44773.6719\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 44633.0499 - mae: 127.7961 - mse: 44633.0547\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 44439.0437 - mae: 127.5799 - mse: 44439.0469\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 44280.4003 - mae: 127.0843 - mse: 44280.3984\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 44118.9900 - mae: 126.4745 - mse: 44118.9883\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 43970.6890 - mae: 126.0649 - mse: 43970.6914\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 43786.4395 - mae: 126.0792 - mse: 43786.4375\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 43615.9364 - mae: 126.3373 - mse: 43615.9336\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 43421.2484 - mae: 126.2101 - mse: 43421.2500\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 43266.0845 - mae: 126.2892 - mse: 43266.0859\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 43085.6557 - mae: 125.9897 - mse: 43085.6562\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 42872.6126 - mae: 125.3178 - mse: 42872.6133\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 42673.5094 - mae: 124.6691 - mse: 42673.5078\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 42426.5844 - mae: 124.1582 - mse: 42426.5820\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 42158.9294 - mae: 124.0182 - mse: 42158.9297\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 41882.5054 - mae: 123.6986 - mse: 41882.5039\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 41515.4051 - mae: 122.5472 - mse: 41515.4023\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 41204.0300 - mae: 121.6294 - mse: 41204.0352\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 40892.4494 - mae: 121.0862 - mse: 40892.4492\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 40568.2316 - mae: 120.9728 - mse: 40568.2305\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 40298.4094 - mae: 121.0903 - mse: 40298.4141\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 39948.8882 - mae: 120.1483 - mse: 39948.8906\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 39613.9464 - mae: 119.1664 - mse: 39613.9414\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 39246.2087 - mae: 118.9653 - mse: 39246.2070\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 38919.0781 - mae: 118.4859 - mse: 38919.0781\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 38560.6158 - mae: 118.2880 - mse: 38560.6172\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 38215.6779 - mae: 117.6711 - mse: 38215.6758\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 37879.6937 - mae: 116.8018 - mse: 37879.6914\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 37495.3453 - mae: 116.3609 - mse: 37495.3438\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 37108.2110 - mae: 115.5531 - mse: 37108.2109\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 36742.1786 - mae: 115.4397 - mse: 36742.1836\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 36342.7864 - mae: 114.6731 - mse: 36342.7852\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 36000.8693 - mae: 113.1082 - mse: 36000.8711\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 35474.3111 - mae: 112.4053 - mse: 35474.3086\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 35096.2710 - mae: 113.1459 - mse: 35096.2734\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 34594.7336 - mae: 111.8194 - mse: 34594.7344\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 34124.6387 - mae: 110.5697 - mse: 34124.6367\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 33696.3110 - mae: 109.5582 - mse: 33696.3125\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 33260.5201 - mae: 109.3167 - mse: 33260.5195\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 32895.9042 - mae: 108.9068 - mse: 32895.9062\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 32498.9049 - mae: 109.4973 - mse: 32498.9062\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 32105.8296 - mae: 107.8394 - mse: 32105.8301\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 31646.0094 - mae: 107.0248 - mse: 31646.0098\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 31289.3375 - mae: 106.2295 - mse: 31289.3398\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 30931.7111 - mae: 106.7320 - mse: 30931.7129\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 30650.1505 - mae: 105.3739 - mse: 30650.1504\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 30259.6743 - mae: 105.2181 - mse: 30259.6738\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 29951.1018 - mae: 104.8839 - mse: 29951.0996\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 29651.2120 - mae: 104.3167 - mse: 29651.2109\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 29367.4710 - mae: 103.6188 - mse: 29367.4727\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 29134.2335 - mae: 103.7383 - mse: 29134.2324\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 28827.7067 - mae: 102.8505 - mse: 28827.7070\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 28602.9936 - mae: 102.5331 - mse: 28602.9902\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 28396.7038 - mae: 102.6082 - mse: 28396.7031\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 28236.7102 - mae: 102.5282 - mse: 28236.7109\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 28033.8207 - mae: 101.5699 - mse: 28033.8203\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 27828.5471 - mae: 101.1663 - mse: 27828.5488\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 600us/step - loss: 78018.3190 - mae: 195.4162 - mse: 78018.3203\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 43us/step - loss: 77950.5630 - mae: 195.2369 - mse: 77950.5703\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 36us/step - loss: 77856.9758 - mae: 194.9929 - mse: 77856.9766\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 77714.1618 - mae: 194.6362 - mse: 77714.1641\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 77520.1396 - mae: 194.1287 - mse: 77520.1484\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 77239.6172 - mae: 193.4237 - mse: 77239.6250\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 39us/step - loss: 76867.2092 - mae: 192.4442 - mse: 76867.2031\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 76351.7555 - mae: 191.0786 - mse: 76351.7500\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 75624.0031 - mae: 189.2323 - mse: 75623.9922\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 74658.0708 - mae: 186.7105 - mse: 74658.0703\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 73375.0896 - mae: 183.4076 - mse: 73375.0859\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 71716.4684 - mae: 179.1027 - mse: 71716.4688\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 69656.1046 - mae: 173.5394 - mse: 69656.1094\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 67236.7971 - mae: 166.7310 - mse: 67236.7969\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 64368.9548 - mae: 158.9945 - mse: 64368.9609\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 71us/step - loss: 61196.9085 - mae: 150.6657 - mse: 61196.9062\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 57668.4035 - mae: 142.5318 - mse: 57668.3984\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 54280.4790 - mae: 133.8775 - mse: 54280.4727\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 50939.2186 - mae: 125.9158 - mse: 50939.2188\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 47867.1130 - mae: 119.4510 - mse: 47867.1133\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 45440.8937 - mae: 115.5457 - mse: 45440.8906\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 43647.2751 - mae: 113.9586 - mse: 43647.2773\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 42398.1805 - mae: 114.6017 - mse: 42398.1836\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 41677.3926 - mae: 116.1225 - mse: 41677.3906\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 41265.9798 - mae: 117.5493 - mse: 41265.9766\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 41064.8900 - mae: 119.1874 - mse: 41064.8945\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 40885.9227 - mae: 119.7449 - mse: 40885.9219\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 40724.9850 - mae: 119.9448 - mse: 40724.9844\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 40595.2562 - mae: 120.2219 - mse: 40595.2578\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 40452.3582 - mae: 119.9468 - mse: 40452.3594\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 40313.5262 - mae: 119.6213 - mse: 40313.5273\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 40186.2151 - mae: 119.5718 - mse: 40186.2148\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 40055.7482 - mae: 119.6378 - mse: 40055.7500\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 35us/step - loss: 39907.0373 - mae: 119.4882 - mse: 39907.0352\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 39774.2889 - mae: 119.1059 - mse: 39774.2852\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 39649.6712 - mae: 119.0294 - mse: 39649.6719\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 39502.6251 - mae: 118.8878 - mse: 39502.6250\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 39365.6008 - mae: 118.5553 - mse: 39365.6016\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 39248.5893 - mae: 118.7082 - mse: 39248.5859\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 39094.2245 - mae: 118.4536 - mse: 39094.2227\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 56us/step - loss: 38965.5990 - mae: 118.3476 - mse: 38965.5938\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 38826.1676 - mae: 117.9297 - mse: 38826.1680\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 38695.1227 - mae: 117.4074 - mse: 38695.1211\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 38589.6292 - mae: 118.0461 - mse: 38589.6211\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 38398.1087 - mae: 117.8280 - mse: 38398.1094\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 38257.9626 - mae: 117.2734 - mse: 38257.9648\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 38114.4650 - mae: 116.7400 - mse: 38114.4648\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 37987.9718 - mae: 116.3200 - mse: 37987.9648\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 37851.8330 - mae: 116.3774 - mse: 37851.8281\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 37694.9883 - mae: 116.7027 - mse: 37694.9883\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 37538.6185 - mae: 116.3465 - mse: 37538.6211\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 37382.9581 - mae: 115.8468 - mse: 37382.9570\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 37233.6817 - mae: 115.6381 - mse: 37233.6797\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 37081.4872 - mae: 115.5320 - mse: 37081.4883\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 37us/step - loss: 36927.0270 - mae: 115.4652 - mse: 36927.0273\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 36772.9151 - mae: 115.2520 - mse: 36772.9141\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 36613.7660 - mae: 114.8377 - mse: 36613.7656\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 36457.5486 - mae: 114.5544 - mse: 36457.5469\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 36312.0046 - mae: 113.9980 - mse: 36312.0078\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 36127.9799 - mae: 114.1060 - mse: 36127.9844\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 35977.4713 - mae: 114.5338 - mse: 35977.4727\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 35778.0431 - mae: 113.7672 - mse: 35778.0430\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 35590.2326 - mae: 113.3979 - mse: 35590.2344\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - ETA: 0s - loss: 34261.0859 - mae: 117.4221 - mse: 34261.085 - 0s 53us/step - loss: 35389.0866 - mae: 113.3371 - mse: 35389.0898\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 41us/step - loss: 35163.1867 - mae: 112.9275 - mse: 35163.1875\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 34918.4872 - mae: 112.2764 - mse: 34918.4844\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 34642.9973 - mae: 111.3990 - mse: 34643.0000\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 38us/step - loss: 34388.9173 - mae: 110.6662 - mse: 34388.9219\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 34101.2782 - mae: 110.2782 - mse: 34101.2812\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 33823.2869 - mae: 109.2843 - mse: 33823.2891\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 33543.8845 - mae: 108.6801 - mse: 33543.8828\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 33226.0503 - mae: 108.7536 - mse: 33226.0508\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 32933.2418 - mae: 108.5593 - mse: 32933.2383\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 32623.7464 - mae: 107.8211 - mse: 32623.7441\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 32301.8743 - mae: 106.7956 - mse: 32301.8770\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 44us/step - loss: 31969.0393 - mae: 106.1516 - mse: 31969.0371\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 31636.1402 - mae: 105.0953 - mse: 31636.1406\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 31302.6934 - mae: 105.2629 - mse: 31302.6934\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 30949.6192 - mae: 104.3619 - mse: 30949.6191\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 30610.8377 - mae: 104.4222 - mse: 30610.8359\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 30251.2752 - mae: 103.1256 - mse: 30251.2773\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 29895.3067 - mae: 102.5082 - mse: 29895.3066\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 29570.2822 - mae: 102.1178 - mse: 29570.2832\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 29234.5803 - mae: 101.6994 - mse: 29234.5762\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 28832.6342 - mae: 100.1938 - mse: 28832.6328\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 28514.0122 - mae: 99.5044 - mse: 28514.0137\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 28159.5876 - mae: 99.3052 - mse: 28159.5859\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 27832.9435 - mae: 99.0783 - mse: 27832.9453\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 27574.2994 - mae: 97.7245 - mse: 27574.3008\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 27199.5434 - mae: 98.0564 - mse: 27199.5469\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 26867.1713 - mae: 97.8427 - mse: 26867.1719\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 26543.2867 - mae: 97.5310 - mse: 26543.2871\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 26306.4550 - mae: 95.2542 - mse: 26306.4551\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 25986.7314 - mae: 95.6287 - mse: 25986.7324\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 25676.2850 - mae: 95.2297 - mse: 25676.2832\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 25437.8627 - mae: 95.5788 - mse: 25437.8613\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 25138.5082 - mae: 94.3466 - mse: 25138.5098\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 24867.6039 - mae: 93.7891 - mse: 24867.6055\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 24732.9597 - mae: 94.0535 - mse: 24732.9609\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 24390.1466 - mae: 93.2209 - mse: 24390.1465\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 615us/step - loss: 85249.0346 - mae: 196.3805 - mse: 85249.0312\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 85208.1668 - mae: 196.2753 - mse: 85208.1719\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 85160.0680 - mae: 196.1438 - mse: 85160.0703\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 85084.7720 - mae: 195.9513 - mse: 85084.7734\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 84972.6378 - mae: 195.6533 - mse: 84972.6250\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 84796.5695 - mae: 195.1871 - mse: 84796.5703\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 84514.7531 - mae: 194.4486 - mse: 84514.7500\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 84059.8570 - mae: 193.2558 - mse: 84059.8594\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 83348.1482 - mae: 191.3561 - mse: 83348.1484\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 82263.2025 - mae: 188.5427 - mse: 82263.2031\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 80681.2085 - mae: 184.5127 - mse: 80681.2109\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 78590.5100 - mae: 178.8359 - mse: 78590.5156\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 75787.3142 - mae: 171.3245 - mse: 75787.3203\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 72256.3547 - mae: 162.1505 - mse: 72256.3516\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 68256.6680 - mae: 151.9738 - mse: 68256.6719\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 44us/step - loss: 63706.2357 - mae: 141.3745 - mse: 63706.2344\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 59288.6532 - mae: 131.9134 - mse: 59288.6523\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 55152.3073 - mae: 123.8037 - mse: 55152.3086\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 52227.9309 - mae: 120.1772 - mse: 52227.9336\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 50166.9717 - mae: 121.3664 - mse: 50166.9648\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 48870.2135 - mae: 123.7327 - mse: 48870.2148\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 48426.3366 - mae: 126.4771 - mse: 48426.3320\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 48185.8128 - mae: 128.7661 - mse: 48185.8086\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 47925.5987 - mae: 129.6371 - mse: 47925.6016\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 47711.2289 - mae: 129.0872 - mse: 47711.2266\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 47548.9824 - mae: 129.3140 - mse: 47548.9844\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 47355.6036 - mae: 128.6968 - mse: 47355.6016\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 47182.1777 - mae: 128.7237 - mse: 47182.1797\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 46953.9928 - mae: 128.8090 - mse: 46953.9922\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 46768.5598 - mae: 128.5445 - mse: 46768.5586\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 46601.9421 - mae: 128.3011 - mse: 46601.9414\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 46457.5496 - mae: 128.5590 - mse: 46457.5586\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 46215.6174 - mae: 128.5135 - mse: 46215.6211\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 46037.8024 - mae: 128.2072 - mse: 46037.8047\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 50us/step - loss: 45875.1654 - mae: 127.1357 - mse: 45875.1680\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 45716.6814 - mae: 127.5134 - mse: 45716.6797\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 45494.4749 - mae: 128.1112 - mse: 45494.4727\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 45289.4227 - mae: 127.3615 - mse: 45289.4258\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 45128.7467 - mae: 126.8165 - mse: 45128.7461\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 44923.9367 - mae: 126.4089 - mse: 44923.9375\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 59us/step - loss: 44735.6902 - mae: 126.8520 - mse: 44735.6914\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 44536.9253 - mae: 126.8538 - mse: 44536.9219\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 44382.0232 - mae: 126.1822 - mse: 44382.0234\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 44150.9326 - mae: 125.3508 - mse: 44150.9297\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 43972.0245 - mae: 125.5015 - mse: 43972.0234\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 43750.4292 - mae: 125.9540 - mse: 43750.4297\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 43549.9384 - mae: 126.2370 - mse: 43549.9375\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 43352.5785 - mae: 126.2416 - mse: 43352.5742\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 43202.6900 - mae: 126.4833 - mse: 43202.6914\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 42960.0443 - mae: 125.2524 - mse: 42960.0391\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 42729.8645 - mae: 124.4924 - mse: 42729.8594\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 42536.3724 - mae: 125.2447 - mse: 42536.3711\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 42267.4842 - mae: 125.1122 - mse: 42267.4844\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 42043.6440 - mae: 124.6216 - mse: 42043.6484\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 41784.1142 - mae: 123.5643 - mse: 41784.1133\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 41534.3156 - mae: 123.3903 - mse: 41534.3203\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 41249.2396 - mae: 123.7453 - mse: 41249.2383\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 40990.5159 - mae: 123.6225 - mse: 40990.5195\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 40760.2596 - mae: 122.1307 - mse: 40760.2617\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 40528.4390 - mae: 122.8135 - mse: 40528.4414\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 40185.4711 - mae: 123.6937 - mse: 40185.4648\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 39832.0333 - mae: 122.2389 - mse: 39832.0352\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 39581.1693 - mae: 120.6219 - mse: 39581.1680\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 39340.2559 - mae: 120.6136 - mse: 39340.2617\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 38987.9884 - mae: 120.9161 - mse: 38987.9883\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 38676.7970 - mae: 120.1059 - mse: 38676.7930\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 38369.3934 - mae: 119.8144 - mse: 38369.3984\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 38053.2266 - mae: 119.3315 - mse: 38053.2266\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 0s 41us/step - loss: 37745.0441 - mae: 119.2939 - mse: 37745.0430\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 37433.7340 - mae: 119.2333 - mse: 37433.7344\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 37091.3096 - mae: 118.6979 - mse: 37091.3125\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 36762.9862 - mae: 117.2406 - mse: 36762.9883\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 36428.8685 - mae: 116.8363 - mse: 36428.8711\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 36125.4359 - mae: 116.1897 - mse: 36125.4375\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 35744.4635 - mae: 115.6921 - mse: 35744.4648\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 35429.1023 - mae: 116.5757 - mse: 35429.1016\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 35034.2924 - mae: 115.8073 - mse: 35034.2852\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 34698.7669 - mae: 114.8453 - mse: 34698.7695\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 34318.1969 - mae: 113.6667 - mse: 34318.1953\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 33956.0149 - mae: 112.8926 - mse: 33956.0156\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 33591.4295 - mae: 112.2900 - mse: 33591.4297\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 33267.9780 - mae: 112.6644 - mse: 33267.9805\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 68us/step - loss: 32834.2415 - mae: 112.0890 - mse: 32834.2422\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 32515.0773 - mae: 110.3730 - mse: 32515.0801\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 32154.2932 - mae: 109.4654 - mse: 32154.2871\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 31835.9768 - mae: 110.4536 - mse: 31835.9805\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 31366.0643 - mae: 109.4129 - mse: 31366.0625\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 39us/step - loss: 30989.1777 - mae: 108.3760 - mse: 30989.1797\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 30645.6128 - mae: 107.5655 - mse: 30645.6133\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 30266.9133 - mae: 106.4087 - mse: 30266.9141\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 55us/step - loss: 29947.8878 - mae: 106.3282 - mse: 29947.8906\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 29544.8639 - mae: 105.6549 - mse: 29544.8633\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 29192.2758 - mae: 105.1553 - mse: 29192.2734\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 28829.7275 - mae: 104.2847 - mse: 28829.7266\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 28508.3618 - mae: 103.4543 - mse: 28508.3594\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 28151.3079 - mae: 103.0484 - mse: 28151.3066\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 27828.3547 - mae: 102.8152 - mse: 27828.3555\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 41us/step - loss: 27541.8714 - mae: 102.7958 - mse: 27541.8691\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 27172.3830 - mae: 101.5713 - mse: 27172.3828\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 26895.8733 - mae: 101.1208 - mse: 26895.8750\n",
      "Epoch 1/100\n",
      "600/600 [==============================] - 0s 691us/step - loss: 83602.1891 - mae: 203.3059 - mse: 83602.1875\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 37us/step - loss: 83556.9974 - mae: 203.1914 - mse: 83556.9922\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 83504.2034 - mae: 203.0643 - mse: 83504.2109\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 83426.1323 - mae: 202.8713 - mse: 83426.1328\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 83288.3857 - mae: 202.5312 - mse: 83288.3828\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 83036.7065 - mae: 201.9209 - mse: 83036.7109\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 82635.4333 - mae: 200.9397 - mse: 82635.4297\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 82014.6992 - mae: 199.3647 - mse: 82014.6875\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 81065.0125 - mae: 197.0285 - mse: 81065.0078\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 0s 67us/step - loss: 79726.2091 - mae: 193.6278 - mse: 79726.2109\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 77847.8344 - mae: 188.8708 - mse: 77847.8438\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 0s 57us/step - loss: 75231.5314 - mae: 182.0884 - mse: 75231.5312\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 71773.5927 - mae: 172.7075 - mse: 71773.5938\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 67322.3926 - mae: 161.4695 - mse: 67322.3984\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 62203.7436 - mae: 149.1311 - mse: 62203.7461\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 57009.2348 - mae: 136.3732 - mse: 57009.2344\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 51882.2000 - mae: 125.8795 - mse: 51882.1992\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 48243.0372 - mae: 120.6655 - mse: 48243.0352\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 45634.2665 - mae: 119.8816 - mse: 45634.2656\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 44506.6306 - mae: 122.7782 - mse: 44506.6289\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 43978.2866 - mae: 125.4176 - mse: 43978.2852\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 43745.1573 - mae: 126.9629 - mse: 43745.1602\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 43537.4301 - mae: 127.4741 - mse: 43537.4336\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 43357.9852 - mae: 127.5589 - mse: 43357.9883\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 43152.4876 - mae: 127.0459 - mse: 43152.4883\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 43013.5910 - mae: 126.0538 - mse: 43013.5938\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 42822.4975 - mae: 125.4561 - mse: 42822.5000\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 42631.0919 - mae: 126.3557 - mse: 42631.0938\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 42450.5867 - mae: 126.7188 - mse: 42450.5859\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 42280.9687 - mae: 126.3067 - mse: 42280.9688\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 42113.8432 - mae: 125.7508 - mse: 42113.8438\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 0s 66us/step - loss: 41935.3351 - mae: 125.4287 - mse: 41935.3359\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 0s 50us/step - loss: 41760.0327 - mae: 125.4125 - mse: 41760.0352\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 41580.2798 - mae: 125.2251 - mse: 41580.2812\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 41415.1969 - mae: 124.9494 - mse: 41415.1914\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 41249.7952 - mae: 125.3347 - mse: 41249.7969\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 41091.3130 - mae: 124.6756 - mse: 41091.3086\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 40923.6757 - mae: 124.7848 - mse: 40923.6797\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 40712.2038 - mae: 124.5831 - mse: 40712.2070\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 0s 70us/step - loss: 40541.4583 - mae: 124.1401 - mse: 40541.4570\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 40379.5290 - mae: 124.3705 - mse: 40379.5273\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 40176.0944 - mae: 123.8387 - mse: 40176.0938\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 39988.2654 - mae: 123.3328 - mse: 39988.2656\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 39800.6740 - mae: 122.9010 - mse: 39800.6680\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 39630.9124 - mae: 122.9512 - mse: 39630.9141\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 0s 61us/step - loss: 39425.4185 - mae: 122.6970 - mse: 39425.4219\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 0s 38us/step - loss: 39238.9751 - mae: 122.1288 - mse: 39238.9766\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 39071.1432 - mae: 122.7520 - mse: 39071.1484\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 38840.9499 - mae: 122.3174 - mse: 38840.9531\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 38659.8906 - mae: 121.4682 - mse: 38659.8945\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 38437.4240 - mae: 121.3340 - mse: 38437.4219\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 38233.3255 - mae: 121.3909 - mse: 38233.3281\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 38012.4909 - mae: 121.2783 - mse: 38012.4883\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 37817.3027 - mae: 120.2911 - mse: 37817.3086\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 37598.5648 - mae: 120.2034 - mse: 37598.5625\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 37371.5082 - mae: 120.1814 - mse: 37371.5117\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 37167.2080 - mae: 120.3689 - mse: 37167.2070\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 0s 63us/step - loss: 36919.9807 - mae: 119.3544 - mse: 36919.9805\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 36711.6490 - mae: 118.6232 - mse: 36711.6484\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 36449.6196 - mae: 118.4520 - mse: 36449.6211\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 36212.1442 - mae: 118.5346 - mse: 36212.1445\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 0s 65us/step - loss: 35982.7096 - mae: 118.7644 - mse: 35982.7109\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 0s 51us/step - loss: 35717.4938 - mae: 117.7836 - mse: 35717.4922\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 35456.7668 - mae: 117.0304 - mse: 35456.7656\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 0s 41us/step - loss: 35190.6794 - mae: 116.7048 - mse: 35190.6797\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 34936.0270 - mae: 116.4810 - mse: 34936.0234\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 34679.7918 - mae: 115.9739 - mse: 34679.7891\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 34397.7212 - mae: 115.6332 - mse: 34397.7227\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 40us/step - loss: 34110.1421 - mae: 115.0155 - mse: 34110.1406\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 0s 62us/step - loss: 33836.3831 - mae: 114.0521 - mse: 33836.3789\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 33596.0677 - mae: 114.4223 - mse: 33596.0625\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 0s 46us/step - loss: 33247.2163 - mae: 113.7416 - mse: 33247.2148\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 0s 42us/step - loss: 32965.1283 - mae: 112.5689 - mse: 32965.1289\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 32671.4678 - mae: 112.2303 - mse: 32671.4629\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 0s 59us/step - loss: 32375.5376 - mae: 111.7120 - mse: 32375.5371\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 32054.6598 - mae: 111.6360 - mse: 32054.6602\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 31793.6952 - mae: 111.4587 - mse: 31793.6934\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 31445.6331 - mae: 110.4719 - mse: 31445.6328\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 0s 58us/step - loss: 31169.5189 - mae: 109.2232 - mse: 31169.5195\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 30828.0730 - mae: 109.0509 - mse: 30828.0762\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 30521.5557 - mae: 108.4562 - mse: 30521.5566\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 0s 48us/step - loss: 30239.9667 - mae: 107.3538 - mse: 30239.9668\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 29891.8964 - mae: 106.8848 - mse: 29891.8965\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 29600.1451 - mae: 106.8481 - mse: 29600.1426\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 29278.7905 - mae: 106.6649 - mse: 29278.7930\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 28990.6742 - mae: 105.7349 - mse: 28990.6699\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 0s 40us/step - loss: 28665.7166 - mae: 104.4144 - mse: 28665.7207\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 28368.0108 - mae: 104.2559 - mse: 28368.0137\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 28040.0395 - mae: 103.8250 - mse: 28040.0391\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 0s 60us/step - loss: 27742.0556 - mae: 102.9820 - mse: 27742.0527\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 27453.0486 - mae: 102.1621 - mse: 27453.0469\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 27137.1392 - mae: 102.0307 - mse: 27137.1387\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 0s 53us/step - loss: 26863.9736 - mae: 101.6153 - mse: 26863.9707\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 0s 45us/step - loss: 26573.8783 - mae: 100.6406 - mse: 26573.8809\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 26286.4449 - mae: 100.2035 - mse: 26286.4473\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 26034.7810 - mae: 100.1031 - mse: 26034.7793\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 0s 52us/step - loss: 25766.5391 - mae: 99.7730 - mse: 25766.5391\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 0s 47us/step - loss: 25489.5032 - mae: 98.7741 - mse: 25489.5039\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 25296.5458 - mae: 97.7220 - mse: 25296.5469\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 0s 43us/step - loss: 25025.7506 - mae: 97.8728 - mse: 25025.7500\n",
      "Epoch 1/100\n",
      "750/750 [==============================] - 0s 591us/step - loss: 84438.6618 - mae: 201.0794 - mse: 84438.6562\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 84353.9460 - mae: 200.8657 - mse: 84353.9453\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 0s 50us/step - loss: 84226.2168 - mae: 200.5435 - mse: 84226.2266\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 84015.2416 - mae: 200.0363 - mse: 84015.2344\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 0s 43us/step - loss: 83634.4765 - mae: 199.0903 - mse: 83634.4609\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 82946.7370 - mae: 197.3598 - mse: 82946.7422\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 81767.0707 - mae: 194.4204 - mse: 81767.0781\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 79784.2926 - mae: 189.3748 - mse: 79784.2969\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 76557.5259 - mae: 181.0238 - mse: 76557.5234\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 0s 54us/step - loss: 71728.8324 - mae: 168.5557 - mse: 71728.8359\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 65625.8834 - mae: 153.0776 - mse: 65625.8906\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 58688.5616 - mae: 136.8661 - mse: 58688.5664\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 52281.3640 - mae: 123.6120 - mse: 52281.3711\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 48078.3703 - mae: 120.1190 - mse: 48078.3750\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 46114.3588 - mae: 123.8934 - mse: 46114.3633\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 45433.1420 - mae: 126.0376 - mse: 45433.1406\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 0s 59us/step - loss: 45159.2458 - mae: 127.0959 - mse: 45159.2461\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 44911.0432 - mae: 127.2915 - mse: 44911.0469\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 0s 40us/step - loss: 44719.9097 - mae: 126.4554 - mse: 44719.9102\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 44456.2257 - mae: 127.0776 - mse: 44456.2266\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 0s 54us/step - loss: 44213.0314 - mae: 127.1486 - mse: 44213.0391\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 0s 39us/step - loss: 43994.3597 - mae: 126.6982 - mse: 43994.3555\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 43771.1526 - mae: 127.1239 - mse: 43771.1523\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 0s 59us/step - loss: 43628.6449 - mae: 125.5173 - mse: 43628.6445\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 0s 60us/step - loss: 43331.3039 - mae: 125.2470 - mse: 43331.3047\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 43109.2221 - mae: 125.2868 - mse: 43109.2227\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 42914.2227 - mae: 125.9393 - mse: 42914.2227\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 42734.5281 - mae: 126.6691 - mse: 42734.5273\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 42483.0581 - mae: 124.7732 - mse: 42483.0547\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 42253.3215 - mae: 124.7886 - mse: 42253.3242\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 0s 56us/step - loss: 41996.7661 - mae: 124.2655 - mse: 41996.7695\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 41760.5245 - mae: 123.5976 - mse: 41760.5195\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 41513.9335 - mae: 123.6574 - mse: 41513.9336\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 41257.2146 - mae: 123.6151 - mse: 41257.2148\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 0s 45us/step - loss: 41006.9438 - mae: 123.0344 - mse: 41006.9453\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 0s 49us/step - loss: 40765.4933 - mae: 123.0063 - mse: 40765.4922\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 40491.0617 - mae: 122.6298 - mse: 40491.0625\n",
      "Epoch 38/100\n",
      "750/750 [==============================] - 0s 52us/step - loss: 40215.6758 - mae: 121.8650 - mse: 40215.6758\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 0s 66us/step - loss: 39992.7375 - mae: 122.3258 - mse: 39992.7422\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 0s 86us/step - loss: 39668.3496 - mae: 120.3292 - mse: 39668.3516\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 0s 73us/step - loss: 39314.6056 - mae: 120.0727 - mse: 39314.6094\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 0s 66us/step - loss: 38990.9671 - mae: 121.2516 - mse: 38990.9688\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 0s 80us/step - loss: 38611.7329 - mae: 120.3363 - mse: 38611.7305\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 0s 81us/step - loss: 38299.8792 - mae: 118.2568 - mse: 38299.8789\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 0s 82us/step - loss: 37933.9326 - mae: 118.6707 - mse: 37933.9336\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 0s 84us/step - loss: 37488.7681 - mae: 118.1347 - mse: 37488.7695\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 0s 68us/step - loss: 37093.8463 - mae: 117.6675 - mse: 37093.8438\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 0s 55us/step - loss: 36712.1654 - mae: 117.3080 - mse: 36712.1680\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 36374.9950 - mae: 117.5383 - mse: 36374.9961\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 35868.8573 - mae: 115.6526 - mse: 35868.8555\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 35451.8136 - mae: 114.4513 - mse: 35451.8164\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 35066.8779 - mae: 114.5047 - mse: 35066.8789\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 34641.1270 - mae: 113.1852 - mse: 34641.1289\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 34310.8171 - mae: 113.9141 - mse: 34310.8203\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 33742.9799 - mae: 112.4957 - mse: 33742.9805\n",
      "Epoch 56/100\n",
      "750/750 [==============================] - 0s 60us/step - loss: 33284.2711 - mae: 110.6592 - mse: 33284.2695\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 0s 56us/step - loss: 32856.8670 - mae: 110.3615 - mse: 32856.8672\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 0s 50us/step - loss: 32431.4009 - mae: 109.8288 - mse: 32431.4004\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 31977.7478 - mae: 108.4396 - mse: 31977.7500\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 0s 50us/step - loss: 31522.5104 - mae: 108.8987 - mse: 31522.5059\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 31064.3784 - mae: 107.3441 - mse: 31064.3770\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 0s 47us/step - loss: 30630.8236 - mae: 107.4233 - mse: 30630.8242\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 30166.8015 - mae: 106.0572 - mse: 30166.8008\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 0s 43us/step - loss: 29723.8276 - mae: 105.0874 - mse: 29723.8301\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 29290.5864 - mae: 104.3345 - mse: 29290.5859\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 0s 55us/step - loss: 28853.9512 - mae: 103.1529 - mse: 28853.9492\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 28500.0228 - mae: 103.3728 - mse: 28500.0215\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 28044.3782 - mae: 102.2516 - mse: 28044.3809\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 27668.4746 - mae: 101.0823 - mse: 27668.4727\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 0s 44us/step - loss: 27353.4344 - mae: 99.9936 - mse: 27353.4355\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 27008.0253 - mae: 99.2734 - mse: 27008.0293\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 0s 39us/step - loss: 26644.9006 - mae: 99.5096 - mse: 26644.9004\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 0s 57us/step - loss: 26331.1790 - mae: 98.5444 - mse: 26331.1777\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 0s 58us/step - loss: 26021.0309 - mae: 98.1807 - mse: 26021.0312\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 25777.2000 - mae: 98.0137 - mse: 25777.1992\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 0s 55us/step - loss: 25502.3024 - mae: 97.8037 - mse: 25502.3008\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 25256.6693 - mae: 96.3742 - mse: 25256.6719\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 0s 55us/step - loss: 25018.6701 - mae: 96.6755 - mse: 25018.6699\n",
      "Epoch 79/100\n",
      "750/750 [==============================] - 0s 57us/step - loss: 24758.0186 - mae: 95.7740 - mse: 24758.0195\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 24544.8570 - mae: 95.6170 - mse: 24544.8555\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 24371.6249 - mae: 95.1839 - mse: 24371.6230\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 24166.0037 - mae: 94.9871 - mse: 24166.0020\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 0s 50us/step - loss: 24019.4729 - mae: 95.3291 - mse: 24019.4746\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 23835.8761 - mae: 93.9160 - mse: 23835.8770\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 23673.0117 - mae: 94.0431 - mse: 23673.0098\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 0s 54us/step - loss: 23544.8859 - mae: 94.2625 - mse: 23544.8848\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 23402.2997 - mae: 94.0144 - mse: 23402.2988\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 23263.5625 - mae: 93.3220 - mse: 23263.5625\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 23141.1223 - mae: 93.3474 - mse: 23141.1230\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 23036.8162 - mae: 93.0231 - mse: 23036.8125\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 0s 56us/step - loss: 22946.5451 - mae: 93.2968 - mse: 22946.5449\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 22829.7141 - mae: 92.6598 - mse: 22829.7148\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 0s 48us/step - loss: 22735.7425 - mae: 92.2784 - mse: 22735.7422\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 0s 61us/step - loss: 22681.0441 - mae: 92.5459 - mse: 22681.0449\n",
      "Epoch 95/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 22592.0297 - mae: 92.6614 - mse: 22592.0293\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 0s 53us/step - loss: 22505.7516 - mae: 92.0015 - mse: 22505.7520\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 22428.8448 - mae: 91.8116 - mse: 22428.8477\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 0s 51us/step - loss: 22380.7593 - mae: 91.8125 - mse: 22380.7598\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 0s 50us/step - loss: 22289.0908 - mae: 91.6863 - mse: 22289.0918\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 0s 49us/step - loss: 22231.2073 - mae: 91.6596 - mse: 22231.2070\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=11, activation = 'relu', input_dim=22))\n",
    "    model.add(Dense(units=11, activation = 'relu'))\n",
    "    model.add(Dense(units=11, activation = 'relu'))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae','mse'])\n",
    "    return model\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "NN_Regressor = KerasRegressor(build_fn=build_model, batch_size=40,epochs=100)    \n",
    "\n",
    "scores = cross_val_score(NN_Regressor, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "NN = NN_Regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the scores for each model run\n",
      "[-25689.92047577 -16121.26387972 -40942.26717027 -24309.82918077\n",
      " -35726.95904963]\n",
      " \n",
      "Mean and variance: 28558.05 (+/- 17566.09)\n",
      " \n",
      " \n",
      "Model performance on testing data\n",
      "Mean Absolute Error: 107.83027166259767\n",
      "Root Mean Squared Error: 38047.33872083337\n",
      "Time Taken =  61.15625\n"
     ]
    }
   ],
   "source": [
    "print(\"Below are the scores for each model run\")\n",
    "print(scores)\n",
    "print(\" \")\n",
    "print(\"Mean and variance: %0.2f (+/- %0.2f)\" % (abs(scores.mean()), scores.std() * 2))\n",
    "\n",
    "y_pred= NN_Regressor.predict(X_test_holdout)\n",
    "print(\" \")\n",
    "print(\" \")\n",
    "print('Model performance on testing data')\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_holdout, y_pred))  \n",
    "print('Root Mean Squared Error:', sqrt(metrics.mean_squared_error(y_test_holdout, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
